{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanHoann/Yelp_Dataset_Challenges/blob/main/Link_Prediction/Final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYZeXSDm7JKf"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlSm_Z7FEAQ7",
        "outputId": "db6a65e9-1526-4c79-d960-d73a86664eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 10 05:30:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NxODlNoNsSVl"
      },
      "outputs": [],
      "source": [
        "import os, time\n",
        "import networkx as nx\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import chain\n",
        "from collections import defaultdict\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VhjbYaKWSVv",
        "outputId": "36beed09-5999-4e37-94b4-6a7c325dc134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6.0\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "print(\n",
        "    gensim.__version__\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set seed"
      ],
      "metadata": {
        "id": "oLg5OSK4o8My"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mNlZGtouqFg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb4e0d7-f312-4337-a397-012f4d3cd780"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1anQhtdbsSVx"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7txwBwGOsSV1"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zR76FAZsSV3"
      },
      "source": [
        "We need to load networks into memory. Usually networks are organized as pairs of nodes. And sometimes different edges have different weights. Hence, we use networkx.DiGraph to store such structure information and attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s1RZzx04YzQc"
      },
      "outputs": [],
      "source": [
        "def construct_uid_index(file_train_csv='train.csv'):\n",
        "    '''\n",
        "        build two dictionaries to \n",
        "        link uid (--UOvCH5qEgdNQ8lzR8QYQ, ...) to index (1,2,3,...)\n",
        "    '''\n",
        "    df = pd.read_csv(file_train_csv)\n",
        "\n",
        "    list_uid = []\n",
        "    for idx, row in df.iterrows():\n",
        "        user_id, friends = row[\"user_id\"], eval(row[\"friends\"])\n",
        "        list_uid.append(user_id)\n",
        "        list_uid.extend(friends)\n",
        "\n",
        "    sorted_list_unique_uid = ['']+sorted(set(list_uid))\n",
        "\n",
        "    uid2index = {}\n",
        "    index2uid = {}\n",
        "    uid2ind = {}\n",
        "    ind2uid = {}\n",
        "    for i, uid in enumerate(sorted_list_unique_uid):\n",
        "        uid2index.update({uid: str(i)})\n",
        "        index2uid.update({str(i): uid})\n",
        "        uid2ind.update({uid: i})\n",
        "        ind2uid.update({i: uid})\n",
        "\n",
        "    return index2uid, uid2index, uid2ind, ind2uid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cvETBR6WsSV5"
      },
      "outputs": [],
      "source": [
        "def load_data(file_name, uid2index):\n",
        "    \"\"\"\n",
        "    read edges from an edge file\n",
        "    \"\"\"\n",
        "    edges = list()\n",
        "    df = pd.read_csv(file_name)\n",
        "    for idx, row in df.iterrows():\n",
        "        user_id, friends = row[\"user_id\"], eval(row[\"friends\"])\n",
        "        for friend in friends:\n",
        "            # add each friend relation as an edge\n",
        "            edges.append(\n",
        "                (uid2index.get(user_id, '0'), uid2index.get(friend, '0'))\n",
        "            )\n",
        "    edges = sorted(edges)\n",
        "    \n",
        "    return edges\n",
        "\n",
        "def load_test_data(file_name, uid2index):\n",
        "    \"\"\"\n",
        "    read edges from an edge file\n",
        "    \"\"\"\n",
        "    edges = list()\n",
        "    scores = list()\n",
        "    df = pd.read_csv(file_name)\n",
        "    for idx, row in df.iterrows():\n",
        "        edges.append(\n",
        "            (uid2index.get(row[\"src\"], '0'), uid2index.get(row[\"dst\"], '0'))\n",
        "        )\n",
        "    # edges = sorted(edges)\n",
        "    \n",
        "    return edges\n",
        "\n",
        "def generate_false_edges(true_edges, num_false_edges=5):\n",
        "    \"\"\"\n",
        "    generate false edges given true edges\n",
        "    \"\"\"\n",
        "    nodes = list(set(chain.from_iterable(true_edges)))\n",
        "    N = len(nodes)\n",
        "    true_edges = set(true_edges)\n",
        "    print(N, len(true_edges))\n",
        "    false_edges = set()\n",
        "    \n",
        "    while len(false_edges) < num_false_edges:\n",
        "        # randomly sample two different nodes and check whether the pair exisit or not\n",
        "        src, dst = nodes[int(np.random.rand() * N)], nodes[int(np.random.rand() * N)]\n",
        "        if src != dst and (src, dst) not in true_edges and (src, dst) not in false_edges:\n",
        "            false_edges.add((src, dst))\n",
        "    false_edges = sorted(false_edges)\n",
        "    \n",
        "    return false_edges\n",
        "\n",
        "def construct_graph_from_edges(edges):\n",
        "    \"\"\"\n",
        "    generate a directed graph object given true edges\n",
        "    DiGraph documentation: https://networkx.github.io/documentation/stable/reference/classes/digraph.html\n",
        "    \"\"\"\n",
        "    # convert a list of edges {(u, v)} to a list of edges with weights {(u, v, w)}\n",
        "    edge_weight = defaultdict(float)\n",
        "    for e in edges:\n",
        "        edge_weight[e] += 1.0\n",
        "    weighed_edge_list = list()\n",
        "    for e in sorted(edge_weight.keys()):\n",
        "        weighed_edge_list.append((e[0], e[1], edge_weight[e]))\n",
        "        \n",
        "    graph = nx.DiGraph()\n",
        "    graph.add_weighted_edges_from(weighed_edge_list)\n",
        "    \n",
        "    print(\"number of nodes:\", graph.number_of_nodes())\n",
        "    print(\"number of edges:\", graph.number_of_edges())\n",
        "    \n",
        "    return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojab1rAfsSV-"
      },
      "source": [
        "### Random Walk Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GomJAOc0sSWA"
      },
      "source": [
        "Random walk generators or random walkers yield random walks that contain both local and higher-order neighborhood information. However, naive non-uniform sampling is very slow, which requires O(n) time complexity. Here alias sampling can reduce the time complexity to O(1) with O(n) space. If you are interested, please see the following blog:\\\n",
        "https://lips.cs.princeton.edu/the-alias-method-efficient-sampling-with-many-discrete-outcomes/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "doF5gQfWsSWD"
      },
      "outputs": [],
      "source": [
        "def alias_setup(probs):\n",
        "    \"\"\"\n",
        "    compute utility lists for non-uniform sampling from discrete distributions.\n",
        "    details: https://lips.cs.princeton.edu/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n",
        "    \"\"\"\n",
        "    K = len(probs)\n",
        "    q = np.zeros(K)\n",
        "    J = np.zeros(K, dtype=np.int32)\n",
        "\n",
        "    smaller = list()\n",
        "    larger = list()\n",
        "    for kk, prob in enumerate(probs):\n",
        "        q[kk] = K * prob\n",
        "        if q[kk] < 1.0:\n",
        "            smaller.append(kk)\n",
        "        else:\n",
        "            larger.append(kk)\n",
        "\n",
        "    while len(smaller) > 0 and len(larger) > 0:\n",
        "        small = smaller.pop()\n",
        "        large = larger.pop()\n",
        "\n",
        "        J[small] = large\n",
        "        q[large] = q[large] + q[small] - 1.0\n",
        "        if q[large] < 1.0:\n",
        "            smaller.append(large)\n",
        "        else:\n",
        "            larger.append(large)\n",
        "\n",
        "    return J, q\n",
        "\n",
        "def get_alias_node(graph, node):\n",
        "    \"\"\"\n",
        "    get the alias node setup lists for a given node.\n",
        "    \"\"\"\n",
        "    # get the unnormalized probabilities with the first-order information\n",
        "    unnormalized_probs = list()\n",
        "    for nbr in graph.neighbors(node):\n",
        "        unnormalized_probs.append(graph[node][nbr][\"weight\"])\n",
        "    unnormalized_probs = np.array(unnormalized_probs)\n",
        "    if len(unnormalized_probs) > 0:\n",
        "        normalized_probs = unnormalized_probs / unnormalized_probs.sum()\n",
        "    else:\n",
        "        normalized_probs = unnormalized_probs\n",
        "        \n",
        "    return alias_setup(normalized_probs)\n",
        "    \n",
        "def get_alias_edge(graph, src, dst, p=1, q=1):\n",
        "    \"\"\"\n",
        "    get the alias edge setup lists for a given edge.\n",
        "    \"\"\"\n",
        "    # get the unnormalized probabilities with the second-order information\n",
        "    unnormalized_probs = list()\n",
        "    for dst_nbr in graph.neighbors(dst):\n",
        "        if dst_nbr == src: # distance is 0\n",
        "            unnormalized_probs.append(graph[dst][dst_nbr][\"weight\"]/p)\n",
        "        elif graph.has_edge(dst_nbr, src): # distance is 1\n",
        "            unnormalized_probs.append(graph[dst][dst_nbr][\"weight\"])\n",
        "        else: # distance is 2\n",
        "            unnormalized_probs.append(graph[dst][dst_nbr][\"weight\"]/q)\n",
        "    unnormalized_probs = np.array(unnormalized_probs)\n",
        "    if len(unnormalized_probs) > 0:\n",
        "        normalized_probs = unnormalized_probs / unnormalized_probs.sum()\n",
        "    else:\n",
        "        normalized_probs = unnormalized_probs\n",
        "\n",
        "    return alias_setup(normalized_probs)\n",
        "\n",
        "def preprocess_transition_probs(graph, p=1, q=1):\n",
        "    \"\"\"\n",
        "    preprocess transition probabilities for guiding the random walks.\n",
        "    \"\"\"\n",
        "    alias_nodes = dict()\n",
        "    for node in graph.nodes():\n",
        "        alias_nodes[node] = get_alias_node(graph, node)\n",
        "\n",
        "    alias_edges = dict()\n",
        "    for edge in graph.edges():\n",
        "        alias_edges[edge] = get_alias_edge(graph, edge[0], edge[1], p=p, q=q)\n",
        "\n",
        "    return alias_nodes, alias_edges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqJSzoBTsSWH"
      },
      "source": [
        "The difference between DeepWalk and node2vec is how to generate random walks. The former only consider the first-order information while the latter also involves the second-order information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8Jh6NpC-sSWJ"
      },
      "outputs": [],
      "source": [
        "def alias_draw(J, q):\n",
        "    \"\"\"\n",
        "    draw sample from a non-uniform discrete distribution using alias sampling.\n",
        "    \"\"\"\n",
        "    K = len(J)\n",
        "\n",
        "    kk = int(np.floor(np.random.rand() * K))\n",
        "    if np.random.rand() < q[kk]:\n",
        "        return kk\n",
        "    else:\n",
        "        return J[kk]\n",
        "\n",
        "\n",
        "# helper function to generate the long random walk as desired\n",
        "def fallback(walk, fetch_last_num=1):\n",
        "    if len(walk) > fetch_last_num:\n",
        "        walk.pop()\n",
        "        fetched = []\n",
        "        for i in range(fetch_last_num):\n",
        "            fetched.append(walk[-1-i])\n",
        "        return walk, fetched\n",
        "    else:\n",
        "        return [], [None for _ in range(fetch_last_num)]\n",
        "\n",
        "def generate_first_order_random_walk(graph, alias_nodes, \n",
        "                                     walk_length=10, start_node=None, verbose=False, max_trails=10):\n",
        "    \"\"\"\n",
        "    simulate a random walk starting from start node and considering the first order information.\n",
        "    max_trials: set the max trials to be one for standard random walk. Larger max_trails will make the generated biased.\n",
        "    \"\"\"\n",
        "    if start_node == None:\n",
        "        start_node = np.random.choice(graph.nodes())\n",
        "    walk = [start_node]\n",
        "    cur = start_node\n",
        "    num_tried = 0\n",
        "    \n",
        "    ########## begin ##########\n",
        "    while len(walk) < walk_length:\n",
        "        cur_nbrs = list(graph.neighbors(cur))\n",
        "        if len(cur_nbrs) > 0: # if we can sample next nodes\n",
        "            # sample the next node based on alias_nodes\n",
        "            cur = cur_nbrs[alias_draw(*alias_nodes[cur])]\n",
        "            walk.append(cur)\n",
        "        else: # if we can't do that\n",
        "            num_tried += 1\n",
        "            if num_tried >= max_trails:\n",
        "                break\n",
        "\n",
        "            walk, fetched = fallback(walk, fetch_last_num=1)\n",
        "            cur = fetched[0]\n",
        "            if len(walk) == 0: # if falls back to the empty walk\n",
        "                start_node = np.random.choice(graph.nodes())\n",
        "                walk = [start_node]\n",
        "                cur = start_node\n",
        "    ########## end ##########\n",
        "\n",
        "    if verbose: \n",
        "        print(f'walk of lenght {len(walk)} generated with {num_tried} trails')\n",
        "    return walk\n",
        "    \n",
        "def generate_second_order_random_walk(graph, alias_nodes, alias_edges, \n",
        "                                      walk_length=10, start_node=None, verbose=False, max_trails=10):\n",
        "    \"\"\"\n",
        "    simulate a random walk starting from start node and considering the second order information.\n",
        "    \"\"\"\n",
        "    if start_node == None:\n",
        "        start_node = np.random.choice(graph.nodes())\n",
        "    walk = [start_node]\n",
        "    \n",
        "    prev = None\n",
        "    cur = start_node\n",
        "    num_tried = 0\n",
        "\n",
        "    ########## begin ##########\n",
        "    while len(walk) < walk_length:\n",
        "        cur_nbrs = list(graph.neighbors(cur))\n",
        "        if len(cur_nbrs) > 0:\n",
        "            if prev is None:\n",
        "                # sample the next node based on alias_nodes\n",
        "                prev, cur = cur, cur_nbrs[alias_draw(*alias_nodes[cur])]\n",
        "            else:\n",
        "                # sample the next node based on alias_edges\n",
        "                prev, cur = cur, cur_nbrs[alias_draw(*alias_edges[(prev, cur)])]\n",
        "            walk.append(cur)\n",
        "        else:\n",
        "            num_tried += 1\n",
        "            if num_tried >= max_trails:\n",
        "                break\n",
        "            walk, (cur, prev) = fallback(walk, fetch_last_num=2)\n",
        "            if len(walk) == 0:\n",
        "                start_node = np.random.choice(graph.nodes())\n",
        "                walk = [start_node]\n",
        "                cur = start_node\n",
        "                prev = None\n",
        "    ########## end ##########\n",
        "    if verbose: \n",
        "        print(f'walk of lenght {len(walk)} generated with {num_tried} trails')\n",
        "    return walk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyYYps9zsSWN"
      },
      "source": [
        "### Network Embedding Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepWalk uses 1st-order random walks while Node2Vec uses 2nd-order"
      ],
      "metadata": {
        "id": "8FpMCLGZqmYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OJvllGwssSWO"
      },
      "outputs": [],
      "source": [
        "def build_deepwalk(graph, alias_nodes, node_dim=10, num_walks=10, walk_length=10):\n",
        "    \"\"\"\n",
        "    build a deepwalk model\n",
        "    \"\"\"\n",
        "    print(\"building a DeepWalk model...\", end=\"\\t\")\n",
        "    st = time.time()\n",
        "    np.random.seed(0)\n",
        "    nodes = list(graph.nodes())\n",
        "    walks = list()\n",
        "    # generate random walks\n",
        "    for walk_iter in range(num_walks):\n",
        "        np.random.shuffle(nodes)\n",
        "        for node in nodes:\n",
        "            walks.append(generate_first_order_random_walk(\n",
        "                graph, alias_nodes, walk_length=walk_length, start_node=node))\n",
        "        \n",
        "    walk_lens = [len(w) for w in walks]\n",
        "    if len(walk_lens) > 0:\n",
        "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
        "    else:\n",
        "        avg_walk_len = 0.0\n",
        "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
        "    \n",
        "    # train a skip-gram model for these walks\n",
        "    # replace vector_size by size\n",
        "    model = Word2Vec(walks, size=node_dim, window=3, min_count=0, sg=1, workers=os.cpu_count(), iter=10) #sg=1 for skipgram, 0 for CBOW\n",
        "    print(\"training time: %.4f\" % (time.time()-st))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def build_node2vec(graph, alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10, iter=10):\n",
        "    \"\"\"\n",
        "    build a node2vec model\n",
        "    \"\"\"\n",
        "    print(\"building a node2vec model...\", end=\"\\t\")\n",
        "    st = time.time()\n",
        "    np.random.seed(0)\n",
        "    nodes = list(graph.nodes())\n",
        "    walks = list()\n",
        "    # generate random walks\n",
        "    for walk_iter in range(num_walks):\n",
        "        np.random.shuffle(nodes)\n",
        "        for node in nodes:\n",
        "            walks.append(generate_second_order_random_walk(\n",
        "                graph, alias_nodes, alias_edges, walk_length=walk_length, start_node=node))\n",
        "            \n",
        "    walk_lens = [len(w) for w in walks]\n",
        "    if len(walk_lens) > 0:\n",
        "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
        "    else:\n",
        "        avg_walk_len = 0.0    \n",
        "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
        "    \n",
        "    # train a skip-gram model for these walks\n",
        "    model = Word2Vec(walks, size=node_dim, window=3, min_count=0, sg=1, workers=os.cpu_count(), iter=iter)\n",
        "    print(\"training time: %.4f\" % (time.time()-st))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Dc8VhHBd4Rz9"
      },
      "outputs": [],
      "source": [
        "def build_node2vec_walks(graph, alias_nodes, alias_edges, num_walks=10, walk_length=10):\n",
        "    nodes = list(graph.nodes())\n",
        "    walks = list()\n",
        "    # generate random walks\n",
        "    for walk_iter in range(num_walks):\n",
        "        np.random.shuffle(nodes)\n",
        "        for node in nodes:\n",
        "            walks.append(generate_second_order_random_walk(\n",
        "                graph, alias_nodes, alias_edges, walk_length=walk_length, start_node=node))\n",
        "            \n",
        "    walk_lens = [len(w) for w in walks]\n",
        "    if len(walk_lens) > 0:\n",
        "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
        "    else:\n",
        "        avg_walk_len = 0.0    \n",
        "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len))\n",
        "    return walks\n",
        "\n",
        "def build_deepwalk_walks(graph, alias_nodes, node_dim=10, num_walks=10, walk_length=10):\n",
        "    np.random.seed(0)\n",
        "    nodes = list(graph.nodes())\n",
        "    walks = list()\n",
        "    # generate random walks\n",
        "    for walk_iter in range(num_walks):\n",
        "        np.random.shuffle(nodes)\n",
        "        for node in nodes:\n",
        "            walks.append(generate_first_order_random_walk(\n",
        "                graph, alias_nodes, walk_length=walk_length, start_node=node))\n",
        "        \n",
        "    walk_lens = [len(w) for w in walks]\n",
        "    if len(walk_lens) > 0:\n",
        "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
        "    else:\n",
        "        avg_walk_len = 0.0\n",
        "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0d9Olk1sSW6"
      },
      "source": [
        "### Scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SKwzU-9DsSW7"
      },
      "outputs": [],
      "source": [
        "def get_cosine_sim(model, u, v, default=0.5):\n",
        "    \"\"\"\n",
        "    get the cosine similarity between two nodes\n",
        "    \"\"\"\n",
        "    try:\n",
        "        u = model.wv[u]\n",
        "        v = model.wv[v]\n",
        "        return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "    except:\n",
        "        return default\n",
        "\n",
        "def get_auc_score(model, true_edges, false_edges, default=0.5):\n",
        "    \"\"\"\n",
        "    get the auc score\n",
        "    \"\"\"\n",
        "    y_true = [1] * len(true_edges) + [0] * len(false_edges)\n",
        "    \n",
        "    y_score = list()\n",
        "    for e in true_edges:\n",
        "        y_score.append(get_cosine_sim(model, e[0], e[1], default))\n",
        "    for e in false_edges:\n",
        "        y_score.append(get_cosine_sim(model, e[0], e[1], default))\n",
        "    \n",
        "    return roc_auc_score(y_true, y_score)\n",
        "\n",
        "def write_pred(file_name, edges, scores):\n",
        "    df = pd.DataFrame()\n",
        "    df[\"src\"] = [e[0] for e in edges]\n",
        "    df[\"dst\"] = [e[1] for e in edges]\n",
        "    df[\"score\"] = scores\n",
        "    df.to_csv(file_name, index=False)\n",
        "\n",
        "def write_valid_ans(file_name, edges, scores):\n",
        "    df = pd.DataFrame()\n",
        "    df[\"src\"] = [e[0] for e in edges]\n",
        "    df[\"dst\"] = [e[1] for e in edges]\n",
        "    df[\"score\"] = scores\n",
        "    df.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5DMNZ8tsSW8"
      },
      "source": [
        "###Build a DeepWalk/Node2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEV-6norsSW8"
      },
      "source": [
        "Firstly, we need to load edges into memory and use the networkx.DiGraph structure to store the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUY0Fp59sSW9",
        "outputId": "ef313381-966c-4ca8-c6fd-f83327210ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of nodes: 8343\n",
            "number of edges: 100000\n",
            "8344 119238\n"
          ]
        }
      ],
      "source": [
        "data = \"https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Link_Prediction/data\"\n",
        "train_file = f\"{data}/train.csv\"\n",
        "valid_file = f\"{data}/valid.csv\"\n",
        "test_file = f\"{data}/test.csv\"\n",
        "\n",
        "np.random.seed(0)\n",
        "index2uid, uid2index, uid2ind, ind2uid = construct_uid_index(train_file)\n",
        "train_edges = load_data(train_file, uid2index)\n",
        "graph = construct_graph_from_edges(train_edges)\n",
        "valid_edges = load_data(valid_file, uid2index)\n",
        "false_edges = generate_false_edges(train_edges+valid_edges, 40000-len(valid_edges))\n",
        "test_edges = load_test_data(test_file, uid2index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_edges), len(valid_edges), len(false_edges))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9HmS_96vawG",
        "outputId": "8b1be87b-8a14-48a9-efb3-12e6dc1f03a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000 19267 20733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwxiliPcsSW_"
      },
      "source": [
        "After that, we can use preprocess transition probabilities with the help of alias sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uxAZbBcFsSXA"
      },
      "outputs": [],
      "source": [
        "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=1, q=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41HawQv5sSXC"
      },
      "source": [
        "Generate a first-order random walk and a second-order random walk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2oEEqJGsSXC",
        "outputId": "072ceecf-e9ff-4f3c-f4cb-d98e9b361d6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '2155', '6167', '1563', '6510', '1586', '6407', '3821', '4595', '1474']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "generate_first_order_random_walk(graph, alias_nodes=alias_nodes,\n",
        "                                 start_node='1',    #\"N6ZTMIue-2b30CJv2tyPGg\", \n",
        "                                 walk_length=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKymt6ZgsSXD",
        "outputId": "f5cd0b77-8eee-4fc9-d035-935ba2c8e616"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10', '6561', '287', '1607', '4926', '6232', '3841', '3821', '2058', '262']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "generate_second_order_random_walk(graph, alias_nodes=alias_nodes, alias_edges=alias_edges,\n",
        "                                  start_node='10',   #\"N6ZTMIue-2b30CJv2tyPGg\", \n",
        "                                  walk_length=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJdOZlE_sSXE"
      },
      "source": [
        "Build a DeepWalk model and a Node2Vec model. Here we set p=q=0.5 so that the walker will not go very far away from the start node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S00ZVbONsSXE",
        "outputId": "3feabe89-085e-419f-d109-15c935ed1fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building a DeepWalk model...\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of walks: 83430\taverage walk length: 19.7400\ttraining time: 57.5206\n"
          ]
        }
      ],
      "source": [
        "model = build_deepwalk(graph, alias_nodes, node_dim=10, num_walks=10, walk_length=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdQB-GqesSXF",
        "outputId": "c7f19c07-19a7-40d1-cfb7-6d5e0119f1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building a node2vec model...\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of walks: 83430\taverage walk length: 9.9948\ttraining time: 36.7921\n"
          ]
        }
      ],
      "source": [
        "model = build_node2vec(graph, alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8PA-aRzsSXF"
      },
      "source": [
        "Let's see the node embeddings of some nodes, and cosine similarities of some edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhy3cW9JsSXG",
        "outputId": "ab77d12e-38f1-413d-ef23-6efb64eb1388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--UOvCH5qEgdNQ8lzR8QYQ : [ 0.99527234  1.4488736  -0.29352498 -1.8813608  -0.3363347  -0.2920351\n",
            " -1.7571712   0.13309774  0.86316544  0.20035091]\n",
            "-05T0q5BxB9g0RCKiGYoyQ : [ 1.7628663   1.4622574   0.22454695 -0.4967443   0.14784668 -0.4732637\n",
            "  0.6051041  -1.2409475   1.5562629   0.32209906]\n",
            "a true edge 1 2155 0.95641786\n",
            "a false edge 0 6867 0.5\n"
          ]
        }
      ],
      "source": [
        "print(index2uid[\"1\"], \":\", model.wv[\"1\"])\n",
        "print(index2uid[\"2\"], \":\", model.wv[\"2\"])\n",
        "print(\"a true edge\", train_edges[0][0], train_edges[0][1],\n",
        "      get_cosine_sim(model, train_edges[0][0], train_edges[0][1]))\n",
        "print(\"a false edge\", false_edges[0][0], false_edges[0][1],\n",
        "      get_cosine_sim(model, false_edges[0][0], false_edges[0][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u6X-qfieWAk",
        "outputId": "e070bffc-0a4c-4327-94a1-76012c3e5443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default -1.00 0.9165113211280438\n",
            "default -0.75 0.9165113211280438\n",
            "default -0.50 0.9165113211280438\n",
            "default -0.25 0.9165113211280438\n",
            "default 0.00 0.9166515269556661\n",
            "default 0.25 0.9196488930852922\n",
            "default 0.50 0.9241318296665744\n",
            "default 0.75 0.9119706695226429\n",
            "default 1.00 0.8442588624999343\n"
          ]
        }
      ],
      "source": [
        "#default similarity score 0.5 is the best\n",
        "for d in np.linspace(-1.0, 1.0, num=9):\n",
        "    print('default %.2f' % d, get_auc_score(model, valid_edges, false_edges, default=d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8u5mrzasSXG"
      },
      "source": [
        "#Link Prediction (baseline)\n",
        "\n",
        "Train the model with different parameters (GridSearch) and test the model on the validation set. \n",
        "\n",
        "The best setting is\n",
        "num_walks = 10,\n",
        "walk_length = 20,\n",
        "node_dim = 10,\n",
        "iter = 10,\n",
        "p = q = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpBS-QzEsSXH",
        "outputId": "2184feb3-603e-4b8e-fcc3-02c63e369b14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node dim: 10,\tnum_walks: 5,\twalk_length: 10\n",
            "building a DeepWalk model...\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of walks: 41715\taverage walk length: 9.8874\ttraining time: 18.2179\n",
            "auc: 0.9038\n",
            "node dim: 10,\tnum_walks: 5,\twalk_length: 20\n",
            "building a DeepWalk model...\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of walks: 41715\taverage walk length: 19.7406\ttraining time: 28.6991\n",
            "auc: 0.9234\n",
            "node dim: 10,\tnum_walks: 10,\twalk_length: 10\n",
            "building a DeepWalk model...\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of walks: 83430\taverage walk length: 9.8876\ttraining time: 37.2411\n",
            "auc: 0.9232\n",
            "node dim: 10,\tnum_walks: 10,\twalk_length: 20\n",
            "building a DeepWalk model...\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of walks: 83430\taverage walk length: 19.7400\ttraining time: 56.8899\n",
            "auc: 0.9304\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "node_dim = 10\n",
        "num_walks_list = [5, 10]\n",
        "walk_length_list = [10, 20]\n",
        "# walk_length in [10, 20, 40]] for num_walks in [5, 10, 20, 40]\n",
        "\n",
        "best_model = model\n",
        "deepwalk_auc_scores = dict()\n",
        "for num_walks in num_walks_list:\n",
        "    for walk_length in walk_length_list:\n",
        "        print(\"node dim: %d,\\tnum_walks: %d,\\twalk_length: %d\" % (node_dim, num_walks, walk_length))\n",
        "        model = build_deepwalk(graph, alias_nodes, \n",
        "                       node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
        "        deepwalk_auc_scores[(node_dim, num_walks, walk_length)] = get_auc_score(model, valid_edges, false_edges)\n",
        "        print(\"auc: %.4f\" % (deepwalk_auc_scores[(node_dim, num_walks, walk_length)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi5dF0WFwZcQ"
      },
      "source": [
        "Node2Vec\n",
        "\n",
        "fixed: num_walks = 10, walk_length = 20, p = 3, q = 0.5\n",
        "\n",
        "| node_dim | word2vec iter | score | time (s)|\n",
        "|--|--|--|--|\n",
        "| 50 | 10 | 0.8620 | 75.86\n",
        "| 50 | 100 | 0.8809 | 641.x\n",
        "| 20 | 10 | 0.9200 | 67.38\n",
        "| 10 | 10 |0.9307 | 57.09\n",
        "| 8  | 10 | 0.9302 | 49.42\n",
        "|3 | 10 | 0.8918 | 44.83\n",
        "|5 | 10 | 0.9186 | 47.67\n",
        "|12 | 10 | 0.9291 | 55.23\n",
        "|15 | 10 | 0.9274 | 59.36\n",
        "| 3 | 20 | 0.8902 | 89.570\n",
        "| 5 | 20 | 0.9167 | 90.54\n",
        "| 8 | 20 | 0.9281 | 97.117\n",
        "| 10 | 20 | 0.929 | 100.317\n",
        "| 12 | 20 | 0.9287 | 123.716\n",
        "| 15 | 20 | 0.9274 | 112.20\n",
        "| 20 | 20 | 0.922 | 131.61\n",
        "|3|5|0.8918|28.97\n",
        "|5|5|0.9168|34.21\n",
        "|8|5|0.9273|25.39\n",
        "|10|5|0.9265|26.41\n",
        "|12|5|0.9237|28.29\n",
        "|15|5|0.9188|30.54\n",
        "|20|5|0.9041|33.21\n",
        "\n",
        "WANT: nearby nodes have similar embeddings </p>\n",
        "-> co-occurence should be more frequent </p>\n",
        "-> small 1/q (far), large q (near) i.e. BFS-like instead of DFS-like\n",
        "\n",
        "fixed: num_walks = 10, walk_length = 20, p = 1, q = 2\n",
        "\n",
        "| node_dim | word2vec iter | score | time (s)|\n",
        "|--|--|--|--|\n",
        "|3|5|0.8933|23.58\n",
        "|5|5|0.9176|25.21\n",
        "|8|5|0.9289|25.79\n",
        "|10|5|0.9284|27.66\n",
        "|12|5|0.9264|28.37\n",
        "|15|5|0.9214|29.85\n",
        "|20|5|0.9092|33.63\n",
        "|3|10|0.8934|49.11\n",
        "|5|10|0.9175|46.73\n",
        "|8|10|0.9306|51.80\n",
        "|10|10|0.9321|64.63\n",
        "|12|10|0.9311|56.75\n",
        "|15|10|0.9283|56.27\n",
        "|20|10|0.9211|63.25\n",
        "|3|20|0.8914|108.97\n",
        "|5|20|0.9157|91.37\n",
        "|8|20|0.9284|106.92\n",
        "|10|20|0.9301|112.85\n",
        "|12|20|0.9298|106.91\n",
        "|15|20|0.9279|111.46\n",
        "|20|20|0.9224|125.99"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GridSearch\n",
        "Record to the above table"
      ],
      "metadata": {
        "id": "GRxnxyCU1Gna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5oy5jWYsSXI",
        "outputId": "b5e8b798-537a-4798-e7ac-8b260dc1dc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_walks: 10,\twalk_length: 20,\tp: 1.00,\tq: 2.00\n",
            "number of walks: 83430\taverage walk length: 19.9819\n",
            "finish building random walks set in 49.92\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "num_walks = 10\n",
        "walk_length = 20\n",
        "\n",
        "p = 1\n",
        "q = 2\n",
        "\n",
        "node2vec_auc_scores = dict()\n",
        "print(\"num_walks: %d,\\twalk_length: %d,\\tp: %.2f,\\tq: %.2f\" % (\n",
        "    num_walks, walk_length, p, q))\n",
        "\n",
        "st = time.time()\n",
        "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
        "walks = build_node2vec_walks(graph, alias_nodes, alias_edges, num_walks=num_walks, walk_length=walk_length)\n",
        "print('finish building random walks set in %.2f' % (time.time()-st))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDVaSgn8bDrQ",
        "outputId": "15d949a0-987b-40a2-dc37-9f6e49f63106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|4|20|0.9031|69.46\n",
            "|8|20|0.9288|76.11\n",
            "|12|20|0.9294|81.65\n"
          ]
        }
      ],
      "source": [
        "iter = 20\n",
        "\n",
        "for node_dim in [4,8,12]:\n",
        "    st = time.time()\n",
        "    model = Word2Vec(walks, size=node_dim, window=3, min_count=0, sg=1, workers=os.cpu_count(), iter=iter)\n",
        "    score = node2vec_auc_scores[(node_dim, num_walks, walk_length, p, q)] = get_auc_score(model, valid_edges, false_edges)\n",
        "    print('|{}|{}|{:.4f}|{:.2f}'.format(node_dim, iter, score, time.time()-st ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7235k0KsSXL"
      },
      "source": [
        "Meaning of q and p \\\n",
        "![Meaning of q and p](https://snap.stanford.edu/node2vec/walk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCCD3xSrLGvS"
      },
      "source": [
        "#  Build Embedding Matrix (start here)\n",
        "\n",
        "Convert nodes, edges to integers or their string-alias (to be compatible input of Word2Vec), then get the embedding by Node2Vec algorithm. There is no other node information, so we rely on this algorithm to construct the embeddings. Besides, we perform negative sampling to get train and valid negative links for supervised learning, such that train_positive, train_negative, valid_positive, valid_negative, test_set are disjoint.\n",
        "\n",
        "**NOTE**: this part can be modified for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsLSSH-_y5F0",
        "outputId": "828d504f-6d8b-458a-fb3d-e6787b676b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8344 159149\n",
            "8344 259149\n",
            "number of nodes: 8343\n",
            "number of edges: 100000\n"
          ]
        }
      ],
      "source": [
        "data = \"https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Link_Prediction/data\"\n",
        "train_file = f\"{data}/train.csv\"\n",
        "valid_file = f\"{data}/valid.csv\"\n",
        "test_file = f\"{data}/test.csv\"\n",
        "\n",
        "np.random.seed(0)\n",
        "index2uid, uid2index, uid2ind, ind2uid = construct_uid_index(train_file)\n",
        "\n",
        "train_edges = load_data(train_file, uid2index)\n",
        "valid_edges = load_data(valid_file, uid2index)\n",
        "test_edges = load_test_data(test_file, uid2index)\n",
        "\n",
        "train_false_edges = generate_false_edges(train_edges+valid_edges+test_edges, len(train_edges))\n",
        "false_edges = generate_false_edges(train_edges+valid_edges+test_edges+train_false_edges, 40000-len(valid_edges))\n",
        "\n",
        "graph = construct_graph_from_edges(train_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll work with tensors"
      ],
      "metadata": {
        "id": "AKfKOYHRNf-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKGk2tH_gXNR",
        "outputId": "a833fdde-fd8b-48d3-8e8e-8a86be8761d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2155) tensor(3444)\n"
          ]
        }
      ],
      "source": [
        "def convert_str_edges_to_tensor(edges):\n",
        "    return torch.tensor([\n",
        "        [int(x[0]) for x in edges],\n",
        "        [int(x[1]) for x in edges]\n",
        "    ])\n",
        "\n",
        "train_pos_edges_T = convert_str_edges_to_tensor(train_edges)\n",
        "train_neg_edges_T = convert_str_edges_to_tensor(train_false_edges)\n",
        "\n",
        "valid_pos_edges_T = convert_str_edges_to_tensor(valid_edges)\n",
        "valid_neg_edges_T = convert_str_edges_to_tensor(false_edges)\n",
        "valid_labels = len(valid_pos_edges_T[0])*[1]+len(valid_neg_edges_T[0])*[0]\n",
        "\n",
        "test_edges_T = convert_str_edges_to_tensor(test_edges)\n",
        "\n",
        "print(train_pos_edges_T[1][0], train_pos_edges_T[1][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the best configuration for Node2Vec"
      ],
      "metadata": {
        "id": "wrWmPBdZQMLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN4VAo7KXTE_",
        "outputId": "1c6efe79-01f7-4e94-9fd5-52b53533c1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building a node2vec model...\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of walks: 83430\taverage walk length: 19.9780\ttraining time: 62.2397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9313416402964332"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "num_walks = 10\n",
        "walk_length = 20\n",
        "node_dim = 10\n",
        "iter = 10\n",
        "p, q = 1, 1\n",
        "\n",
        "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
        "node2embs = build_node2vec(graph, alias_nodes, alias_edges, \n",
        "                           node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
        "\n",
        "get_auc_score(node2embs, valid_edges, false_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store data locally"
      ],
      "metadata": {
        "id": "bq49SrLmQZZH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "uethzK9uih75"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "data = [index2uid, uid2index, uid2ind, ind2uid,\n",
        "        train_edges, valid_edges, train_false_edges, false_edges,\n",
        "        node2embs]\n",
        "\n",
        "with open('data_pickle', 'wb') as f:\n",
        "    pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UspSZbEV0p1B"
      },
      "outputs": [],
      "source": [
        "# node2embs = dict()\n",
        "# for node in index2uid.keys():\n",
        "#     try:\n",
        "#         node2embs[int(node)] = model.wv.get_vector(node)\n",
        "#     except:\n",
        "#         node2embs[int(node)] = np.array(10*[0.0])\n",
        "\n",
        "# nx.relabel_nodes(graph, lambda x: int(x), copy=False)\n",
        "# graph.add_node(0)\n",
        "# nx.classes.function.set_node_attributes(graph, node2embs, name='x')\n",
        "# G = from_networkx(graph)\n",
        "# G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QunyVlXWP9OT",
        "outputId": "5f7f0436-28dc-41ca-fed2-42d699e58bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.4148204   0.6018683  -1.0128235  -1.5625924  -0.748017   -0.36929086\n",
            " -2.756127    0.04731664  1.011351    0.39071855]\n",
            "tensor([ 1.4148,  0.6019, -1.0128, -1.5626, -0.7480, -0.3693, -2.7561,  0.0473,\n",
            "         1.0114,  0.3907])\n",
            "torch.Size([8344, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ],
      "source": [
        "embs_matrix = []\n",
        "num_nodes = len(index2uid.keys())\n",
        "\n",
        "for i in range(num_nodes):\n",
        "    try:\n",
        "        embs_matrix.append(node2embs.wv.get_vector(str(i)))\n",
        "    except:\n",
        "        embs_matrix.append(np.array(node_dim*[0.0]))\n",
        "        \n",
        "embs_matrix = torch.Tensor(embs_matrix)\n",
        "print(\n",
        "    node2embs.wv['1'],\n",
        "    embs_matrix[1],\n",
        "    embs_matrix.shape,\n",
        "    sep='\\n'\n",
        ")\n",
        "\n",
        "# from torch_geometric.utils.convert import from_networkx\n",
        "# from torch_geometric.data import Data\n",
        "# dataset = Data(x=embs_matrix, edge_index=train_edges_T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGzLS0apD9_X",
        "outputId": "a0b8a3d5-a8c2-4e35-a5ea-cbcf7d97ca64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "adj_matrix_src2tar = torch.zeros(num_nodes, num_nodes)\n",
        "adj_matrix_src2tar[train_pos_edges_T[0], train_pos_edges_T[1]] = 1\n",
        "adj_matrix_src2tar.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "IYe0WOS-pbxx"
      },
      "outputs": [],
      "source": [
        "def get_endpoints_embs(embs_matrix, edges_T, indices):\n",
        "    list_src = edges_T[0][indices]\n",
        "    list_tar = edges_T[1][indices]\n",
        "\n",
        "    embs_src = embs_matrix[list_src]\n",
        "    embs_tar = embs_matrix[list_tar]\n",
        "\n",
        "    return embs_src, embs_tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgRdJX0vEcxx"
      },
      "source": [
        "# MLP-aid\n",
        "\n",
        "NOTE: run Convert NetworkX graph to PyG graph first\n",
        "\n",
        "If cannot use PyG, have to do whole batch learning, because currently only PyG supports batch-learning for link prediction\n",
        "\n",
        "Try plain MLP first, then add SAGE-like or Attention-like layer using their definition\n",
        "\n",
        "**Usage:** you need to run 'Build Embedding Matrix' section first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "q3ddnF0nEfbp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import trange\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEH7qLkn_dz1"
      },
      "source": [
        "##Vanilla MLP\n",
        "\n",
        "We build a simple MLP to transform embedding of each node. \n",
        "\n",
        "Theoretically, only pushing node embedding through a MLP w/o any message passing from neighbors (~ simple as a unary function) would not help, because it does not enrich the embedding spaces. Thus, we need later employ GraphSAGE mechanism.\n",
        "\n",
        "About non-linear activation functions, we should not use common `ReLU` as it will destroy the cosine similarity (experimented, poor results). We have to use other activation functions, such as `tanh`.\n",
        "\n",
        "Also, increasing the model size and alternating the cosine similarity decoder by l2-norm or sigmoid function seems decrease the model performance (experimented, but not the main focus hence not save result here)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "S_50uaVwE_41"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module): #on top of Node embeddings\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, \n",
        "                 num_hidden_layers=1, dropout=0.1, device=device):\n",
        "        super(MLP, self).__init__()\n",
        "        # (linear + relu) x n\n",
        "        self.device = device\n",
        "        self.num_layers = num_hidden_layers+2\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "\n",
        "        for l in range(num_hidden_layers):\n",
        "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "\n",
        "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
        "        self.twonode_fc = nn.Linear(2*output_dim, 1)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for layer in self.layers:\n",
        "            layer.reset_parameters()\n",
        "        self.twonode_fc.reset_parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        for i in range(self.num_layers-1):\n",
        "            x = self.layers[i](x)\n",
        "            x = torch.tanh(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.layers[-1](x)       \n",
        "\n",
        "        return x\n",
        "\n",
        "    def decode(self, uv, metric='cosine'):\n",
        "        u, v = uv\n",
        "        assert u.shape == v.shape, \"Tensors u and v must have the same 2d shape\"\n",
        "\n",
        "        u = F.normalize(self.forward(u))\n",
        "        v = F.normalize(self.forward(v))\n",
        "\n",
        "        if metric == 'cosine':\n",
        "            return (u*v).sum(dim=1)\n",
        "        elif metric == 'l2':\n",
        "            return ((u-v)**2).sum(dim=1)\n",
        "        elif metric == 'fc':\n",
        "            temp = self.twonode_fc(torch.cat((u,v), dim=1))\n",
        "            return torch.sigmoid(torch.squeeze(temp))\n",
        "        else:\n",
        "            raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up parameters"
      ],
      "metadata": {
        "id": "Dc4P7OXDSJ8s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "RLf0rNz-dsNU"
      },
      "outputs": [],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 32, 'output_dim': 16,\n",
        "         'num_hidden_layers': 0, 'dropout': 0.0, 'metric': 'cosine', #cosine is better than fc, l2\n",
        "         'epochs': 10, 'batch_size': 64, # half of actual batch size\n",
        "         'weight_decay': 5e-3, 'lr': 0.001}\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model info"
      ],
      "metadata": {
        "id": "3qEmAZAYSQss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQH5xMj1xqhC",
        "outputId": "449fed15-4c9b-4e93-d594-6dc89672627a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
            "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
            "  )\n",
            "  (twonode_fc): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2353, -0.1597,  0.3606,  0.1626, -0.1959,  0.4285,  0.4892,  0.3297,\n",
              "         0.4454,  0.1652, -0.1796, -0.2148, -0.0602, -0.0049,  0.5754, -0.1031],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# build model + optimizer\n",
        "model = MLP(args.input_dim, args.hidden_dim, args.output_dim,\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "model.eval()\n",
        "model(embs_matrix[1].to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "aIi27QyRbnNR",
        "outputId": "b976fcce-a2ab-4f9f-ebdb-5ab9a94e56ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|| 1562/1562 [00:05<00:00, 282.82steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9196532827315639\n",
            "best auc 0.9196532827315639 achieved at epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 1562/1562 [00:05<00:00, 282.96steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.921544759655927\n",
            "best auc 0.921544759655927 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 1562/1562 [00:05<00:00, 286.66steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9226899040896961\n",
            "best auc 0.9226899040896961 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 1562/1562 [00:05<00:00, 286.21steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9234597456582124\n",
            "best auc 0.9234597456582124 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 1562/1562 [00:05<00:00, 285.88steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9239883707192884\n",
            "best auc 0.9239883707192884 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 1562/1562 [00:05<00:00, 285.96steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9243280620002601\n",
            "best auc 0.9243280620002601 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|| 1562/1562 [00:05<00:00, 284.49steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9245198921708615\n",
            "best auc 0.9245198921708615 achieved at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|| 1562/1562 [00:05<00:00, 286.27steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9245972698563096\n",
            "best auc 0.9245972698563096 achieved at epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|| 1562/1562 [00:05<00:00, 286.56steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.924599477822099\n",
            "best auc 0.924599477822099 achieved at epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|| 1562/1562 [00:05<00:00, 286.74steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9245486908539005\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from tqdm import trange #output the progress bar\n",
        "import math\n",
        "\n",
        "# train //refer to the above setup\n",
        "metric = args.metric   # fc, l2 are worse than cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model = None\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        pred_pos = model.decode(\n",
        "            get_endpoints_embs(embs_matrix, train_pos_edges_T, \n",
        "                               range(args.batch_size*i, args.batch_size*(i+1))\n",
        "            ),\n",
        "            metric=metric\n",
        "        )\n",
        "\n",
        "        pred_neg = model.decode(\n",
        "            get_endpoints_embs(embs_matrix, train_neg_edges_T, \n",
        "                               range(args.batch_size*i, args.batch_size*(i+1))\n",
        "            ),\n",
        "            metric=metric\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_pos = model.decode((embs_matrix[valid_pos_edges_T[0]],\n",
        "                                            embs_matrix[valid_pos_edges_T[1]]),\n",
        "                                    metric=metric)\n",
        "            pred_neg = model.decode((embs_matrix[valid_neg_edges_T[0]],\n",
        "                                            embs_matrix[valid_neg_edges_T[1]]),\n",
        "                                    metric=metric)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model = copy.deepcopy(model) //will slow down\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5xZYfj49zTS"
      },
      "source": [
        "## GraphSAGE-like MLP\n",
        "\n",
        "Based on plain MLP, we add adjacency matrix to perform message aggregation from neighbor nodes. Since the graph is small enough (< 10k nodes) to do whole-batch forwarding with message aggregation (naive, not optimized like PyTorch Geometric), we follow this direction.\n",
        "\n",
        "Results related to adjacency matrix suggests that the first column (user id) is the followees, the second column is the followers, since passing message as \"src: inbound neighbor, tar: outbound neighbor\" represents the phenomenon as when a person A follows another person B, and B follows C, then A tends to also follow C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "NN4vPfpp2J4E"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, adj_matrix_src2tar,\n",
        "                 num_hidden_layers=1, dropout=0.1, device=device):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        # (linear + relu) x n\n",
        "        self.device = device\n",
        "        self.num_blocks = num_hidden_layers+1\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.adj_matrix_src2tar = adj_matrix_src2tar\n",
        "\n",
        "        self.lin_s = nn.ModuleList()\n",
        "        self.lin_t = nn.ModuleList()\n",
        "        self.lin_st = nn.ModuleList()\n",
        "\n",
        "        if num_hidden_layers > 0:\n",
        "            self.lin_s.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.lin_t.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.lin_st.append(nn.Linear(2*hidden_dim, hidden_dim))\n",
        "\n",
        "            for l in range(num_hidden_layers-1):\n",
        "                self.lin_s.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "                self.lin_t.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "                self.lin_st.append(nn.Linear(2*hidden_dim, hidden_dim))\n",
        "\n",
        "            self.lin_s.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.lin_t.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.lin_st.append(nn.Linear(2*hidden_dim, output_dim))\n",
        "\n",
        "        else:\n",
        "            self.lin_s.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.lin_t.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.lin_st.append(nn.Linear(2*hidden_dim, output_dim))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for i in range(self.num_blocks):\n",
        "            self.lin_s[i].reset_parameters() \n",
        "            self.lin_t[i].reset_parameters() \n",
        "            self.lin_st[i].reset_parameters()\n",
        "\n",
        "    def forward(self, x, src_or_tar='src', kernel='sum'):\n",
        "        assert x.shape[0] == self.adj_matrix_src2tar.shape[0], \"in whole-batch update, x must be embs_matrix\"\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            source = self.lin_s[i](x)\n",
        "            target = self.lin_t[i](x) \n",
        "            if src_or_tar=='src':\n",
        "                # consider target as message passing to source\n",
        "                aggreg = torch.matmul(self.adj_matrix_src2tar.T, target) # .T ~ inbound, not .T ~ outbound\n",
        "                temp = torch.cat((source, aggreg), dim=1)\n",
        "                # don't use tanh()\n",
        "                x = self.lin_st[i](temp)\n",
        "            elif src_or_tar=='tar':\n",
        "                # consider source as message passing to target\n",
        "                aggreg = torch.matmul(self.adj_matrix_src2tar, source) # .T ~ inbound, not .T ~ outbound\n",
        "                temp = torch.cat((target, aggreg), dim=1)\n",
        "                # don't use tanh()\n",
        "                x = self.lin_st[i](temp)\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "\n",
        "            # x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inFL1DyiX3-5"
      },
      "source": [
        "###**Results**\n",
        "\n",
        "Fixed hyperparams in args: node_dim=10, etc.\n",
        "\n",
        "- Comparing models: to change the configuration, refer to line 51 and 56 of the above cell.\n",
        "\n",
        "|type|hidden_dim|output_dim|num_hidden_layers|auc| Achieved at epoch/total epoch\\\n",
        "|--|--|--|--|--|--|\n",
        "src<-out,tar<-out| 32 | 16 | 0 | 0.9546 | 5/5 |\n",
        "src<-out,tar<-out (*)| 32 | 16 | 1 | 0.9529 | 10/10 |\n",
        "src<-out,tar<-out| 16 | 16 | 0 | 0.9535 | 5/5 |\n",
        "src<-in, tar<-out| 32 | 16 | 0 | **0.9576** | 5/5\n",
        "src<-out, tar<-in| 32 | 16 | 0 | 0.9558 | 5/5\n",
        "src<-in, tar<-out| 32 | 16 | 0 | 0.9551 | 5/5\n",
        "src<-all, tar<-all| 32 | 16 | 0 | **0.9580** | 5/5\n",
        "\n",
        "> (*) more params to train -> more epochs for fair comparison\n",
        "\n",
        "The result suggests that increasing the size of model would not help, so we stick to the default agrs.\n",
        "\n",
        "- Comparing the best 2 models with 10 epochs, we see no difference. Thus, as the (src<-in, tar<-out) model is more simple, we choose this to give scores for the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIJ8csX8kZSq"
      },
      "source": [
        "### src: outbound neighbor, tar: outbound neighbor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FImaTCoakgao"
      },
      "source": [
        "#### default hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "3Nu5U7hQGr8y",
        "outputId": "329404b1-915d-4c16-b491-2b9f46903d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 1562/1562 [00:13<00:00, 114.40steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9561583434004182\n",
            "best auc 0.9561583434004182 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 1562/1562 [00:13<00:00, 113.41steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9566992086527947\n",
            "best auc 0.9566992086527947 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 1562/1562 [00:13<00:00, 114.62steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.956882985505999\n",
            "best auc 0.956882985505999 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 1562/1562 [00:13<00:00, 114.52steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9570083000813561\n",
            "best auc 0.9570083000813561 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 1562/1562 [00:13<00:00, 114.67steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.957101520296847\n",
            "best auc 0.957101520296847 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|| 1562/1562 [00:13<00:00, 114.39steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.957162971589606\n",
            "best auc 0.957162971589606 achieved at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|| 1562/1562 [00:13<00:00, 114.42steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572037588760068\n",
            "best auc 0.9572037588760068 achieved at epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|| 1562/1562 [00:17<00:00, 91.08steps/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572283706851428\n",
            "best auc 0.9572283706851428 achieved at epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|| 1562/1562 [00:13<00:00, 112.52steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572394455611651\n",
            "best auc 0.9572394455611651 achieved at epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|| 1562/1562 [00:13<00:00, 113.60steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572426986808287\n",
            "best auc 0.9572426986808287 achieved at epoch 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 32, 'output_dim': 16,\n",
        "         'num_hidden_layers': 0, 'dropout': 0.0, 'metric': 'cosine',\n",
        "         'epochs': 10,  'lr': 0.001, 'batch_size': 64, # half of actual batch size\n",
        "         } \n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)\n",
        "\n",
        "# build model + optimizer\n",
        "# src <- outbound neighbor, tar <- outbound neighbor\n",
        "model = GraphSAGE(args.input_dim, args.hidden_dim, args.output_dim, adj_matrix_src2tar.to(device),\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "# print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model.eval()\n",
        "# model(embs_matrix)\n",
        "\n",
        "# train\n",
        "metric = args.metric   # fc, l2 are worse then cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model = []\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "embs_matrix = embs_matrix.to(device)\n",
        "\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        indices = range(args.batch_size*i, args.batch_size*(i+1))\n",
        "        pos_u = source[train_pos_edges_T[0][indices]]\n",
        "        pos_v = target[train_pos_edges_T[1][indices]]\n",
        "        pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "        neg_u = source[train_neg_edges_T[0][indices]]\n",
        "        neg_v = target[train_neg_edges_T[1][indices]]\n",
        "        pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "            target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "            pos_u = source[valid_pos_edges_T[0]]\n",
        "            pos_v = target[valid_pos_edges_T[1]]\n",
        "            pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "            neg_u = source[valid_neg_edges_T[0]]\n",
        "            neg_v = target[valid_neg_edges_T[1]]\n",
        "            pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model = copy.deepcopy(model)\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXW2QDc_kl5J"
      },
      "source": [
        "#### 1 hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jEqscSS3aqtI",
        "outputId": "3238f8ad-4e9a-4e56-c416-78e6f9b7bf55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 1562/1562 [00:25<00:00, 61.49steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9433680168960752\n",
            "best auc 0.9433680168960752 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 1562/1562 [00:25<00:00, 61.16steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9445707486824721\n",
            "best auc 0.9445707486824721 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 1562/1562 [00:25<00:00, 60.94steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9465736490232752\n",
            "best auc 0.9465736490232752 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 1562/1562 [00:25<00:00, 60.83steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.949258634305919\n",
            "best auc 0.949258634305919 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 1562/1562 [00:25<00:00, 61.12steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9505142784153389\n",
            "best auc 0.9505142784153389 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|| 1562/1562 [00:25<00:00, 61.09steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9515822854864668\n",
            "best auc 0.9515822854864668 achieved at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|| 1562/1562 [00:25<00:00, 60.84steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9525759251656408\n",
            "best auc 0.9525759251656408 achieved at epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|| 1562/1562 [00:25<00:00, 61.00steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9533816023693886\n",
            "best auc 0.9533816023693886 achieved at epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|| 1562/1562 [00:25<00:00, 60.99steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.953843674284782\n",
            "best auc 0.953843674284782 achieved at epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|| 1562/1562 [00:25<00:00, 60.97steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9540974013466803\n",
            "best auc 0.9540974013466803 achieved at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|| 1562/1562 [00:25<00:00, 60.73steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9542127174919213\n",
            "best auc 0.9542127174919213 achieved at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|| 1562/1562 [00:25<00:00, 60.91steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.954296861766404\n",
            "best auc 0.954296861766404 achieved at epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|| 1562/1562 [00:25<00:00, 61.08steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9543600779297772\n",
            "best auc 0.9543600779297772 achieved at epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|| 1562/1562 [00:25<00:00, 61.12steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9544232239989979\n",
            "best auc 0.9544232239989979 achieved at epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|| 1562/1562 [00:25<00:00, 60.71steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.954492081489929\n",
            "best auc 0.954492081489929 achieved at epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|| 1562/1562 [00:25<00:00, 61.07steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9545595821583456\n",
            "best auc 0.9545595821583456 achieved at epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|| 1562/1562 [00:25<00:00, 61.15steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9546202361301254\n",
            "best auc 0.9546202361301254 achieved at epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|| 1562/1562 [00:25<00:00, 60.97steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9546742987482504\n",
            "best auc 0.9546742987482504 achieved at epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|| 1562/1562 [00:25<00:00, 60.85steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9547204282103818\n",
            "best auc 0.9547204282103818 achieved at epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|| 1562/1562 [00:25<00:00, 60.95steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9547514811714178\n",
            "best auc 0.9547514811714178 achieved at epoch 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 32, 'output_dim': 16,\n",
        "         'num_hidden_layers': 1, 'dropout': 0.0, 'metric': 'cosine',\n",
        "         'epochs': 20,  'lr': 0.001, 'batch_size': 64, # half of actual batch size\n",
        "         }      # 20 epochs would not help. just train 10 epochs\n",
        "\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)\n",
        "\n",
        "# build model + optimizer\n",
        "# src <- outbound neighbor, tar <- outbound neighbor\n",
        "model = GraphSAGE(args.input_dim, args.hidden_dim, args.output_dim, adj_matrix_src2tar.to(device),\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "# print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model.eval()\n",
        "# model(embs_matrix)\n",
        "\n",
        "# train\n",
        "metric = args.metric   # fc, l2 are worse then cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model = []\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "embs_matrix = embs_matrix.to(device)\n",
        "\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        indices = range(args.batch_size*i, args.batch_size*(i+1))\n",
        "        pos_u = source[train_pos_edges_T[0][indices]]\n",
        "        pos_v = target[train_pos_edges_T[1][indices]]\n",
        "        pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "        neg_u = source[train_neg_edges_T[0][indices]]\n",
        "        neg_v = target[train_neg_edges_T[1][indices]]\n",
        "        pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "            target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "            pos_u = source[valid_pos_edges_T[0]]\n",
        "            pos_v = target[valid_pos_edges_T[1]]\n",
        "            pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "            neg_u = source[valid_neg_edges_T[0]]\n",
        "            neg_v = target[valid_neg_edges_T[1]]\n",
        "            pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model = copy.deepcopy(model)\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuvTqriFkrJI"
      },
      "source": [
        "#### hidden_dim=16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "w4Gj3OnaheAq",
        "outputId": "43995a11-a91f-45ed-a34c-3278fa4f0e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 1562/1562 [00:15<00:00, 103.51steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9541032366848379\n",
            "best auc 0.9541032366848379 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 1562/1562 [00:15<00:00, 103.16steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9561645292093358\n",
            "best auc 0.9561645292093358 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 1562/1562 [00:15<00:00, 103.45steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9567672500475268\n",
            "best auc 0.9567672500475268 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 1562/1562 [00:15<00:00, 102.65steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9569469902285823\n",
            "best auc 0.9569469902285823 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 1562/1562 [00:15<00:00, 103.33steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9570518686035754\n",
            "best auc 0.9570518686035754 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|| 1562/1562 [00:15<00:00, 103.67steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.957136833980982\n",
            "best auc 0.957136833980982 achieved at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|| 1562/1562 [00:15<00:00, 103.34steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572115192999829\n",
            "best auc 0.9572115192999829 achieved at epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|| 1562/1562 [00:15<00:00, 103.52steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572739231222012\n",
            "best auc 0.9572739231222012 achieved at epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|| 1562/1562 [00:15<00:00, 103.62steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9573201339436161\n",
            "best auc 0.9573201339436161 achieved at epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|| 1562/1562 [00:15<00:00, 103.51steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9573530331345496\n",
            "best auc 0.9573530331345496 achieved at epoch 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 16, 'output_dim': 16,\n",
        "         'num_hidden_layers': 0, 'dropout': 0.0, 'metric': 'cosine',\n",
        "         'epochs': 10,  'lr': 0.001, 'batch_size': 64, # half of actual batch size\n",
        "         }\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)\n",
        "\n",
        "# build model + optimizer\n",
        "# src <- outbound neighbor, tar <- outbound neighbor\n",
        "model = GraphSAGE(args.input_dim, args.hidden_dim, args.output_dim, adj_matrix_src2tar.to(device),\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "# print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model.eval()\n",
        "# model(embs_matrix)\n",
        "\n",
        "# train\n",
        "metric = args.metric   # fc, l2 are worse then cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model = []\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "embs_matrix = embs_matrix.to(device)\n",
        "\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        indices = range(args.batch_size*i, args.batch_size*(i+1))\n",
        "        pos_u = source[train_pos_edges_T[0][indices]]\n",
        "        pos_v = target[train_pos_edges_T[1][indices]]\n",
        "        pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "        neg_u = source[train_neg_edges_T[0][indices]]\n",
        "        neg_v = target[train_neg_edges_T[1][indices]]\n",
        "        pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "            target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "            pos_u = source[valid_pos_edges_T[0]]\n",
        "            pos_v = target[valid_pos_edges_T[1]]\n",
        "            pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "            neg_u = source[valid_neg_edges_T[0]]\n",
        "            neg_v = target[valid_neg_edges_T[1]]\n",
        "            pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model = copy.deepcopy(model)\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5jOkFVBk4gB"
      },
      "source": [
        "### src: in, tar: out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "yR2-qxa3hpxd",
        "outputId": "4a9a458b-dcad-4fbb-d5ee-8cb9525db74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 1562/1562 [00:14<00:00, 111.44steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9554498204464446\n",
            "best auc 0.9554498204464446 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 1562/1562 [00:13<00:00, 112.81steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9563893023797156\n",
            "best auc 0.9563893023797156 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 1562/1562 [00:13<00:00, 112.82steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9567466811689465\n",
            "best auc 0.9567466811689465 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 1562/1562 [00:13<00:00, 113.07steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9569698559423235\n",
            "best auc 0.9569698559423235 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 1562/1562 [00:13<00:00, 112.70steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9571204544796673\n",
            "best auc 0.9571204544796673 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|| 1562/1562 [00:13<00:00, 112.62steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572219082546606\n",
            "best auc 0.9572219082546606 achieved at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|| 1562/1562 [00:13<00:00, 112.72steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572846162354314\n",
            "best auc 0.9572846162354314 achieved at epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|| 1562/1562 [00:13<00:00, 111.58steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9573200913864525\n",
            "best auc 0.9573200913864525 achieved at epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|| 1562/1562 [00:13<00:00, 112.73steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9573395450170067\n",
            "best auc 0.9573395450170067 achieved at epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|| 1562/1562 [00:13<00:00, 112.60steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9573454667211729\n",
            "best auc 0.9573454667211729 achieved at epoch 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 32, 'output_dim': 16,\n",
        "         'num_hidden_layers': 0, 'dropout': 0.0, 'metric': 'cosine',\n",
        "         'epochs': 10,  'lr': 0.001, 'batch_size': 64, # half of actual batch size\n",
        "         }\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)\n",
        "\n",
        "# build model + optimizer\n",
        "# src <- inbound neighbor, tar <- outbound neighbor\n",
        "model = GraphSAGE(args.input_dim, args.hidden_dim, args.output_dim, adj_matrix_src2tar.to(device),\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "# print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model.eval()\n",
        "# model(embs_matrix)\n",
        "\n",
        "# train\n",
        "metric = args.metric   # fc, l2 are worse then cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model = []\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "embs_matrix = embs_matrix.to(device)\n",
        "\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        indices = range(args.batch_size*i, args.batch_size*(i+1))\n",
        "        pos_u = source[train_pos_edges_T[0][indices]]\n",
        "        pos_v = target[train_pos_edges_T[1][indices]]\n",
        "        pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "        neg_u = source[train_neg_edges_T[0][indices]]\n",
        "        neg_v = target[train_neg_edges_T[1][indices]]\n",
        "        pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "            target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "            pos_u = source[valid_pos_edges_T[0]]\n",
        "            pos_v = target[valid_pos_edges_T[1]]\n",
        "            pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "            neg_u = source[valid_neg_edges_T[0]]\n",
        "            neg_v = target[valid_neg_edges_T[1]]\n",
        "            pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model = copy.deepcopy(model)\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n1gwl-Qj-Aj"
      },
      "source": [
        "Previous run's result\n",
        "\n",
        "```\n",
        "Epoch 1: 100%|| 1562/1562 [00:37<00:00, 41.44steps/s]\n",
        "auc score  0.9568289341530052\n",
        "best auc 0.9568289341530052 achieved at epoch 1\n",
        "Epoch 2: 100%|| 1562/1562 [00:40<00:00, 38.11steps/s]\n",
        "auc score  0.9577462337905177\n",
        "best auc 0.9577462337905177 achieved at epoch 2\n",
        "Epoch 3: 100%|| 1562/1562 [00:40<00:00, 38.79steps/s]\n",
        "auc score  0.9579914994869195\n",
        "best auc 0.9579914994869195 achieved at epoch 3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQlWqqqDlBJi"
      },
      "source": [
        "### src: in, tar: in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "wVdcCmmhjj6A",
        "outputId": "162b431e-3b49-44d7-bcf6-b4fbfe6636f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 1562/1562 [00:13<00:00, 112.64steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9555335616795532\n",
            "best auc 0.9555335616795532 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 1562/1562 [00:13<00:00, 112.88steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9565296546540486\n",
            "best auc 0.9565296546540486 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 1562/1562 [00:13<00:00, 112.91steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9569044305614799\n",
            "best auc 0.9569044305614799 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 1562/1562 [00:13<00:00, 112.81steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9570938512456046\n",
            "best auc 0.9570938512456046 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 1562/1562 [00:14<00:00, 111.26steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9571940383191361\n",
            "best auc 0.9571940383191361 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 32, 'output_dim': 16,\n",
        "         'num_hidden_layers': 0, 'dropout': 0.0, 'metric': 'cosine',\n",
        "         'epochs': 5,  'lr': 0.001, 'batch_size': 64, # half of actual batch size\n",
        "         }\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)\n",
        "\n",
        "# build model + optimizer\n",
        "# src <- outbound neighbor, tar <- bound neighbor\n",
        "model = GraphSAGE(args.input_dim, args.hidden_dim, args.output_dim, adj_matrix_src2tar.to(device),\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "# print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model.eval()\n",
        "# model(embs_matrix)\n",
        "\n",
        "# train\n",
        "metric = args.metric   # fc, l2 are worse then cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model = []\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "embs_matrix = embs_matrix.to(device)\n",
        "\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        indices = range(args.batch_size*i, args.batch_size*(i+1))\n",
        "        pos_u = source[train_pos_edges_T[0][indices]]\n",
        "        pos_v = target[train_pos_edges_T[1][indices]]\n",
        "        pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "        neg_u = source[train_neg_edges_T[0][indices]]\n",
        "        neg_v = target[train_neg_edges_T[1][indices]]\n",
        "        pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "            target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "            pos_u = source[valid_pos_edges_T[0]]\n",
        "            pos_v = target[valid_pos_edges_T[1]]\n",
        "            pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "            neg_u = source[valid_neg_edges_T[0]]\n",
        "            neg_v = target[valid_neg_edges_T[1]]\n",
        "            pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model = copy.deepcopy(model)\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UzOz4QklP7z"
      },
      "source": [
        "### src: out, tar: in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "55-1FrCAlZH5",
        "outputId": "9cd8cdf5-52c5-4bd6-cdd2-4d12e22f49d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 1562/1562 [00:13<00:00, 112.27steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9554006381336555\n",
            "best auc 0.9554006381336555 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 1562/1562 [00:13<00:00, 112.65steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9564494606857058\n",
            "best auc 0.9564494606857058 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 1562/1562 [00:13<00:00, 112.68steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9568222326513978\n",
            "best auc 0.9568222326513978 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 1562/1562 [00:13<00:00, 112.51steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9570002505190028\n",
            "best auc 0.9570002505190028 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 1562/1562 [00:13<00:00, 112.69steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9571071603727239\n",
            "best auc 0.9571071603727239 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcyklEQVR4nO3dfXBUdb7n8fe3O4EIBASSkYcAYbyoQEAeAkpZjqiLos6AD7csuKU73BVxZ5bZ3bsXd2TLAuXurWuVLnp1fEJlxnH2qhSOLtdxRkRgR7dQCYgOEBTkMhLAMYA8yoNJvvtHnzSdTifpJp10cvi8qrr6nN/5nXO+faA/5+T06dPm7oiISHhFcl2AiIi0LQW9iEjIKehFREJOQS8iEnIKehGRkMvLdQHJioqKvLS0NNdliIh0Khs2bNjv7sWppnW4oC8tLaWioiLXZYiIdCpm9uempunUjYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJyCXkQk5BT0IiIh1+Guo5d25B57kPxMiraWnsm8f9aWleKZ+qdWLCP+TMPa6pcfrzOh7azH0+3T2mWkOZ5x7WlMp6n+LU1rqq72Xm6668x0uQnjPQdA+d+SbeEJ+trv4OutUFcLXnfm2WuD4fr2uoTh2oTpnjBclzRcl7SM+vnqUvStzeI6Ur2O5taRQT316xSRDsBiTyXlCvpmnTgEz/4gRys3iETBomCRM8ORSGzcoknTI2n0TRzOb9g3PhxJ0TfSRN+m1hGJ1W8WPAevBxLazuY5jfnTXsfZ1kLq19aq12XxxTb494/X2IrxVi0jsZxW1tFgmdlYRqrakpbf0rSm6uosy21qe7ST8AR9QU+Y8S8JQZYiTJsNyGjsHyNlQAbTUoZwJOf/iCIizUkr6M1sKvDPQBR43t0fSpo+BFgKFAMHgTvcvSqYVgv8Kej6pbtPy1LtDeV1hUtuapNFi4h0Zi0GvZlFgSeBKUAVsN7MVrj71oRujwC/dvcXzewa4J+AO4NpJ9x9TJbrFhGRNKVzeeVEYIe773T308ArwPSkPiOA1cHwmhTTRUQkR9IJ+oHA7oTxqqAt0SfArcHwLUChmfUNxgvMrMLMPjCzm1OtwMzmBH0qqqurMyhfRERakq0vTM0DrjKzj4GrgD1AbTBtiLuXA38DPGZmFybP7O5L3L3c3cuLi1PeN19ERM5SOh/G7gEGJYyXBG1x7r6X4IjezHoAt7n7oWDanuB5p5mtBcYCX7S6chERSUs6R/TrgWFmNtTMugAzgBWJHcysyMzqlzWf2BU4mFlvM+ta3we4Akj8EFdERNpYi0Hv7jXAXOBtoBJY5u5bzGyRmdVfKjkZ+MzMPgcuAP4xaB8OVJjZJ8Q+pH0o6WodERFpY+aN7sOQW+Xl5a7fjBURyYyZbQg+D21Ed68UEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOQU9CIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQSyvozWyqmX1mZjvM7L4U04eY2btm9qmZrTWzkoRpPzaz7cHjx9ksXkREWtZi0JtZFHgSuAEYAcw0sxFJ3R4Bfu3uo4FFwD8F8/YBFgKXAROBhWbWO3vli4hIS9I5op8I7HD3ne5+GngFmJ7UZwSwOhhekzD9euAddz/o7t8A7wBTW1+2iIikK52gHwjsThivCtoSfQLcGgzfAhSaWd8058XM5phZhZlVVFdXp1u7iIikIVsfxs4DrjKzj4GrgD1Abbozu/sSdy939/Li4uIslSQiIgB5afTZAwxKGC8J2uLcfS/BEb2Z9QBuc/dDZrYHmJw079pW1CsiIhlK54h+PTDMzIaaWRdgBrAisYOZFZlZ/bLmA0uD4beB68ysd/Ah7HVBm4iItJMWg97da4C5xAK6Eljm7lvMbJGZTQu6TQY+M7PPgQuAfwzmPQj8A7GdxXpgUdAmIiLtxNw91zU0UF5e7hUVFbkuQ0SkUzGzDe5enmqavhkrIhJyCnoRkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOQU9CIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQm5tILezKaa2WdmtsPM7ksxfbCZrTGzj83sUzO7MWgvNbMTZrYpeDyT7RcgIiLNy2upg5lFgSeBKUAVsN7MVrj71oRu9wPL3P1pMxsBvAWUBtO+cPcx2S1bRETSlc4R/URgh7vvdPfTwCvA9KQ+DvQMhnsBe7NXooiItEaLR/TAQGB3wngVcFlSnweAlWb2M6A78O8Spg01s4+BI8D97v5e8grMbA4wB2Dw4MFpFy8i7e+7776jqqqKkydP5rqUc1JBQQElJSXk5+enPU86QZ+OmcCv3P1/mdkk4CUzKwP2AYPd/YCZjQfeMLOR7n4kcWZ3XwIsASgvL/cs1SQibaCqqorCwkJKS0sxs1yXc05xdw4cOEBVVRVDhw5Ne750Tt3sAQYljJcEbYnuApYFhawDCoAidz/l7geC9g3AF8BFaVcnIh3OyZMn6du3r0I+B8yMvn37ZvzXVDpBvx4YZmZDzawLMANYkdTnS+DaoJDhxIK+2syKgw9zMbPvA8OAnRlVKCIdjkI+d85m27cY9O5eA8wF3gYqiV1ds8XMFpnZtKDb3wN3m9knwMvALHd34AfAp2a2CVgO/Ed3P5hxlSIigUOHDvHUU0+d1bw33ngjhw4darbPggULWLVq1VktP1lpaSn79+/PyrJaw2J53HGUl5d7RUVFrssQkSZUVlYyfPjwnK1/165d/PCHP2Tz5s2NptXU1JCXl62PHluvtLSUiooKioqKsrrcVP8GZrbB3ctT9dc3Y0WkU7nvvvv44osvGDNmDPfeey9r167lyiuvZNq0aYwYMQKAm2++mfHjxzNy5EiWLFkSn7f+CHvXrl0MHz6cu+++m5EjR3Lddddx4sQJAGbNmsXy5cvj/RcuXMi4ceMYNWoU27ZtA6C6upopU6YwcuRIZs+ezZAhQ1o8cl+8eDFlZWWUlZXx2GOPAXD8+HFuuukmLr30UsrKynj11Vfjr3HEiBGMHj2aefPmtXqbdZxdn4h0Og/+6xa27j3ScscMjBjQk4U/Gtnk9IceeojNmzezadMmANauXcvGjRvZvHlz/EqUpUuX0qdPH06cOMGECRO47bbb6Nu3b4PlbN++nZdffpnnnnuO22+/nddee4077rij0fqKiorYuHEjTz31FI888gjPP/88Dz74INdccw3z58/nD3/4Ay+88EKzr2nDhg388pe/5MMPP8Tdueyyy7jqqqvYuXMnAwYM4He/+x0Ahw8f5sCBA7z++uts27YNM2vxVFM6dEQvIp3exIkTG1xu+Pjjj3PppZdy+eWXs3v3brZv395onqFDhzJmTOxL++PHj2fXrl0pl33rrbc26vP+++8zY8YMAKZOnUrv3r2bre/999/nlltuoXv37vTo0YNbb72V9957j1GjRvHOO+/w85//nPfee49evXrRq1cvCgoKuOuuu/jtb39Lt27dMt0cjeiIXkTOWnNH3u2pe/fu8eG1a9eyatUq1q1bR7du3Zg8eXLKyxG7du0aH45Go/FTN031i0aj1NTUZLXuiy66iI0bN/LWW29x//33c+2117JgwQI++ugj3n33XZYvX84vfvELVq9e3ar16IheRDqVwsJCjh492uT0w4cP07t3b7p168a2bdv44IMPsl7DFVdcwbJlywBYuXIl33zzTbP9r7zySt544w2+/fZbjh8/zuuvv86VV17J3r176datG3fccQf33nsvGzdu5NixYxw+fJgbb7yRRx99lE8++aTV9eqIXkQ6lb59+3LFFVdQVlbGDTfcwE033dRg+tSpU3nmmWcYPnw4F198MZdffnnWa1i4cCEzZ87kpZdeYtKkSfTr14/CwsIm+48bN45Zs2YxceJEAGbPns3YsWN5++23uffee4lEIuTn5/P0009z9OhRpk+fzsmTJ3F3Fi9e3Op6dXmliGQk15dXdgSnTp0iGo2Sl5fHunXr+MlPfhL/cLg9ZHp5pY7oRUQy9OWXX3L77bdTV1dHly5deO6553JdUrMU9CIiGRo2bBgff/xxrstImz6MFREJOQW9iEjIKehFREJOQS8iEnIKehHpVFpzm2KAxx57jG+//TaLFXV8CnoR6VQU9JlT0ItIp5J8m2KAhx9+mAkTJjB69GgWLlwIpL4F8OOPP87evXu5+uqrufrqqxste9GiRUyYMIGysjLmzJlD/RdKJ0+eTP0XOffv309paSkAtbW1zJs3j7KyMkaPHs0TTzzRDlsgc7qOXkTO3u/vg6/+lN1l9hsFNzzU5OTk2xSvXLmS7du389FHH+HuTJs2jT/+8Y9UV1c3ugVwr169WLx4MWvWrEn5YyBz585lwYIFANx55528+eab/OhHP2qyliVLlrBr1y42bdpEXl4eBw92zB/Q0xG9iHRqK1euZOXKlYwdO5Zx48axbds2tm/fnvIWwC1Zs2YNl112GaNGjWL16tVs2bKl2f6rVq3innvuif+qVZ8+fbLymrJNR/QicvaaOfJuL+7O/PnzueeeexpNS3UL4KacPHmSn/70p1RUVDBo0CAeeOCB+O2N8/LyqKuri/frbHRELyKdSvJtiq+//nqWLl3KsWPHANizZw9ff/11ylsAp5q/Xn2AFxUVcezYsfjPCULsJwU3bNgA0KB9ypQpPPvss/H71HfUUzc6oheRTiX5NsUPP/wwlZWVTJo0CYAePXrwm9/8hh07djS6BTDAnDlzmDp1KgMGDGDNmjXx5Z5//vncfffdlJWV0a9fPyZMmBCfNm/ePG6//XaWLFnS4LbIs2fP5vPPP2f06NHk5+dz9913M3fu3HbaEunTbYpFJCO6TXHuZXqbYp26EREJOQW9iEjIKehFREJOQS8iGeton+2dS85m2yvoRSQjBQUFHDhwQGGfA+7OgQMHKCgoyGg+XV4pIhkpKSmhqqqK6urqXJdyTiooKKCkpCSjeRT0IpKR/Px8hg4dmusyJANpnboxs6lm9pmZ7TCz+1JMH2xma8zsYzP71MxuTJg2P5jvMzO7PpvFi4hIy1o8ojezKPAkMAWoAtab2Qp335rQ7X5gmbs/bWYjgLeA0mB4BjASGACsMrOL3L022y9ERERSS+eIfiKww913uvtp4BVgelIfB3oGw72AvcHwdOAVdz/l7v8G7AiWJyIi7SSdoB8I7E4YrwraEj0A3GFmVcSO5n+WwbyY2RwzqzCzCn3AIyKSXdm6vHIm8Ct3LwFuBF4ys7SX7e5L3L3c3cuLi4uzVJKIiEB6V93sAQYljJcEbYnuAqYCuPs6MysAitKcV0RE2lA6R93rgWFmNtTMuhD7cHVFUp8vgWsBzGw4UABUB/1mmFlXMxsKDAM+ylbxIiLSshaP6N29xszmAm8DUWCpu28xs0VAhbuvAP4eeM7M/o7YB7OzPPa1uS1mtgzYCtQA/0lX3IiItC/dj15EJAR0P3oRkXOYgl5EJOQU9CIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOQU9CIiIaegFxEJOQW9iEjIKehFREIuraA3s6lm9pmZ7TCz+1JMf9TMNgWPz83sUMK02oRpK7JZvIiItCyvpQ5mFgWeBKYAVcB6M1vh7lvr+7j73yX0/xkwNmERJ9x9TPZKFhGRTKRzRD8R2OHuO939NPAKML2Z/jOBl7NRnIiItF46QT8Q2J0wXhW0NWJmQ4ChwOqE5gIzqzCzD8zs5ibmmxP0qaiurk6zdBERSUe2P4ydASx399qEtiHuXg78DfCYmV2YPJO7L3H3cncvLy4uznJJIiLntnSCfg8wKGG8JGhLZQZJp23cfU/wvBNYS8Pz9yIi0sbSCfr1wDAzG2pmXYiFeaOrZ8zsEqA3sC6hrbeZdQ2Gi4ArgK3J84qISNtp8aobd68xs7nA20AUWOruW8xsEVDh7vWhPwN4xd09YfbhwLNmVkdsp/JQ4tU6IiLS9qxhLudeeXm5V1RU5LoMEZFOxcw2BJ+HNqJvxoqIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOQU9CIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIt/vBIZ/FdbR2zX6zgogt6MGJAT4b378mFxT3Ij2pfJiLnttAE/cHjpzlw/BQvrjvA6Zo6ALpEI/zV93owvH9PhvcvZET/2A6gd/cuOa5WRKT9hO4Xpmpq69i5/ziV+46wdd8RKvcdpXLfEaqPnor36dezgOH9C4MdQOwxtKg70Yhl4yWIiLS75n5hKjRH9PXyohEuuqCQiy4oZPqYgfH2/cdOUbnvSPCIhf972/dTUxfb0RXkR7j4gobhf0n/QnoW5OfqpYiIZEXojugzcaqmlh1fH6Ny31G27g12Al8d4dC338X7lPQ+Lx78I4K/Agb17kZER/8i0oGcU0f0meiaF2XkgF6MHNALxsfa3J2vjpyMH/lvDf4KeLfyLwQH//TomsfF/QobnP65pF8h3bqc05tTRDqoc/qIPhMnTtfy2V+OJpz+OcK2fUc5eqoGADMo7ds9Fv79gtM/A3oyoFcBZjr6F5G2pSP6LDivS5Qxg85nzKDz423uTtU3J+JH/ZX7jrB5zxHe+tNX8T69zsvnkn6xI/8RA3oyon9P/up7PSjIj+biZYjIOUhB3wpmxqA+3RjUpxvXj+wXbz968js+++pocOVP7PnV9bs58V0tANGIcWFx9wYf/A7vX8j3Cgty9VJEJMQU9G2gsCCf8tI+lJf2ibfV1jl/PnA8fsVP5b4jrP+3g/yfTXvjfYp6dGkQ/PrSl4hkg4K+nUQjxveLe/D94h7cNLp/vP3Qt6cbhH/lV0f41f/bxelafelLRLJDQZ9j53frwqQL+zLpwr7xtu9q69hZfTwe/lv3HeH/fl7Naxur4n30pS8RSZeCvgPKj0a4uF8hF/cr5OaxZ770VX30VIOrfir3HdWXvkSkRQr6TqS4sCvFhcX84KLieNupmlq2/+VYg2/8/mHLV7yyfne8j770JXJuSyvozWwq8M9AFHje3R9Kmv4ocHUw2g34nrufH0z7MXB/MO1/uvuL2ShcYrrmRSkb2Iuygb3ibU196WtV5V/wpC999e6WT8SMaCTpYUZe1IiYkRcxIpGGz1Fr3FbfN7aMCNEI8efYtIZt0UiEaIp11y+rUVvSeuK1JNSsnZdIYy1+YcrMosDnwBSgClgPzHT3rU30/xkw1t3/g5n1ASqAcsCBDcB4d/+mqfV11C9MhUHyl762fXWU46dqqK3zMw93amqdOndq6py6oK22NpgWtNWfLuqIkndI0ail3KGkbGuivX4HEzEjEoldWhsxw4CIxXZkBM/142b1/cAInoP2xH6J8yX2i8T7NjEfCfNZM/PV94vEln9mOc30SxyPv5YW5muinxFrg8TxM6+3/vuElrA8S9gWJPSrn9cS+6dqT1hupKk+IfsiY2u/MDUR2OHuO4OFvQJMB1IGPTATWBgMXw+84+4Hg3nfAaYCL6dfvmRLqi99tUZ94NfvFGoTdgJ1STuF2uSHO7V1ddTW0URb7Lmmri62rGDnc2Za6vXE1+eN2+qXE1tPw0fia6h/nK6pa9S3zh13Gj4Te66rC7aLe/AA99hfWPF+dSnmc8DPzOcQ/8tL2l4kxQ6GhB1UJD4t9kziTiMYrt+ZNNyZNdyxUt+WascVDI8Y0IsnZo7N+mtMJ+gHArsTxquAy1J1NLMhwFBgdTPzDkwx3xxgDsDgwYPTKEk6gkjE6KJTJW3CU+xIPNhxJO5IkncQKXdESfM59Tuf5vvF/mgL+tW1sHxiO7rE5dfWxdpj02Ntsdd2pr0u2BEGq0rqHyw3GIm3JQ4nbKtU88b7p2rnzHLrUvQhYfnxnXYwb/zfKKlOD16Ie+N11XnDZaZ6DYP7nNcm/5+y/WHsDGC5u9dmMpO7LwGWQOzUTZZrEul04qdq0I5UWi+dr1zuAQYljJcEbanMoOFpmUzmFRGRNpBO0K8HhpnZUDPrQizMVyR3MrNLgN7AuoTmt4HrzKy3mfUGrgvaRESknbR46sbda8xsLrGAjgJL3X2LmS0CKty9PvRnAK94wmU87n7QzP6B2M4CYFH9B7MiItI+dD96EZEQaO7ySt0WUUQk5BT0IiIhp6AXEQk5Bb2ISMh1uA9jzawa+HMrFlEE7M9SOdmkujKjujKjujITxrqGuHtxqgkdLuhby8wqmvrkOZdUV2ZUV2ZUV2bOtbp06kZEJOQU9CIiIRfGoF+S6wKaoLoyo7oyo7oyc07VFbpz9CIi0lAYj+hFRCSBgl5EJOQ6ZdCb2VQz+8zMdpjZfSmmdzWzV4PpH5pZaQepa5aZVZvZpuAxu53qWmpmX5vZ5iamm5k9HtT9qZmN6yB1TTazwwnba0E71TXIzNaY2VYz22Jm/yVFn3bfZmnW1e7bzMwKzOwjM/skqOvBFH3a/T2ZZl05eU8G646a2cdm9maKadndXrGfsOo8D2K3Sv4C+D7QBfgEGJHU56fAM8HwDODVDlLXLOAXOdhmPwDGAZubmH4j8HtiP1t5OfBhB6lrMvBmDrZXf2BcMFwIfJ7i37Ldt1madbX7Ngu2QY9gOB/4ELg8qU8u3pPp1JWT92Sw7v8G/Euqf69sb6/OeEQf/7Fydz8N1P9YeaLpwIvB8HLgWmv7n3xPp66ccPc/As39DsB04Nce8wFwvpn17wB15YS773P3jcHwUaCSxr913O7bLM262l2wDY4Fo/nBI/kqj3Z/T6ZZV06YWQlwE/B8E12yur06Y9Cn84Pj8T7uXgMcBvp2gLoAbgv+1F9uZoNSTM+FdGvPhUnBn96/N7OR7b3y4E/mscSOBhPldJs1UxfkYJsFpyE2AV8D77h7k9urHd+T6dQFuXlPPgb8d6CuielZ3V6dMeg7s38FSt19NPAOZ/bYktpGYvfvuBR4AnijPVduZj2A14D/6u5H2nPdzWmhrpxsM3evdfcxxH4XeqKZlbXHeluSRl3t/p40sx8CX7v7hrZeV73OGPTp/OB4vI+Z5QG9gAO5rsvdD7j7qWD0eWB8G9eUrg75I+7ufqT+T293fwvIN7Oi9li3meUTC9P/7e6/TdElJ9uspbpyuc2CdR4C1gBTkybl4j3ZYl05ek9eAUwzs13ETvFeY2a/SeqT1e3VGYM+nR8rXwH8OBj+a2C1B59q5LKupHO404idY+0IVgD/PriS5HLgsLvvy3VRZtav/rykmU0k9v+1zcMhWOcLQKW7L26iW7tvs3TqysU2M7NiMzs/GD4PmAJsS+rW7u/JdOrKxXvS3ee7e4m7lxLLidXufkdSt6xurxZ/HLyj8fR+rPwF4CUz20Hsw74ZHaSu/2xm04CaoK5ZbV0XgJm9TOxqjCIzqwIWEvtgCnd/BniL2FUkO4Bvgb/tIHX9NfATM6sBTgAz2mGHDbEjrjuBPwXndwH+BzA4obZcbLN06srFNusPvGhmUWI7lmXu/mau35Np1pWT92Qqbbm9dAsEEZGQ64ynbkREJAMKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyP1/H/h7AFqERuYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 32, 'output_dim': 16,\n",
        "         'num_hidden_layers': 0, 'dropout': 0.0, 'metric': 'cosine',\n",
        "         'epochs': 5,  'lr': 0.001, 'batch_size': 64, # half of actual batch size\n",
        "         }\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)\n",
        "\n",
        "# build model + optimizer\n",
        "# src <- outbound neighbor, tar <- bound neighbor\n",
        "model = GraphSAGE(args.input_dim, args.hidden_dim, args.output_dim, adj_matrix_src2tar.to(device),\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "# print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model.eval()\n",
        "# model(embs_matrix)\n",
        "\n",
        "# train\n",
        "metric = args.metric   # fc, l2 are worse then cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model = []\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "embs_matrix = embs_matrix.to(device)\n",
        "\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        indices = range(args.batch_size*i, args.batch_size*(i+1))\n",
        "        pos_u = source[train_pos_edges_T[0][indices]]\n",
        "        pos_v = target[train_pos_edges_T[1][indices]]\n",
        "        pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "        neg_u = source[train_neg_edges_T[0][indices]]\n",
        "        neg_v = target[train_neg_edges_T[1][indices]]\n",
        "        pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "            target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "            pos_u = source[valid_pos_edges_T[0]]\n",
        "            pos_v = target[valid_pos_edges_T[1]]\n",
        "            pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "            neg_u = source[valid_neg_edges_T[0]]\n",
        "            neg_v = target[valid_neg_edges_T[1]]\n",
        "            pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model = copy.deepcopy(model)\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvCpWz1zxW-X"
      },
      "source": [
        "### src: both in-out, tar: both in-out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE6ROhYTyBfe",
        "outputId": "8052e179-a2f7-447a-d441-efe1094ada67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "adj_matrix_src2tar_both_di = torch.zeros(num_nodes, num_nodes)\n",
        "adj_matrix_src2tar_both_di[train_pos_edges_T[0], train_pos_edges_T[1]] = 1\n",
        "adj_matrix_src2tar_both_di[train_pos_edges_T[1], train_pos_edges_T[0]] = 1\n",
        "adj_matrix_src2tar_both_di.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQmCrn1LyaO1",
        "outputId": "2c59ec30-a944-4f1d-b4ce-b845d8cdb22f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(127826.) tensor(100000.)\n"
          ]
        }
      ],
      "source": [
        "print(sum(sum(adj_matrix_src2tar_both_di)),\n",
        "      sum(sum(adj_matrix_src2tar))\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "D51McoWrxcIV",
        "outputId": "2de93e95-65cc-494d-8d5b-5081cb0a3def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 1562/1562 [00:13<00:00, 112.54steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.954902601659858\n",
            "best auc 0.954902601659858 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 1562/1562 [00:14<00:00, 111.55steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9562641718015076\n",
            "best auc 0.9562641718015076 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 1562/1562 [00:13<00:00, 112.79steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.956822819689921\n",
            "best auc 0.956822819689921 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 1562/1562 [00:13<00:00, 112.69steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9570813782415851\n",
            "best auc 0.9570813782415851 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 1562/1562 [00:13<00:00, 112.68steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572087681045154\n",
            "best auc 0.9572087681045154 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|| 1562/1562 [00:13<00:00, 112.60steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572705473377713\n",
            "best auc 0.9572705473377713 achieved at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|| 1562/1562 [00:13<00:00, 112.59steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9572998329248309\n",
            "best auc 0.9572998329248309 achieved at epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|| 1562/1562 [00:13<00:00, 112.74steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9573097174519501\n",
            "best auc 0.9573097174519501 achieved at epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|| 1562/1562 [00:14<00:00, 111.46steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9573088237515115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|| 1562/1562 [00:13<00:00, 112.38steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9573004324801669\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 32, 'output_dim': 16,\n",
        "         'num_hidden_layers': 0, 'dropout': 0.0, 'metric': 'cosine',\n",
        "         'epochs': 10,  'lr': 0.001, 'batch_size': 64, # half of actual batch size\n",
        "         }\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)\n",
        "\n",
        "# build model + optimizer\n",
        "# src <- both neighbor, tar <- both neighbor\n",
        "model = GraphSAGE(args.input_dim, args.hidden_dim, args.output_dim, adj_matrix_src2tar_both_di.to(device),\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "# print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model.eval()\n",
        "# model(embs_matrix)\n",
        "\n",
        "# train\n",
        "metric = args.metric   # fc, l2 are worse then cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model = []\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "embs_matrix = embs_matrix.to(device)\n",
        "\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        indices = range(args.batch_size*i, args.batch_size*(i+1))\n",
        "        pos_u = source[train_pos_edges_T[0][indices]]\n",
        "        pos_v = target[train_pos_edges_T[1][indices]]\n",
        "        pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "        neg_u = source[train_neg_edges_T[0][indices]]\n",
        "        neg_v = target[train_neg_edges_T[1][indices]]\n",
        "        pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "            target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "            pos_u = source[valid_pos_edges_T[0]]\n",
        "            pos_v = target[valid_pos_edges_T[1]]\n",
        "            pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "            neg_u = source[valid_neg_edges_T[0]]\n",
        "            neg_v = target[valid_neg_edges_T[1]]\n",
        "            pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model = copy.deepcopy(model)\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9weYnf0rzkI-"
      },
      "source": [
        "Previous run's result\n",
        "```\n",
        "Epoch 1: 100%|| 1562/1562 [00:38<00:00, 40.66steps/s]\n",
        "auc score  0.9575397451803705\n",
        "best auc 0.9575397451803705 achieved at epoch 1\n",
        "Epoch 2: 100%|| 1562/1562 [00:37<00:00, 41.70steps/s]\n",
        "auc score  0.9577850546856175\n",
        "best auc 0.9577850546856175 achieved at epoch 2\n",
        "Epoch 3: 100%|| 1562/1562 [00:37<00:00, 41.78steps/s]\n",
        "auc score  0.9578927042829787\n",
        "best auc 0.9578927042829787 achieved at epoch 3\n",
        "Epoch 4: 100%|| 1562/1562 [00:37<00:00, 41.54steps/s]\n",
        "auc score  0.9579827402212768\n",
        "best auc 0.9579827402212768 achieved at epoch 4\n",
        "Epoch 5: 100%|| 1562/1562 [00:37<00:00, 41.91steps/s]\n",
        "auc score  0.9580494285485385\n",
        "best auc 0.9580494285485385 achieved at epoch 5\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6ytlXnIlP1w"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Link_Prediction/data\""
      ],
      "metadata": {
        "id": "eUAd0iOT5S88"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNiETOhZTc59",
        "outputId": "02677903-a18d-4016-fb27-d4ada442ce9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.5531, -0.9839,  0.9895,  ...,  0.9646,  0.9163,  0.9823])\n"
          ]
        }
      ],
      "source": [
        "# prediction\n",
        "def get_test_scores(test_edges_T):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        u = source[test_edges_T[0]]\n",
        "        v = target[test_edges_T[1]]\n",
        "        pred = (u*v).sum(dim=1).to('cpu')\n",
        "    return pred\n",
        "\n",
        "# test_edges = load_test_data(test_file, uid2index)\n",
        "# test_edges_T = convert_str_edges_to_tensor(test_edges)\n",
        "scores = get_test_scores(test_edges_T)\n",
        "print(scores)\n",
        "\n",
        "# check the order of test_edges_T\n",
        "assert ind2uid[int(test_edges_T[0][0])] ==  'NfU0zDaTMEQ4-X9dbQWd9A'\n",
        "assert ind2uid[int(test_edges_T[1][20])] ==  'AOcBQ6FZAfeHX6P7JvwRcA'\n",
        "\n",
        "df = pd.read_csv(f'{data}/test.csv')\n",
        "df[\"score\"] = scores\n",
        "\n",
        "save_info = 'sage_src-afin_tar-afout_0.958'\n",
        "os.mkdir(f'data')\n",
        "os.mkdir(f'data/{save_info}')\n",
        "df.to_csv(f'data/{save_info}/pred.csv', index=False)\n",
        "torch.save(model.state_dict(), f'data/{save_info}/best_sage_checkpoint.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XlY1WvxdXBL",
        "outputId": "a14f571c-8e14-4e77-f18a-297a787da8bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# check the adj matrix, make sure that it is not updated by optimizer\n",
        "model.adj_matrix_src2tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-ta3C59hAwu"
      },
      "source": [
        "## GAT-like MLP\n",
        "\n",
        "From GraphSAGE-like MLP, we add two more components `key` and `query` to facilitate attention mechanism.\n",
        "\n",
        "Comparing to GraphSAGE-like MLP, this model performs worse, under the setting (src: in, tar: out) achieving AUC score 0.9372 achieved at epoch 4/5. The reason can be the lack of training data, or need more training epochs. In future work, we will address this two possible issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "EPw1g0x5hAwv"
      },
      "outputs": [],
      "source": [
        "class GAT(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, adj_matrix_src2tar,\n",
        "                 num_hidden_layers=1, dropout=0.1, device=device):\n",
        "        super(GAT, self).__init__()\n",
        "        # (linear + relu) x n\n",
        "        self.device = device\n",
        "        self.num_blocks = num_hidden_layers+1\n",
        "        self.dropout = dropout\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.adj_matrix_src2tar = adj_matrix_src2tar\n",
        "\n",
        "        self.lin_s = nn.ModuleList()\n",
        "        self.lin_t = nn.ModuleList()\n",
        "        self.lin_st = nn.ModuleList()\n",
        "        self.query = nn.ModuleList()\n",
        "        self.key = nn.ModuleList()\n",
        "\n",
        "        if num_hidden_layers > 0:\n",
        "            self.lin_s.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.lin_t.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.query.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.key.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.lin_st.append(nn.Linear(2*hidden_dim, hidden_dim))\n",
        "\n",
        "            for l in range(num_hidden_layers-1):\n",
        "                self.lin_s.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "                self.lin_t.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "                self.query.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "                self.key.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "                self.lin_st.append(nn.Linear(2*hidden_dim, hidden_dim))\n",
        "\n",
        "            self.lin_s.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.lin_t.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.query.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.key.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.lin_st.append(nn.Linear(2*hidden_dim, output_dim))\n",
        "\n",
        "        else:\n",
        "            self.lin_s.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.lin_t.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.query.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.key.append(nn.Linear(input_dim, hidden_dim))\n",
        "            self.lin_st.append(nn.Linear(2*hidden_dim, output_dim))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for i in range(self.num_blocks):\n",
        "            self.lin_s[i].reset_parameters() \n",
        "            self.lin_t[i].reset_parameters() \n",
        "            self.query[i].reset_parameters() \n",
        "            self.key[i].reset_parameters() \n",
        "            self.lin_st[i].reset_parameters()\n",
        "\n",
        "    def forward(self, x, src_or_tar='src', kernel='sum'):\n",
        "        assert x.shape[0] == self.adj_matrix_src2tar.shape[0], \\\n",
        "            \"in whole-batch update, x must be embs_matrix\"\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            source = self.lin_s[i](x)\n",
        "            target = self.lin_t[i](x)\n",
        "            query = self.query[i](x)\n",
        "            key = self.key[i](x)\n",
        "            attention_matrix = torch.matmul(query, key.T)/math.sqrt(self.hidden_dim)\n",
        "            attention_matrix = self.adj_matrix_src2tar*attention_matrix\n",
        "            attention_matrix = F.normalize(attention_matrix, p=1)\n",
        "\n",
        "            # non-edge entry in attention matrix must be set back to 0.\n",
        "            # self.adj_matrix_src2tar*attention_matrix ~ attend to focused (src or tar) node,\n",
        "            # not what I think. But what I think is not practicable\n",
        "\n",
        "            if src_or_tar=='src':\n",
        "                aggreg = torch.matmul(attention_matrix.T, target)\n",
        "                temp = torch.cat((source, aggreg), dim=1)\n",
        "                # don't use tanh()\n",
        "                x = self.lin_st[i](temp)\n",
        "            elif src_or_tar=='tar':\n",
        "                aggreg = torch.matmul(attention_matrix, source)\n",
        "                temp = torch.cat((target, aggreg), dim=1)\n",
        "                # don't use tanh()\n",
        "                x = self.lin_st[i](temp)\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "\n",
        "            # x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "1qHUsJRlhAw0",
        "outputId": "05eb62f5-018b-4e69-f59e-252f920139dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT(\n",
            "  (lin_s): ModuleList(\n",
            "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
            "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  )\n",
            "  (lin_t): ModuleList(\n",
            "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
            "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  )\n",
            "  (lin_st): ModuleList(\n",
            "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (1): Linear(in_features=64, out_features=16, bias=True)\n",
            "  )\n",
            "  (query): ModuleList(\n",
            "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
            "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  )\n",
            "  (key): ModuleList(\n",
            "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
            "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|| 390/390 [01:14<00:00,  5.24steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9242181218261446\n",
            "best auc 0.9242181218261446 achieved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|| 390/390 [01:14<00:00,  5.26steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9299696599215239\n",
            "best auc 0.9299696599215239 achieved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|| 390/390 [01:14<00:00,  5.27steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.937319781520233\n",
            "best auc 0.937319781520233 achieved at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|| 390/390 [01:14<00:00,  5.27steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.9405797053232337\n",
            "best auc 0.9405797053232337 achieved at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|| 390/390 [01:14<00:00,  5.27steps/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc score  0.945473356085044\n",
            "best auc 0.945473356085044 achieved at epoch 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args =  {'input_dim': node_dim, 'hidden_dim': 32, 'output_dim': 16,\n",
        "         'num_hidden_layers': 1, 'dropout': 0.0, 'metric': 'cosine',\n",
        "         'epochs': 5,  'lr': 0.001, 'batch_size': 256, # half of actual batch size\n",
        "         }\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "args = objectview(args)\n",
        "\n",
        "# build model + optimizer\n",
        "model_gat = GAT(args.input_dim, args.hidden_dim, args.output_dim, adj_matrix_src2tar.to(device),\n",
        "            args.num_hidden_layers, args.dropout).to(device)\n",
        "print(model_gat)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_gat.parameters(), lr=args.lr)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# model.eval()\n",
        "# model(embs_matrix)\n",
        "\n",
        "\n",
        "from tqdm import trange\n",
        "import math\n",
        "\n",
        "# train\n",
        "metric = args.metric   # fc, l2 are worse then cosine\n",
        "losses = []\n",
        "test_aucs = []\n",
        "best_auc = 0\n",
        "best_model_gat = []\n",
        "num_train_pairs = len(train_pos_edges_T[0])\n",
        "embs_matrix = embs_matrix.to(device)\n",
        "\n",
        "# 9:28pm starting from epoch 11, train to epoch 20, let see there are an improvement\n",
        "for epoch in range(1, args.epochs+1):\n",
        "    total_loss = 0\n",
        "    model_gat.train()\n",
        "    \n",
        "    for i in trange(math.floor(num_train_pairs/args.batch_size), desc=\"Epoch {}\".format(epoch), unit=\"steps\"):\n",
        "        # list_index = args.batch_size*i:args.batch_size*(i+1)\n",
        "\n",
        "        source = F.normalize(model_gat(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model_gat(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        indices = range(args.batch_size*i, args.batch_size*(i+1))\n",
        "        pos_u = source[train_pos_edges_T[0][indices]]\n",
        "        pos_v = target[train_pos_edges_T[1][indices]]\n",
        "        pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "        neg_u = source[train_neg_edges_T[0][indices]]\n",
        "        neg_v = target[train_neg_edges_T[1][indices]]\n",
        "        pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = torch.cat((pred_pos, pred_neg), dim=0)\n",
        "        label = torch.Tensor(args.batch_size*[1]+args.batch_size*[0]).to(device)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    total_loss /= num_train_pairs\n",
        "    losses.append(total_loss*100)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        test_auc = 0\n",
        "        model_gat.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            source = F.normalize(model_gat(embs_matrix, 'src'), dim=1)\n",
        "            target = F.normalize(model_gat(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "            pos_u = source[valid_pos_edges_T[0]]\n",
        "            pos_v = target[valid_pos_edges_T[1]]\n",
        "            pred_pos = (pos_u*pos_v).sum(dim=1)\n",
        "\n",
        "            neg_u = source[valid_neg_edges_T[0]]\n",
        "            neg_v = target[valid_neg_edges_T[1]]\n",
        "            pred_neg = (neg_u*neg_v).sum(dim=1)\n",
        "        \n",
        "            pred = torch.cat((pred_pos, pred_neg), dim=0).to('cpu')\n",
        "            test_auc = roc_auc_score(valid_labels, pred)\n",
        "            test_aucs.append(test_auc)\n",
        "            print('auc score ', test_auc)\n",
        "\n",
        "        if test_auc > best_auc:\n",
        "            best_auc = test_auc\n",
        "            print('best auc {} achieved at epoch {}'.format(best_auc, epoch))\n",
        "            # best_model_gat = copy.deepcopy(model_gat)\n",
        "\n",
        "    else:\n",
        "        test_aucs.append(test_aucs[-1])\n",
        "\n",
        "plt.plot(losses, label=\"training loss\")\n",
        "plt.plot(test_aucs, label=\"test auc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ObcHqu55hAw2"
      },
      "outputs": [],
      "source": [
        "# prediction\n",
        "def get_test_scores(test_edges_T):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        source = F.normalize(model(embs_matrix, 'src'), dim=1)\n",
        "        target = F.normalize(model(embs_matrix, 'tar'), dim=1)\n",
        "\n",
        "        u = source[test_edges_T[0]]\n",
        "        v = target[test_edges_T[1]]\n",
        "        pred = (u*v).sum(dim=1).to('cpu')\n",
        "    return pred\n",
        "\n",
        "test_edges = load_test_data(test_file, uid2index)\n",
        "test_edges_T = convert_str_edges_to_tensor(test_edges)\n",
        "scores = get_test_scores(test_edges_T)\n",
        "\n",
        "# check the order of test_edges_T\n",
        "assert ind2uid[int(test_edges_T[0][0])] ==  'NfU0zDaTMEQ4-X9dbQWd9A'\n",
        "assert ind2uid[int(test_edges_T[1][20])] ==  'AOcBQ6FZAfeHX6P7JvwRcA'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZBNo_rnDiRp",
        "outputId": "a99d427f-8225-47d2-d96e-d3696d6689ed"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5531, -0.9839,  0.9895,  ...,  0.9646,  0.9163,  0.9823])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLOrMdqIhAw2",
        "outputId": "9c195f2f-f441-44a5-cdba-d93b1ce7c2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.5531, -0.9839,  0.9895,  ...,  0.9646,  0.9163,  0.9823])\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), 'data/best_gat_checkpoint.pth')\n",
        "print(scores)\n",
        "\n",
        "# why do we have negative numbers here?? it is supposed to lie b/w 0 and 1?\n",
        "# no, don't need that: \"This is possible because the implementation only requires that the y_true can be sorted according to the y_score.\"\n",
        "# https://datascience.stackexchange.com/questions/40940/why-is-sklearn-metrics-roc-auc-score-seemingly-able-to-accept-scores-on-any-sc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Legacy"
      ],
      "metadata": {
        "id": "sUCiA0Q_ETDF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2VET_UXEPvW"
      },
      "source": [
        "## GNN (compatibility issue)\n",
        "\n",
        "We apply Graph Deep Neural Network (GraphSAGE, GAT, ..), and expect an improvement. \n",
        "\n",
        "We can use [DGL](https://docs.dgl.ai/en/0.7.x/tutorials/blitz/4_link_predict.html), but we prefer PyTorch Geometric (a [sample](https://github.com/Orbifold/pyg-link-prediction/blob/main/Pokec-Pyg-Neo4j.ipynb))\n",
        "\n",
        "BIG TROUBLE: On Apr26, 2022, Google Colab environment starts with PyTorch has version 1.11.0+cu113, while PyG is not yet up to date\n",
        "\n",
        "https://datascience.stackexchange.com/questions/56694/how-to-use-graph-neural-network-to-predict-relationships-between-nodes-with-pyto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGrJAs9iLSc0",
        "outputId": "5bd0f316-9be8-4555-ee05-969502a648ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 1.10.1+cu111\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5yc0m9iuLWMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cb08d1-65d4-4c7b-fc3b-7c1f3c5158c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.10.1+cu111 in /usr/local/lib/python3.7/dist-packages (1.10.1+cu111)\n",
            "Requirement already satisfied: torchvision==0.11.2+cu111 in /usr/local/lib/python3.7/dist-packages (0.11.2+cu111)\n",
            "Requirement already satisfied: torchaudio==0.10.1 in /usr/local/lib/python3.7/dist-packages (0.10.1+rocm4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.1+cu111) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2+cu111) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.15.tar.gz (2.1 MB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl size=1790312 sha256=47d1a9a5a7065138111754fd9f313c28a7614852f1f2de20ec7f7d5123f6565a\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/68/4d/1414be5c2c622bad35364e13213180797717b6d4b8923936dc\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Using cached torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=f560191be2c3ee173631c6d557ac6feef2b9b21dfa81e871aa82b0cc55e1f35a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0.post1\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JtbOmsorcwh"
      },
      "source": [
        "## Building GNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kPrMJK8VtRd6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
        "                                    OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax, degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B0rK7wdilqo6"
      },
      "outputs": [],
      "source": [
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim, args))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim, args))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        self.emb = emb\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GAT':\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        if self.emb == True:\n",
        "            return x\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4yQB__Y0sCaC"
      },
      "outputs": [],
      "source": [
        "class GraphSage(MessagePassing):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, **kwargs):  \n",
        "        super(GraphSage, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self.lin_l = nn.Linear(in_channels, out_channels, bias=bias)\n",
        "        self.lin_r = nn.Linear(in_channels, out_channels, bias=bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        aggr = self.propagate(edge_index, x=x)\n",
        "        x = self.lin_l(x) + self.lin_r(aggr)\n",
        "        \n",
        "        # x = batch_size * emb_size\n",
        "        out = F.normalize(x, dim=1)\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return x_j\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "        # The axis along which to index number of nodes.\n",
        "        node_dim = self.node_dim # = 0 by default\n",
        "        \n",
        "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce=\"mean\")\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HWbtAnBIsmUo"
      },
      "outputs": [],
      "source": [
        "class GAT(MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, args, heads = 2,\n",
        "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
        "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = args.heads\n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.lin_l = nn.Linear(in_channels, out_channels*self.heads)\n",
        "        self.lin_r = nn.Linear(in_channels, out_channels*self.heads) # can we write code like this? pointer or data passing?\n",
        "\n",
        "        self.att_l = nn.Parameter(torch.rand(self.heads, out_channels))\n",
        "        self.att_r = nn.Parameter(torch.rand(self.heads, out_channels))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
        "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
        "        nn.init.xavier_uniform_(self.att_l)\n",
        "        nn.init.xavier_uniform_(self.att_r)\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        H, C = self.heads, self.out_channels\n",
        "        N = x.shape[0]\n",
        "\n",
        "        central   = self.lin_l(x).reshape((N,H,C))\n",
        "        neighbors = self.lin_r(x).reshape((N,H,C))\n",
        "        alpha_l = (central*self.att_l).sum(dim=2)    # N, H\n",
        "        alpha_r = (neighbors*self.att_r).sum(dim=2)  # N, H\n",
        "\n",
        "        aggr = self.propagate(edge_index, x=neighbors, alpha = (alpha_l, alpha_r))  # N, H, C\n",
        "        out = aggr.reshape((N,H*C))\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
        "        alpha = F.leaky_relu(alpha_i+alpha_j, self.negative_slope)      # E, H\n",
        "        alpha = torch_geometric.utils.softmax(alpha, index)\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # E, H\n",
        "        out = alpha.unsqueeze(dim=2)*x_j    # E,H,1 * E,H*C = E,H,C\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "        out = torch_scatter.scatter(inputs, index, dim=self.node_dim)    \n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fozzUxgxwKse"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kIY3vM0fwZbt"
      },
      "outputs": [],
      "source": [
        "import time, os\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import trange\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG2Abd6wHbE9"
      },
      "source": [
        "Need to retrieve subgraph to reduce the computing redundance https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.subgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ed63SZfKwKXF"
      },
      "outputs": [],
      "source": [
        "def train(dataset, args):\n",
        "    # load data\n",
        "    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    # build model + optimizer\n",
        "    model = GNNStack(dataset.num_node_features, args.hidden_dim, args.output_dim, args, embs=True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "\n",
        "    # train\n",
        "    losses = []\n",
        "    test_accs = []\n",
        "    best_acc = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        \n",
        "        for batch in loader:\n",
        "            opt.zero_grad()\n",
        "            pred = model(batch)\n",
        "            label = batch.y\n",
        "            pred = pred[batch.train_mask]\n",
        "            label = label[batch.train_mask]\n",
        "            loss = model.loss(pred, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "        total_loss /= len(loader.dataset)\n",
        "        losses.append(total_loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "          test_acc = test(test_loader, model)\n",
        "          test_accs.append(test_acc)\n",
        "          if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_model = copy.deepcopy(model)\n",
        "        else:\n",
        "          test_accs.append(test_accs[-1])\n",
        "    \n",
        "    return test_accs, losses, best_model, best_acc, test_loader\n",
        "\n",
        "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
        "    test_model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    # Note that Cora is only one graph!\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            # max(dim=1) returns values, indices tuple; only need indices\n",
        "            pred = test_model(data).max(dim=1)[1]\n",
        "            label = data.y\n",
        "\n",
        "        mask = data.val_mask if is_validation else data.test_mask\n",
        "        # node classification: only evaluate on nodes in test set\n",
        "        pred = pred[mask]\n",
        "        label = label[mask]\n",
        "\n",
        "        if save_model_preds:\n",
        "          print (\"Saving Model Predictions for Model Type\", model_type)\n",
        "\n",
        "          data = {}\n",
        "          data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
        "          data['label'] = label.view(-1).cpu().detach().numpy()\n",
        "\n",
        "          df = pd.DataFrame(data=data)\n",
        "          # Save locally as csv\n",
        "          df.to_csv('CORA-Node-' + model_type + '.csv', sep=',', index=False)\n",
        "            \n",
        "        correct += pred.eq(label).sum().item()\n",
        "\n",
        "    total = 0\n",
        "    for data in loader.dataset:\n",
        "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
        "\n",
        "    return correct / total\n",
        "  \n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipzZGXgSwPUU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    for args in [\n",
        "        {'model_type': 'GraphSage',  'num_layers': 4, 'heads': 1, 'hidden_dim': 32, 'dropout': 0.5, \n",
        "         'dataset': 'cora', 'epochs': 500, 'batch_size': 32, \n",
        "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "        for model in ['GAT']:\n",
        "            args.model_type = model\n",
        "\n",
        "            # Match the dimension.\n",
        "            if model == 'GAT':\n",
        "              args.heads = 4\n",
        "            else:\n",
        "              args.heads = 1\n",
        "\n",
        "            if args.dataset == 'cora':\n",
        "                dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
        "            else:\n",
        "                raise NotImplementedError(\"Unknown dataset\") \n",
        "            test_accs, losses, best_model, best_acc, test_loader = train(dataset, args) \n",
        "\n",
        "            print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
        "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
        "\n",
        "            # Run test for our best model to save the predictions!\n",
        "            test(test_loader, best_model, is_validation=False, save_model_preds=True, model_type=model)\n",
        "            print()\n",
        "\n",
        "            plt.title(dataset.name)\n",
        "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXALo6FDZ-41"
      },
      "source": [
        "## Further Work\n",
        "\n",
        "add GraphSAGE-like operations to function get_auc_score(model, ...)\n",
        "\n",
        "build model to train, especially the loss function\n",
        "\n",
        "calculate the distance between two test nodes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K6o_nOwaLmgB"
      },
      "outputs": [],
      "source": [
        "def visualize(h, color, epoch=None, loss=None, accuracy=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    if torch.is_tensor(h):\n",
        "        h = h.detach().cpu().numpy()\n",
        "        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "        if epoch is not None and loss is not None and accuracy['train'] is not None and accuracy['val'] is not None:\n",
        "            plt.xlabel((f'Epoch: {epoch}, Loss: {loss.item():.4f} \\n'\n",
        "                       f'Training Accuracy: {accuracy[\"train\"]*100:.2f}% \\n'\n",
        "                       f' Validation Accuracy: {accuracy[\"val\"]*100:.2f}%'),\n",
        "                       fontsize=16)\n",
        "    else:\n",
        "        nx.draw_networkx(h, pos=nx.spring_layout(h, seed=42), with_labels=False,\n",
        "                         node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "# visualize(G, color=data.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0flagjRjO5S"
      },
      "outputs": [],
      "source": [
        "# check if there are nodes in test set not existing in train set\n",
        "test_nodes = [x[0] for x in test_edges] + [x[1] for x in test_edges]\n",
        "len(set(test_nodes).difference(set(graph.nodes)))\n",
        "# there are several. For those, just ouput the prob. as .5\n",
        "\n",
        "# count how many pairs\n",
        "print(sum([(1 if '0' in pair else 0) for pair in valid_edges]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1gIl1AVkHLM"
      },
      "outputs": [],
      "source": [
        "# with those number of unknown nodes, calculate the max roc_auc_score\n",
        "ood = 196\n",
        "ground = (40000-20732)*[1]+ 20732*[0]\n",
        "pred = (40000-20732-ood)*[1]+ 2*ood*[0.5]+ (20732-ood)*[0]\n",
        "\n",
        "roc_auc_score(ground, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vCdWIjPn0T5"
      },
      "outputs": [],
      "source": [
        "first_20_nodes = list(graph.nodes)[:20]\n",
        "\n",
        "for node in first_20_nodes:\n",
        "    print(np.average(\n",
        "        list(nx.single_source_shortest_path_length(graph, node).values())\n",
        "    ))\n",
        "\n",
        "# avg shortest path length is ~ 4\n",
        "# may set the walk_length and smt accordingly\n",
        "\n",
        "## cannot get the diameter/radius, since the graph is not connected\n",
        "# graph_undir = graph.to_undirected(reciprocal=False, as_view=True)\n",
        "# nx.algorithms.distance_measures.radius(graph_undir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIe6v7rQsSXM"
      },
      "outputs": [],
      "source": [
        "# graph_undir = graph.to_undirected(reciprocal=False, as_view=True)\n",
        "\n",
        "clustering = nx.clustering(graph_undir)\n",
        "pd.Series(clustering).hist(bins=20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}