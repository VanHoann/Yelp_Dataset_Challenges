{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9F8zW3WaZNOYoQZdGydfa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26dfd27b21284d02aabdd195547235ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_608b7a7d3cfd41308d610d8f9eb89dcd",
              "IPY_MODEL_12570571bda54f30b2256761ec5baee7",
              "IPY_MODEL_669e79adc1604506abaaa9a6be290267"
            ],
            "layout": "IPY_MODEL_016e3adc108b4dc197c6d33aacc1bae1"
          }
        },
        "608b7a7d3cfd41308d610d8f9eb89dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37bc86c9d4bd414bad177a40d7e38bc8",
            "placeholder": "​",
            "style": "IPY_MODEL_4cbf6823f6b746379f4075f84fb89fb6",
            "value": "Downloading vocab.json: 100%"
          }
        },
        "12570571bda54f30b2256761ec5baee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_590f5c588a304bb79e48e122ab88ea8c",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0875503ad5de4d758cb808f19fd88e0e",
            "value": 898823
          }
        },
        "669e79adc1604506abaaa9a6be290267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47b040b07564f0eb5633abd7b3bfb64",
            "placeholder": "​",
            "style": "IPY_MODEL_468b8fbd543042a080dd21c701b96777",
            "value": " 878k/878k [00:01&lt;00:00, 942kB/s]"
          }
        },
        "016e3adc108b4dc197c6d33aacc1bae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37bc86c9d4bd414bad177a40d7e38bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbf6823f6b746379f4075f84fb89fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "590f5c588a304bb79e48e122ab88ea8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0875503ad5de4d758cb808f19fd88e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b47b040b07564f0eb5633abd7b3bfb64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468b8fbd543042a080dd21c701b96777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf57b93f2d4a44b087fd9d50115d4c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e9d8292f0694d7cb50cdea0d987f9e2",
              "IPY_MODEL_816f701e15c64fbb8f2117b6da05516f",
              "IPY_MODEL_58c7c2d52d2441169dcc2852da07214d"
            ],
            "layout": "IPY_MODEL_e1901062d9cb4cb5a4272263102cd5fd"
          }
        },
        "0e9d8292f0694d7cb50cdea0d987f9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6736e865bc32484f8fa96ddcb7020449",
            "placeholder": "​",
            "style": "IPY_MODEL_da88e048d83d4f5491a998422e0a55e9",
            "value": "Downloading merges.txt: 100%"
          }
        },
        "816f701e15c64fbb8f2117b6da05516f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe9db93861b4b8196f01f020730d624",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_163cb379242e42bd8ad6485b4868424c",
            "value": 456318
          }
        },
        "58c7c2d52d2441169dcc2852da07214d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2603017428ad4570b020823f036364b9",
            "placeholder": "​",
            "style": "IPY_MODEL_365b31bd61844d6cb94a5efaca58c7b6",
            "value": " 446k/446k [00:01&lt;00:00, 528kB/s]"
          }
        },
        "e1901062d9cb4cb5a4272263102cd5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6736e865bc32484f8fa96ddcb7020449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da88e048d83d4f5491a998422e0a55e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfe9db93861b4b8196f01f020730d624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "163cb379242e42bd8ad6485b4868424c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2603017428ad4570b020823f036364b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365b31bd61844d6cb94a5efaca58c7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a58ab656c559421f89df73e78f3c9c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5b9814e8ab84762914782f52634154a",
              "IPY_MODEL_d70267e1b0b84a3daadc7184ed210d95",
              "IPY_MODEL_0dc5e567306e44ddbe7354055f54e363"
            ],
            "layout": "IPY_MODEL_57f8d7af59724839b4d35ce3be29856a"
          }
        },
        "e5b9814e8ab84762914782f52634154a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e149840db04a3dba740e4f57a16c0f",
            "placeholder": "​",
            "style": "IPY_MODEL_92bda65ef082477799a130582d9d3ce1",
            "value": "Downloading config.json: 100%"
          }
        },
        "d70267e1b0b84a3daadc7184ed210d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e25b814f3bb4045be60e283fec5cffc",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c96a6f879854dc7b318fa6bcc55aca5",
            "value": 481
          }
        },
        "0dc5e567306e44ddbe7354055f54e363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_299709d520404d239a3bc61126536a5a",
            "placeholder": "​",
            "style": "IPY_MODEL_b1ec879d62194db7a5822e78e40b9668",
            "value": " 481/481 [00:00&lt;00:00, 14.1kB/s]"
          }
        },
        "57f8d7af59724839b4d35ce3be29856a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09e149840db04a3dba740e4f57a16c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92bda65ef082477799a130582d9d3ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e25b814f3bb4045be60e283fec5cffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c96a6f879854dc7b318fa6bcc55aca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "299709d520404d239a3bc61126536a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ec879d62194db7a5822e78e40b9668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cdb5a5e9a5040809d05e9dfd2ea20be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af824ce817704b71b40c342b1a3a62bb",
              "IPY_MODEL_1320d734690441cfa6466ffd63715a38",
              "IPY_MODEL_204cc8b1df654a8496f2028aee1a13e1"
            ],
            "layout": "IPY_MODEL_b3cc5e53ebf8429e89e6fcf4832e95eb"
          }
        },
        "af824ce817704b71b40c342b1a3a62bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa8360ffc8c04b85a9adfc67b538243c",
            "placeholder": "​",
            "style": "IPY_MODEL_30fd253189fc4f9584ba468ecc210df3",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "1320d734690441cfa6466ffd63715a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ababd4735354ca08f88b7ef6496c72a",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34b8c0818d424e6ba2eb93b2a7f988bf",
            "value": 501200538
          }
        },
        "204cc8b1df654a8496f2028aee1a13e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4c8207de2843da807596bd7fe4cb1e",
            "placeholder": "​",
            "style": "IPY_MODEL_dcf50bb6164f400baeef9c4dc7c6ce2d",
            "value": " 478M/478M [00:08&lt;00:00, 57.4MB/s]"
          }
        },
        "b3cc5e53ebf8429e89e6fcf4832e95eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8360ffc8c04b85a9adfc67b538243c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30fd253189fc4f9584ba468ecc210df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ababd4735354ca08f88b7ef6496c72a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34b8c0818d424e6ba2eb93b2a7f988bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f4c8207de2843da807596bd7fe4cb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf50bb6164f400baeef9c4dc7c6ce2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanHoann/Yelp_Dataset_Challenges/blob/main/Sentiment_Analysis/Final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "qZ1aakvS6TpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl97GFfVh6Rm",
        "outputId": "d0f1f80c-d68b-46b4-ba28-2e0e5ca51aba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  9 04:53:29 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tqdm\n",
        "!pip install -q torch\n",
        "!pip install -q transformers\n",
        "!pip install -q tensorflow-gpu\n",
        "!pip install -q nltk\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q absl-py\n",
        "!pip install -q pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z15GEO08QHi",
        "outputId": "08ab933f-257d-4297-fd55-1520748e3a8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.7 MB 37.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 50.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 16 kB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 60.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 45.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 56.5 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires keras<2.9,>=2.8.0rc0, but you have keras 2.10.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Useful link:\n",
        "* https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n"
      ],
      "metadata": {
        "id": "ShRj67MsuOvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "b10UMOpn_4rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiDiwvMC_6_V",
        "outputId": "d6c4b6bd-3833-442e-97c7-524dd6e7588f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lower(s):\n",
        "    \"\"\"\n",
        "    :param s: a string.\n",
        "    return a string with lower characters\n",
        "    Note that we allow the input to be nested string of a list.\n",
        "    e.g.\n",
        "    Input: 'Text mining is to identify useful information.'\n",
        "    Output: 'text mining is to identify useful information.'\n",
        "    \"\"\"\n",
        "    if isinstance(s, list):\n",
        "        return [lower(t) for t in s]\n",
        "    if isinstance(s, str):\n",
        "        return s.lower()\n",
        "    else:\n",
        "        raise NotImplementedError(\"unknown datatype\")\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    :param text: a doc with multiple sentences, type: str\n",
        "    return a word list, type: list\n",
        "    e.g.\n",
        "    Input: 'Text mining is to identify useful information.'\n",
        "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "def stem(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of stemmed words, type: list\n",
        "    e.g.\n",
        "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "    ### equivalent code\n",
        "    # results = list()\n",
        "    # for token in tokens:\n",
        "    #     results.append(ps.stem(token))\n",
        "    # return results\n",
        "\n",
        "    return [ps.stem(token) for token in tokens]\n",
        "\n",
        "\n",
        "def n_gram(tokens, n=1):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    :param n: the corresponding n-gram, type: int\n",
        "    return a list of n-gram tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
        "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
        "    \"\"\"\n",
        "    if n == 1:\n",
        "        return tokens\n",
        "    else:\n",
        "        results = list()\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
        "            results.append(\" \".join(tokens[i:i + n]))\n",
        "        return results\n",
        "\n",
        "\n",
        "def filter_stopwords(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of filtered tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "    ### equivalent code\n",
        "    # results = list()\n",
        "    # for token in tokens:\n",
        "    #     if token not in stopwords and not token.isnumeric():\n",
        "    #         results.append(token)\n",
        "    # return results\n",
        "\n",
        "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
        "\n",
        "\n",
        "def get_pretrained_embedding(file_path, tokenizer, embedding_dim):\n",
        "    if not os.path.exists(file_path):\n",
        "        return None\n",
        "    embeddings_index = {}\n",
        "    with open(file_path) as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "Am0Emi-qAGVl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "gctgYPMM6XwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Sentiment_Analysis/data'"
      ],
      "metadata": {
        "id": "VpazxRwyijYV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv(f\"{data}/train.csv\")[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "_WACTx_EeZyP",
        "outputId": "18e40869-6217-49d1-eaa7-8a55efa8eeda"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              business_id  cool                 date  funny  \\\n",
              "0  JCZEK7wiazoM6xiq8YeZyw     1  2018-01-16 20:13:13      1   \n",
              "1  ALn_0f-Usn3n0a9WBcjhhg     0           2018-04-10      0   \n",
              "\n",
              "                review_id  stars  \\\n",
              "0  oxj0_2jKOqQFIWEYRjWi6g      5   \n",
              "1  gZITaUSvzBUijZvNGXO_Cg      1   \n",
              "\n",
              "                                                text  useful  \\\n",
              "0  I've been here a handful of times now and I've...       1   \n",
              "1  The service was terrible. The food was just ok...       0   \n",
              "\n",
              "                  user_id  \n",
              "0  1fq-gL1i_8xKhc9VgOZDGw  \n",
              "1  wqG3PCf8ufXId2RG0oBufA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7d747bf-81a9-413f-912a-4991e6a8a754\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JCZEK7wiazoM6xiq8YeZyw</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-01-16 20:13:13</td>\n",
              "      <td>1</td>\n",
              "      <td>oxj0_2jKOqQFIWEYRjWi6g</td>\n",
              "      <td>5</td>\n",
              "      <td>I've been here a handful of times now and I've...</td>\n",
              "      <td>1</td>\n",
              "      <td>1fq-gL1i_8xKhc9VgOZDGw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALn_0f-Usn3n0a9WBcjhhg</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-10</td>\n",
              "      <td>0</td>\n",
              "      <td>gZITaUSvzBUijZvNGXO_Cg</td>\n",
              "      <td>1</td>\n",
              "      <td>The service was terrible. The food was just ok...</td>\n",
              "      <td>0</td>\n",
              "      <td>wqG3PCf8ufXId2RG0oBufA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7d747bf-81a9-413f-912a-4991e6a8a754')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7d747bf-81a9-413f-912a-4991e6a8a754 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7d747bf-81a9-413f-912a-4991e6a8a754');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "from transformers import BertTokenizer, RobertaTokenizer, XLNetTokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "mnTd-mnA611z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 mode,\n",
        "                 model_name,\n",
        "                 framework=\"pt\",\n",
        "                 max_length=256,\n",
        "                 columns=[\"cool\", \"funny\", \"useful\"],\n",
        "                 tokenizer=None,\n",
        "                 use_uncased=False):\n",
        "        self.root = root\n",
        "        self.mode = mode\n",
        "        self.data_file = pd.read_csv(os.path.join(self.root, f\"{self.mode}.csv\"))\n",
        "        self.framework = framework\n",
        "        if use_uncased:\n",
        "            self.data_file['text'] = self.data_file['text'].map(lower)\n",
        "\n",
        "        self.review_texts = None\n",
        "\n",
        "        if \"roberta\" in model_name:\n",
        "            tokenizer_base = RobertaTokenizer\n",
        "        elif \"bert\" in model_name:\n",
        "            tokenizer_base = BertTokenizer\n",
        "        elif \"xlnet\" in model_name:\n",
        "            tokenizer_base = XLNetTokenizer\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "            \n",
        "        self.tokenizer = tokenizer_base.from_pretrained(model_name)\n",
        "        self.max_length = max_length\n",
        "\n",
        "        if self.review_texts is None:\n",
        "            self.review_texts = self.data_file[\"text\"].to_list()\n",
        "        if mode != \"test\":\n",
        "            self.stars = self.data_file[\"stars\"].to_numpy()\n",
        "            self.stars -= 1  # 1~5 -> 0~4\n",
        "\n",
        "        if len(columns) == 0:\n",
        "            self.other_features = None\n",
        "            return\n",
        "\n",
        "        # normalize other features to 0~1\n",
        "        self.other_features = MinMaxScaler().fit_transform(\n",
        "            self.data_file[columns].to_numpy())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.review_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.review_texts[idx]\n",
        "        if self.mode != \"test\":\n",
        "            label = self.stars[idx]\n",
        "\n",
        "        encoded = self.tokenizer.encode_plus(text,\n",
        "                                             add_special_tokens=True,\n",
        "                                             max_length=self.max_length,\n",
        "                                             return_token_type_ids=False,\n",
        "                                             padding='max_length',\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_tensors=self.framework,\n",
        "                                             truncation=True)\n",
        "\n",
        "        data = {\n",
        "            \"input_ids\": encoded[\"input_ids\"][0],\n",
        "            \"attention_mask\": encoded[\"attention_mask\"][0]\n",
        "        }\n",
        "        if self.mode != \"test\":\n",
        "            data[\"label\"] = label\n",
        "\n",
        "        if self.other_features is not None:\n",
        "            data[\"features\"] = torch.FloatTensor(self.other_features[idx])\n",
        "        return data\n",
        "\n",
        "    def get_class_weights(self):\n",
        "        if self.mode == \"test\":\n",
        "            return None\n",
        "        return compute_class_weight('balanced',\n",
        "                                    classes=np.unique(self.stars),\n",
        "                                    y=self.stars)\n",
        "\n",
        "    def get_keras_data(self):\n",
        "        data = self.tokenizer.texts_to_sequences(self.review_texts)\n",
        "        data = [pad_sequences(data, maxlen=self.max_length), self.other_features]\n",
        "\n",
        "        return data, self.stars\n",
        "\n",
        "\n",
        "def create_dataloader(root,\n",
        "                      mode,\n",
        "                      model_name,\n",
        "                      batch_size=32,\n",
        "                      max_length=256,\n",
        "                      columns=[\"cool\", \"funny\", \"useful\"],\n",
        "                      use_uncased=False):\n",
        "    review_ds = SentimentDataset(root,\n",
        "                                 mode,\n",
        "                                 model_name,\n",
        "                                 max_length=max_length,\n",
        "                                 columns=columns,\n",
        "                                 use_uncased=use_uncased)\n",
        "\n",
        "    # shuffle the dataset if it is not test dataset\n",
        "    dataloader = torch.utils.data.DataLoader(review_ds,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=mode == \"train\")\n",
        "\n",
        "    class_weights = review_ds.get_class_weights()\n",
        "\n",
        "    return dataloader, class_weights"
      ],
      "metadata": {
        "id": "wFOGOUwl6_RI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "vcX-kduFATB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, RobertaModel, XLNetModel\n",
        "import torch\n",
        "from torch import nn\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_0BG8-KeAUeT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerSentimentAnalyzer(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_name,\n",
        "                 num_class=5,\n",
        "                 num_other_features=3,\n",
        "                 hidden_size=10,\n",
        "                 dropout_rate=0.3,\n",
        "                 use_pooled=True):\n",
        "        super().__init__()\n",
        "        self.use_pooled = use_pooled\n",
        "\n",
        "        if \"roberta\" in model_name:\n",
        "            transformer_base = RobertaModel\n",
        "        elif \"bert\" in model_name:\n",
        "            transformer_base = BertModel\n",
        "        elif \"xlnet\" in model_name:\n",
        "            transformer_base = XLNetModel\n",
        "            self.use_pooled = False  # no pooler for xlnet\n",
        "\n",
        "        self.transformer = transformer_base.from_pretrained(model_name)\n",
        "        if not self.use_pooled:\n",
        "            self.hidden = nn.Linear(self.transformer.config.hidden_size,\n",
        "                                    self.transformer.config.hidden_size)\n",
        "            nn.init.xavier_uniform_(self.hidden.weight, gain=nn.init.calculate_gain('relu'))\n",
        "\n",
        "        if num_other_features > 0:\n",
        "            self.fc1 = nn.Linear(num_other_features, hidden_size)\n",
        "            nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('relu'))\n",
        "            self.other_relu = nn.ReLU()\n",
        "            self.classifier = nn.Linear(self.transformer.config.hidden_size + hidden_size,\n",
        "                                        num_class)\n",
        "        else:\n",
        "            self.classifier = nn.Linear(self.transformer.config.hidden_size, num_class)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, other_features): \n",
        "        transformer_out = self.transformer(input_ids=input_ids,\n",
        "                                           attention_mask=attention_mask)\n",
        "        if self.use_pooled:\n",
        "            output = transformer_out[\"pooler_output\"]\n",
        "        else:\n",
        "            cls_token = transformer_out[\"last_hidden_state\"][:, 0]  # get the [CLS] token\n",
        "            output = self.hidden(cls_token)\n",
        "        dropped = self.dropout(output)  # [batch_size, 768]\n",
        "\n",
        "        if hasattr(self, \"fc1\"):\n",
        "            feat = self.fc1(other_features)  # [batch_size, num_other_features]\n",
        "            feat = self.other_relu(feat)\n",
        "            final = torch.cat([dropped, feat], axis=1)\n",
        "        else:\n",
        "            final = dropped\n",
        "        return self.classifier(final)\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def fix_transformer_stem(self, yes=True):\n",
        "        if yes:\n",
        "            for param in self.transformer.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(f'Fixed Transformer stem. Total head trainable parameters {self.count_parameters()}')\n",
        "        else:\n",
        "            for param in self.transformer.parameters():\n",
        "                param.requires_grad = True\n",
        "            print(f'Trained Transformer stem. Total head trainable parameters {self.count_parameters()}')"
      ],
      "metadata": {
        "id": "WvL9jzk2BTU9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "UIOIqu1B5uGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from absl import app\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "46uAxNW15wHd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hrWg1vKBg_7Y",
        "outputId": "0bc52be2-2cac-44dc-ed94-37abb90bda54"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Sentiment_Analysis/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert this class to `flags` later on"
      ],
      "metadata": {
        "id": "9VBoUZp0kTYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class parameters: #best set\n",
        "  model_name = 'roberta-base'\n",
        "  batch_size = 32\n",
        "  max_len = 256\n",
        "  use_pooled = True\n",
        "  other_hidden_dim = 32\n",
        "  epochs = 3\n",
        "  eval_every = 300\n",
        "  lr = 1e-05\n",
        "  dropout = 0.4\n",
        "  other_features = []\n",
        "  data_path = data\n",
        "  save_path = 'models/{}_bs{}_lr{}_drop{}_hidden{}_seed{}_lpft.pth'\n",
        "  use_uncased = 0\n",
        "  use_lpft = 1\n",
        "  lp_step = 10\n",
        "  seed = 101\n",
        "\n",
        "FLAGS = parameters"
      ],
      "metadata": {
        "id": "HROzR73PKjUR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the seed"
      ],
      "metadata": {
        "id": "ace2Fmm4lYdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = FLAGS.seed\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "hPsLbyuKCcUI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjyHk43jl8kp",
        "outputId": "0967634b-0e3a-4fcf-d99a-343a5be8863d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_train, data_val, epochs, device, criterion, \n",
        "          optimizer, scheduler, save_path, eval_every, use_lpft, lp_step):\n",
        "    step = 0\n",
        "    curr_best_val_f1_macro = 0\n",
        "    best_val_at_step = 0\n",
        "\n",
        "    if use_lpft:\n",
        "        model.fix_transformer_stem(True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_bar = tqdm(data_train,\n",
        "                         total=int(len(data_train)),\n",
        "                         desc=f\"train: {epoch + 1} / {epochs}\")\n",
        "\n",
        "        correct_num = 0\n",
        "        total_num = 0\n",
        "        running_loss = 0\n",
        "        for batch in train_bar:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            other_features = batch[\"features\"].to(device) if \"features\" in batch else None\n",
        "            label = batch[\"label\"].to(device)\n",
        "            step += 1\n",
        "            logits = model(input_ids, attention_mask, other_features)\n",
        "            predicted = torch.max(logits, dim=1)[1]\n",
        "\n",
        "            loss = criterion(logits, label)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            correct_num += (predicted == label).sum().item()\n",
        "            total_num += label.shape[0]\n",
        "\n",
        "            train_bar.set_postfix(acc=(correct_num / total_num),\n",
        "                                  loss=(running_loss / total_num))\n",
        "\n",
        "            del batch, input_ids, attention_mask, other_features, label, logits, loss, predicted\n",
        "\n",
        "            if step == lp_step and use_lpft:\n",
        "                model.fix_transformer_stem(False)\n",
        "\n",
        "            if step%eval_every == 0 or (step == lp_step and use_lpft):\n",
        "                model.eval()\n",
        "                y_pred = []\n",
        "                y_true = []\n",
        "                val_running_loss = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for batch in data_val:\n",
        "                        input_ids = batch[\"input_ids\"].to(device)\n",
        "                        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                        other_features = batch[\"features\"].to(\n",
        "                            device) if \"features\" in batch else None\n",
        "                        label = batch[\"label\"].to(device)\n",
        "\n",
        "                        logits = model(input_ids, attention_mask, other_features)\n",
        "                        predicted = torch.max(logits, dim=1)[1]\n",
        "\n",
        "                        loss = criterion(logits, label)\n",
        "                        val_running_loss += loss.item()\n",
        "\n",
        "                        y_pred.extend(predicted.tolist())\n",
        "                        y_true.extend(label.tolist())\n",
        "\n",
        "                        del batch, input_ids, attention_mask, label, logits, predicted\n",
        "                \n",
        "                report = classification_report(y_true, y_pred, output_dict=True)\n",
        "                print(\n",
        "                    f\"[valid] epoch: {epoch}, global step: {step}, loss: {val_running_loss / len(data_val)},\"\n",
        "                    f\" report:\\n{classification_report(y_true, y_pred, digits=4)}\"\n",
        "                    f\"confusion_matrix:\\n{confusion_matrix(y_true, y_pred)}\"\n",
        "                    )\n",
        "\n",
        "                if report['macro avg']['f1-score'] > curr_best_val_f1_macro:\n",
        "                    curr_best_val_f1_macro = report[\"macro avg\"]['f1-score']\n",
        "                    best_val_at_step = step\n",
        "                    model_dir, name = save_path.rsplit(\"/\", 1)\n",
        "                    # name = f\"acc{curr_best_val_f1_macro}_{name}\"\n",
        "                    os.makedirs(model_dir, exist_ok=True)\n",
        "                    torch.save(model.state_dict(), os.path.join(model_dir, name))\n",
        "\n",
        "        print(\n",
        "            f\"[train] epoch: {epoch}, global step: {step}, loss: {running_loss / total_num},\"\n",
        "            f\" accuracy: {correct_num / total_num}\")\n",
        "\n",
        "    print(f\"[finish] best valid macro avg is {curr_best_val_f1_macro}, achieved at global step {best_val_at_step}\")"
      ],
      "metadata": {
        "id": "p1q0tgh8CDVK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data\n"
      ],
      "metadata": {
        "id": "Nt5EDibPMyNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, class_weights = create_dataloader(FLAGS.data_path,\n",
        "                                                        \"train\",\n",
        "                                                        FLAGS.model_name,\n",
        "                                                        batch_size=FLAGS.batch_size,\n",
        "                                                        max_length=FLAGS.max_len,\n",
        "                                                        columns=FLAGS.other_features,\n",
        "                                                        use_uncased=FLAGS.use_uncased)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "26dfd27b21284d02aabdd195547235ed",
            "608b7a7d3cfd41308d610d8f9eb89dcd",
            "12570571bda54f30b2256761ec5baee7",
            "669e79adc1604506abaaa9a6be290267",
            "016e3adc108b4dc197c6d33aacc1bae1",
            "37bc86c9d4bd414bad177a40d7e38bc8",
            "4cbf6823f6b746379f4075f84fb89fb6",
            "590f5c588a304bb79e48e122ab88ea8c",
            "0875503ad5de4d758cb808f19fd88e0e",
            "b47b040b07564f0eb5633abd7b3bfb64",
            "468b8fbd543042a080dd21c701b96777",
            "cf57b93f2d4a44b087fd9d50115d4c2c",
            "0e9d8292f0694d7cb50cdea0d987f9e2",
            "816f701e15c64fbb8f2117b6da05516f",
            "58c7c2d52d2441169dcc2852da07214d",
            "e1901062d9cb4cb5a4272263102cd5fd",
            "6736e865bc32484f8fa96ddcb7020449",
            "da88e048d83d4f5491a998422e0a55e9",
            "cfe9db93861b4b8196f01f020730d624",
            "163cb379242e42bd8ad6485b4868424c",
            "2603017428ad4570b020823f036364b9",
            "365b31bd61844d6cb94a5efaca58c7b6",
            "a58ab656c559421f89df73e78f3c9c88",
            "e5b9814e8ab84762914782f52634154a",
            "d70267e1b0b84a3daadc7184ed210d95",
            "0dc5e567306e44ddbe7354055f54e363",
            "57f8d7af59724839b4d35ce3be29856a",
            "09e149840db04a3dba740e4f57a16c0f",
            "92bda65ef082477799a130582d9d3ce1",
            "1e25b814f3bb4045be60e283fec5cffc",
            "2c96a6f879854dc7b318fa6bcc55aca5",
            "299709d520404d239a3bc61126536a5a",
            "b1ec879d62194db7a5822e78e40b9668"
          ]
        },
        "id": "_HW5u55xJXPn",
        "outputId": "8e57e8f5-b503-41b0-9b67-7c4ad0de36dc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26dfd27b21284d02aabdd195547235ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf57b93f2d4a44b087fd9d50115d4c2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a58ab656c559421f89df73e78f3c9c88"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_weights) #balanced among #data per class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59Lv1edmQpuq",
        "outputId": "91833452-fab9-406e-9c53-bfc1914cf051"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.34730539 2.47083047 1.80995475 0.90657265 0.45506257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO5QJfz1RaOA",
        "outputId": "7562f63f-274f-4377-ebc5-710e02c125ca"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader) #an empty shell to load later on"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-ASECAgRe9w",
        "outputId": "49438366-464e-44aa-8296-6404dfc41bb8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "563"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader, _ = create_dataloader(FLAGS.data_path,\n",
        "                                          \"valid\",\n",
        "                                          FLAGS.model_name,\n",
        "                                          batch_size=FLAGS.batch_size,\n",
        "                                          max_length=FLAGS.max_len,\n",
        "                                          columns=FLAGS.other_features,\n",
        "                                          use_uncased=FLAGS.use_uncased)"
      ],
      "metadata": {
        "id": "6eQWONicR-Kz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHzBx4S2SFWY",
        "outputId": "695d2e53-ccbb-4b8d-f701-1b2e2a0ed8b0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    print(batch)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daQ51rAfljqb",
        "outputId": "a91289ee-d2e1-42f5-dfc8-c175e8f27b35"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    0,  1779,    38,  ...,     5,  1883,     2],\n",
            "        [    0, 32136,   460,  ...,     1,     1,     1],\n",
            "        [    0,   100,   393,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,  2387,   122,  ...,     1,     1,     1],\n",
            "        [    0, 40113,    77,  ...,     1,     1,     1],\n",
            "        [    0, 40907,   636,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([1, 1, 4, 4, 3, 4, 3, 4, 4, 4, 1, 4, 4, 3, 3, 2, 0, 3, 2, 1, 4, 4, 0, 2,\n",
            "        4, 0, 0, 4, 2, 4, 4, 4])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model\n",
        " "
      ],
      "metadata": {
        "id": "gSvYhV7ZSjqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerSentimentAnalyzer(FLAGS.model_name,\n",
        "                                         num_class=5,\n",
        "                                         num_other_features=len(FLAGS.other_features),\n",
        "                                         hidden_size=FLAGS.other_hidden_dim,\n",
        "                                         dropout_rate=FLAGS.dropout,\n",
        "                                         use_pooled=FLAGS.use_pooled).to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "2cdb5a5e9a5040809d05e9dfd2ea20be",
            "af824ce817704b71b40c342b1a3a62bb",
            "1320d734690441cfa6466ffd63715a38",
            "204cc8b1df654a8496f2028aee1a13e1",
            "b3cc5e53ebf8429e89e6fcf4832e95eb",
            "fa8360ffc8c04b85a9adfc67b538243c",
            "30fd253189fc4f9584ba468ecc210df3",
            "5ababd4735354ca08f88b7ef6496c72a",
            "34b8c0818d424e6ba2eb93b2a7f988bf",
            "0f4c8207de2843da807596bd7fe4cb1e",
            "dcf50bb6164f400baeef9c4dc7c6ce2d"
          ]
        },
        "id": "VTNBogIySMJz",
        "outputId": "b249a082-595f-4080-c056-bfaab3ada46b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cdb5a5e9a5040809d05e9dfd2ea20be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "4oyoBk6TUSgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(DEVICE))\n",
        "bert_optim = AdamW(model.parameters(), lr=FLAGS.lr, correct_bias=False, no_deprecation_warning=True)\n",
        "\n",
        "total_steps = len(train_dataloader) * FLAGS.epochs\n",
        "scheduler = get_linear_schedule_with_warmup(bert_optim,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "model_save_path = FLAGS.save_path.format(FLAGS.model_name, FLAGS.batch_size, FLAGS.lr,\n",
        "                                         FLAGS.dropout, FLAGS.other_hidden_dim, FLAGS.seed)\n",
        "\n",
        "print(f'Fixed Transformer stem. Total head trainable parameters {model.count_parameters()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa0-iH-2SQ7e",
        "outputId": "55f10cbc-fa3d-4173-c9fb-9301984ee00e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed Transformer stem. Total head trainable parameters 124649477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    history = train(model, train_dataloader, val_dataloader, FLAGS.epochs, DEVICE, loss_fn,\n",
        "          bert_optim, scheduler, model_save_path,\n",
        "          FLAGS.eval_every, FLAGS.use_lpft, FLAGS.lp_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmH5hMu3VVzW",
        "outputId": "1f30f7be-4e24-426f-e9cb-499e331c012f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed Transformer stem. Total head trainable parameters 3845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 1 / 3:   2%|▏         | 9/563 [00:05<04:52,  1.89it/s, acc=0.662, loss=0.0313]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Transformer stem. Total head trainable parameters 124649477\n",
            "[valid] epoch: 0, global step: 10, loss: 1.2422451963500372, report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5336    0.9858    0.6924       282\n",
            "           1     0.1622    0.0441    0.0694       136\n",
            "           2     0.3491    0.4528    0.3943       212\n",
            "           3     0.5379    0.1524    0.2375       466\n",
            "           4     0.7691    0.8805    0.8210       904\n",
            "\n",
            "    accuracy                         0.6235      2000\n",
            "   macro avg     0.4704    0.5031    0.4429      2000\n",
            "weighted avg     0.5962    0.6235    0.5706      2000\n",
            "confusion_matrix:\n",
            "[[278   0   3   1   0]\n",
            " [114   6  14   0   2]\n",
            " [ 75  18  96  10  13]\n",
            " [ 31   8 132  71 224]\n",
            " [ 23   5  30  50 796]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 1 / 3:  53%|█████▎    | 299/563 [06:41<05:37,  1.28s/it, acc=0.675, loss=0.026]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[valid] epoch: 0, global step: 300, loss: 0.8593490208898272, report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7647    0.8759    0.8165       282\n",
            "           1     0.3707    0.5588    0.4457       136\n",
            "           2     0.3858    0.4858    0.4301       212\n",
            "           3     0.5042    0.3906    0.4401       466\n",
            "           4     0.8318    0.7765    0.8032       904\n",
            "\n",
            "    accuracy                         0.6550      2000\n",
            "   macro avg     0.5714    0.6175    0.5871      2000\n",
            "weighted avg     0.6673    0.6550    0.6566      2000\n",
            "confusion_matrix:\n",
            "[[247  33   2   0   0]\n",
            " [ 43  76  16   1   0]\n",
            " [ 13  71 103  22   3]\n",
            " [  8  19 118 182 139]\n",
            " [ 12   6  28 156 702]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 1 / 3: 100%|██████████| 563/563 [12:46<00:00,  1.36s/it, acc=0.684, loss=0.0255]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] epoch: 0, global step: 563, loss: 0.025500442501571442, accuracy: 0.6841111111111111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 2 / 3:   6%|▋         | 36/563 [00:49<11:44,  1.34s/it, acc=0.738, loss=0.0224]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[valid] epoch: 1, global step: 600, loss: 0.8130658983238159, report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8750    0.7943    0.8327       282\n",
            "           1     0.4409    0.6029    0.5093       136\n",
            "           2     0.5440    0.4953    0.5185       212\n",
            "           3     0.5301    0.6245    0.5734       466\n",
            "           4     0.8480    0.7655    0.8047       904\n",
            "\n",
            "    accuracy                         0.6970      2000\n",
            "   macro avg     0.6476    0.6565    0.6477      2000\n",
            "weighted avg     0.7178    0.6970    0.7043      2000\n",
            "confusion_matrix:\n",
            "[[224  52   3   2   1]\n",
            " [ 22  82  30   1   1]\n",
            " [  3  46 105  56   2]\n",
            " [  5   2  48 291 120]\n",
            " [  2   4   7 199 692]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 2 / 3:  60%|█████▉    | 336/563 [07:45<04:51,  1.29s/it, acc=0.759, loss=0.0192]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[valid] epoch: 1, global step: 900, loss: 0.8061559413160596, report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8351    0.8262    0.8307       282\n",
            "           1     0.5124    0.4559    0.4825       136\n",
            "           2     0.5451    0.6557    0.5953       212\n",
            "           3     0.5349    0.5923    0.5621       466\n",
            "           4     0.8396    0.7699    0.8032       904\n",
            "\n",
            "    accuracy                         0.7030      2000\n",
            "   macro avg     0.6534    0.6600    0.6548      2000\n",
            "weighted avg     0.7145    0.7030    0.7071      2000\n",
            "confusion_matrix:\n",
            "[[233  36  10   1   2]\n",
            " [ 33  62  38   3   0]\n",
            " [  5  20 139  46   2]\n",
            " [  4   2  55 276 129]\n",
            " [  4   1  13 190 696]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 2 / 3: 100%|██████████| 563/563 [13:05<00:00,  1.40s/it, acc=0.763, loss=0.0189]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] epoch: 1, global step: 1126, loss: 0.01894877203471131, accuracy: 0.7631666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 3 / 3:  13%|█▎        | 73/563 [01:38<10:57,  1.34s/it, acc=0.771, loss=0.0172]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[valid] epoch: 2, global step: 1200, loss: 0.8670355441078307, report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8716    0.7943    0.8312       282\n",
            "           1     0.4611    0.6103    0.5253       136\n",
            "           2     0.5259    0.6226    0.5702       212\n",
            "           3     0.5174    0.6073    0.5587       466\n",
            "           4     0.8614    0.7290    0.7897       904\n",
            "\n",
            "    accuracy                         0.6905      2000\n",
            "   macro avg     0.6475    0.6727    0.6550      2000\n",
            "weighted avg     0.7199    0.6905    0.7005      2000\n",
            "confusion_matrix:\n",
            "[[224  52   4   1   1]\n",
            " [ 22  83  29   2   0]\n",
            " [  3  39 132  36   2]\n",
            " [  5   3  72 283 103]\n",
            " [  3   3  14 225 659]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 3 / 3:  66%|██████▋   | 373/563 [08:34<04:04,  1.29s/it, acc=0.812, loss=0.0145]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[valid] epoch: 2, global step: 1500, loss: 0.9068262179692587, report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8633    0.7837    0.8216       282\n",
            "           1     0.4702    0.5809    0.5197       136\n",
            "           2     0.5482    0.5896    0.5682       212\n",
            "           3     0.5363    0.6030    0.5677       466\n",
            "           4     0.8447    0.7699    0.8056       904\n",
            "\n",
            "    accuracy                         0.7010      2000\n",
            "   macro avg     0.6525    0.6654    0.6565      2000\n",
            "weighted avg     0.7185    0.7010    0.7078      2000\n",
            "confusion_matrix:\n",
            "[[221  52   5   1   3]\n",
            " [ 22  79  32   3   0]\n",
            " [  5  31 125  48   3]\n",
            " [  5   3  55 281 122]\n",
            " [  3   3  11 191 696]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 3 / 3: 100%|██████████| 563/563 [13:07<00:00,  1.40s/it, acc=0.821, loss=0.0138]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] epoch: 2, global step: 1689, loss: 0.013813368017474811, accuracy: 0.8207222222222222\n",
            "[finish] best valid macro avg is 0.6565424643618735, achieved at global step 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.count_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abLiy64B4ijz",
        "outputId": "ba056658-aae7-4c6c-80dc-ea0690fd0813"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124649477"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load best model"
      ],
      "metadata": {
        "id": "k1lUf98mhYa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS.save_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xzOaK9JNh0bZ",
        "outputId": "8cf9ae21-393f-47c3-a357-a51909864927"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'models/{}_bs{}_lr{}_drop{}_hidden{}_seed{}_lpft.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtXfghzuiIK0",
        "outputId": "bbccdf2a-daff-4079-9d88-18a7d6ee607d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta-base_bs32_lr1e-05_drop0.4_hidden32_seed101_lpft.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"models/roberta-base_bs32_lr1e-05_drop0.4_hidden32_seed101_lpft.pth\""
      ],
      "metadata": {
        "id": "Wfa8J6RpiZLp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_INFYphhbFQ",
        "outputId": "581e0b17-703d-4a63-d309-656ee97b28ec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "4BLAwHhsWX7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_data, device, mode=\"test\", save_name=\"pred.csv\"):\n",
        "    test_bar = tqdm(test_data, total=int(len(test_data)))\n",
        "\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    if mode == \"valid\":\n",
        "        y_true = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_bar:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            other_features = batch[\"features\"].to(device) if \"features\" in batch else None\n",
        "            logits = model(input_ids, attention_mask, other_features)\n",
        "            predicted = torch.max(logits, dim=1)[1]\n",
        "            preds.extend(predicted.tolist())\n",
        "            if mode == \"valid\":\n",
        "                y_true.extend(batch[\"label\"].tolist())\n",
        "\n",
        "    if mode == \"valid\":\n",
        "        print(classification_report(y_true, preds, digits=4))\n",
        "    else:\n",
        "        review_ids = test_data.dataset.data_file[\"review_id\"]\n",
        "        save_preds(review_ids, np.array(preds), save_name)\n",
        "\n",
        "def save_preds(review_ids, preds, save_name=\"pred.csv\"):\n",
        "    answer_df = pd.DataFrame(data={\n",
        "        'review_id': review_ids,\n",
        "        'stars': preds + 1,\n",
        "    })\n",
        "    answer_df.to_csv(save_name, index=False)"
      ],
      "metadata": {
        "id": "AiGJVjN1fkIs"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model,\n",
        "             val_dataloader,\n",
        "             DEVICE,\n",
        "             mode='valid',\n",
        "             save_name=FLAGS.save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObmenbKgcqz",
        "outputId": "b4fa6a98-457c-448c-b751-cb5cd69b3625"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:29<00:00,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8633    0.7837    0.8216       282\n",
            "           1     0.4702    0.5809    0.5197       136\n",
            "           2     0.5482    0.5896    0.5682       212\n",
            "           3     0.5363    0.6030    0.5677       466\n",
            "           4     0.8447    0.7699    0.8056       904\n",
            "\n",
            "    accuracy                         0.7010      2000\n",
            "   macro avg     0.6525    0.6654    0.6565      2000\n",
            "weighted avg     0.7185    0.7010    0.7078      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write .py scripts "
      ],
      "metadata": {
        "id": "qMFvcrHHYjsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## requirements.txt"
      ],
      "metadata": {
        "id": "zOCU-B4XbEps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "tqdm\n",
        "torch\n",
        "transformers\n",
        "tensorflow-gpu\n",
        "nltk\n",
        "scikit-learn\n",
        "absl-py\n",
        "pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwVBq_2cbHTM",
        "outputId": "8623094c-f977-4c28-8e15-608ecb4c51f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocess.py"
      ],
      "metadata": {
        "id": "ClvUTJg8aY-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile preprocess.py\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "\n",
        "\n",
        "def lower(s):\n",
        "    \"\"\"\n",
        "    :param s: a string.\n",
        "    return a string with lower characters\n",
        "    Note that we allow the input to be nested string of a list.\n",
        "    e.g.\n",
        "    Input: 'Text mining is to identify useful information.'\n",
        "    Output: 'text mining is to identify useful information.'\n",
        "    \"\"\"\n",
        "    if isinstance(s, list):\n",
        "        return [lower(t) for t in s]\n",
        "    if isinstance(s, str):\n",
        "        return s.lower()\n",
        "    else:\n",
        "        raise NotImplementedError(\"unknown datatype\")\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    :param text: a doc with multiple sentences, type: str\n",
        "    return a word list, type: list\n",
        "    e.g.\n",
        "    Input: 'Text mining is to identify useful information.'\n",
        "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "def stem(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of stemmed words, type: list\n",
        "    e.g.\n",
        "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "    ### equivalent code\n",
        "    # results = list()\n",
        "    # for token in tokens:\n",
        "    #     results.append(ps.stem(token))\n",
        "    # return results\n",
        "\n",
        "    return [ps.stem(token) for token in tokens]\n",
        "\n",
        "\n",
        "def n_gram(tokens, n=1):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    :param n: the corresponding n-gram, type: int\n",
        "    return a list of n-gram tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
        "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
        "    \"\"\"\n",
        "    if n == 1:\n",
        "        return tokens\n",
        "    else:\n",
        "        results = list()\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
        "            results.append(\" \".join(tokens[i:i + n]))\n",
        "        return results\n",
        "\n",
        "\n",
        "def filter_stopwords(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of filtered tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "    ### equivalent code\n",
        "    # results = list()\n",
        "    # for token in tokens:\n",
        "    #     if token not in stopwords and not token.isnumeric():\n",
        "    #         results.append(token)\n",
        "    # return results\n",
        "\n",
        "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
        "\n",
        "\n",
        "def get_pretrained_embedding(file_path, tokenizer, embedding_dim):\n",
        "    if not os.path.exists(file_path):\n",
        "        return None\n",
        "    embeddings_index = {}\n",
        "    with open(file_path) as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-NU1iiCYmXy",
        "outputId": "4573fd1a-0abb-46aa-c128-7c0f8511aa2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting preprocess.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset.py"
      ],
      "metadata": {
        "id": "Ws66m2ETbAPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.py\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "from transformers import BertTokenizer, RobertaTokenizer, XLNetTokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from preprocess import *\n",
        "\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 mode,\n",
        "                 model_name,\n",
        "                 framework=\"pt\",\n",
        "                 max_length=256,\n",
        "                 columns=[\"cool\", \"funny\", \"useful\"],\n",
        "                 tokenizer=None,\n",
        "                 use_uncased=False):\n",
        "        self.root = root\n",
        "        self.mode = mode\n",
        "        self.data_file = pd.read_csv(os.path.join(self.root, f\"{self.mode}.csv\"))\n",
        "        self.framework = framework\n",
        "        if use_uncased:\n",
        "            self.data_file['text'] = self.data_file['text'].map(lower)\n",
        "\n",
        "        self.review_texts = None\n",
        "        if model_name == \"lstm-cnn\":\n",
        "            self.review_texts = self.data_file[\"text\"].map(lower).map(tokenize).map(stem)\n",
        "            if mode != \"train\":\n",
        "                assert tokenizer is not None\n",
        "                assert isinstance(tokenizer, Tokenizer)\n",
        "                self.tokenizer = tokenizer\n",
        "            else:\n",
        "                self.tokenizer = Tokenizer(split=' ', oov_token=\"[OOV]\")\n",
        "                self.tokenizer.fit_on_texts(self.review_texts)\n",
        "        else:\n",
        "            if \"roberta\" in model_name:\n",
        "                tokenizer_base = RobertaTokenizer\n",
        "            elif \"bert\" in model_name:\n",
        "                tokenizer_base = BertTokenizer\n",
        "            elif \"xlnet\" in model_name:\n",
        "                tokenizer_base = XLNetTokenizer\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "            self.tokenizer = tokenizer_base.from_pretrained(model_name)\n",
        "        self.max_length = max_length\n",
        "\n",
        "        if self.review_texts is None:\n",
        "            self.review_texts = self.data_file[\"text\"].to_list()\n",
        "        if mode != \"test\":\n",
        "            self.stars = self.data_file[\"stars\"].to_numpy()\n",
        "            self.stars -= 1  # 1~5 -> 0~4\n",
        "\n",
        "        if len(columns) == 0:\n",
        "            self.other_features = None\n",
        "            return\n",
        "\n",
        "        # normalize other features to 0~1\n",
        "        self.other_features = MinMaxScaler().fit_transform(\n",
        "            self.data_file[columns].to_numpy())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.review_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.review_texts[idx]\n",
        "        if self.mode != \"test\":\n",
        "            label = self.stars[idx]\n",
        "\n",
        "        encoded = self.tokenizer.encode_plus(text,\n",
        "                                             add_special_tokens=True,\n",
        "                                             max_length=self.max_length,\n",
        "                                             return_token_type_ids=False,\n",
        "                                             padding='max_length',\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_tensors=self.framework,\n",
        "                                             truncation=True)\n",
        "\n",
        "        data = {\n",
        "            \"input_ids\": encoded[\"input_ids\"][0],\n",
        "            \"attention_mask\": encoded[\"attention_mask\"][0]\n",
        "        }\n",
        "        if self.mode != \"test\":\n",
        "            data[\"label\"] = label\n",
        "\n",
        "        if self.other_features is not None:\n",
        "            data[\"features\"] = torch.FloatTensor(self.other_features[idx])\n",
        "        return data\n",
        "\n",
        "    def get_class_weights(self):\n",
        "        if self.mode == \"test\":\n",
        "            return None\n",
        "        return compute_class_weight('balanced',\n",
        "                                    classes=np.unique(self.stars),\n",
        "                                    y=self.stars)\n",
        "\n",
        "    def get_keras_data(self):\n",
        "        data = self.tokenizer.texts_to_sequences(self.review_texts)\n",
        "        data = [pad_sequences(data, maxlen=self.max_length), self.other_features]\n",
        "\n",
        "        return data, self.stars\n",
        "\n",
        "def create_dataloader(root,\n",
        "                      mode,\n",
        "                      model_name,\n",
        "                      batch_size=32,\n",
        "                      max_length=256,\n",
        "                      columns=[\"cool\", \"funny\", \"useful\"],\n",
        "                      use_uncased=False):\n",
        "    review_ds = SentimentDataset(root,\n",
        "                                 mode,\n",
        "                                 model_name,\n",
        "                                 max_length=max_length,\n",
        "                                 columns=columns,\n",
        "                                 use_uncased=use_uncased)\n",
        "\n",
        "    # shuffle the dataset if it is not test dataset\n",
        "    dataloader = torch.utils.data.DataLoader(review_ds,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=mode == \"train\")\n",
        "\n",
        "    class_weights = review_ds.get_class_weights()\n",
        "\n",
        "    return dataloader, class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5MqyqwEa1yT",
        "outputId": "d26c21a7-c0a0-4d94-caa6-6190d3daca42"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model.py"
      ],
      "metadata": {
        "id": "tGMDsoIOdDOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "from transformers import BertModel, RobertaModel, XLNetModel\n",
        "import torch\n",
        "from torch import nn\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class TransformerSentimentAnalyzer(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_name,\n",
        "                 num_class=5,\n",
        "                 num_other_features=3,\n",
        "                 hidden_size=10,\n",
        "                 dropout_rate=0.3,\n",
        "                 use_pooled=True):\n",
        "        super().__init__()\n",
        "        self.use_pooled = use_pooled\n",
        "\n",
        "        if \"roberta\" in model_name:\n",
        "            transformer_base = RobertaModel\n",
        "        elif \"bert\" in model_name:\n",
        "            transformer_base = BertModel\n",
        "        elif \"xlnet\" in model_name:\n",
        "            transformer_base = XLNetModel\n",
        "            self.use_pooled = False  # no pooler for xlnet\n",
        "\n",
        "        self.transformer = transformer_base.from_pretrained(model_name)\n",
        "        if not self.use_pooled:\n",
        "            self.hidden = nn.Linear(self.transformer.config.hidden_size,\n",
        "                                    self.transformer.config.hidden_size)\n",
        "            nn.init.xavier_uniform_(self.hidden.weight, gain=nn.init.calculate_gain('relu'))\n",
        "\n",
        "        if num_other_features > 0:\n",
        "            self.fc1 = nn.Linear(num_other_features, hidden_size)\n",
        "            nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('relu'))\n",
        "            self.other_relu = nn.ReLU()\n",
        "            self.classifier = nn.Linear(self.transformer.config.hidden_size + hidden_size,\n",
        "                                        num_class)\n",
        "        else:\n",
        "            self.classifier = nn.Linear(self.transformer.config.hidden_size, num_class)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, other_features):\n",
        "        transformer_out = self.transformer(input_ids=input_ids,\n",
        "                                           attention_mask=attention_mask)\n",
        "        if self.use_pooled:\n",
        "            output = transformer_out[\"pooler_output\"]\n",
        "        else:\n",
        "            cls_token = transformer_out[\"last_hidden_state\"][:, 0]  # get the [CLS] token\n",
        "            output = self.hidden(cls_token)\n",
        "        dropped = self.dropout(output)  # [batch_size, 768]\n",
        "\n",
        "        if hasattr(self, \"fc1\"):\n",
        "            feat = self.fc1(other_features)  # [batch_size, num_other_features]\n",
        "            feat = self.other_relu(feat)\n",
        "            final = torch.cat([dropped, feat], axis=1)\n",
        "        else:\n",
        "            final = dropped\n",
        "        return self.classifier(final)\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def fix_transformer_stem(self, yes=True):\n",
        "        if yes:\n",
        "            for param in self.transformer.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(f'Fixed Transformer stem. Total head trainable parameters {self.count_parameters()}')\n",
        "        else:\n",
        "            for param in self.transformer.parameters():\n",
        "                param.requires_grad = True\n",
        "            print(f'Trained Transformer stem. Total head trainable parameters {self.count_parameters()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z6V-DgjdCqs",
        "outputId": "ed9ee887-45b4-4971-ec07-0894d170f050"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main.py"
      ],
      "metadata": {
        "id": "7k75C0sUc0R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from absl import flags\n",
        "from absl import app\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "from model import TransformerSentimentAnalyzer\n",
        "from dataset import create_dataloader\n",
        "\n",
        "flags.DEFINE_string(\"model_name\", \"bert-base-cased\", \"which transformer to use\")\n",
        "flags.DEFINE_integer(\"batch_size\", 16, \"batch size: 16 or 32 preferred\")\n",
        "flags.DEFINE_integer(\"max_len\", 256, \"max sentence length. max value is 512 for bert\")\n",
        "flags.DEFINE_bool(\"use_pooled\", True, \"whether to use pooled output of Bert\")\n",
        "flags.DEFINE_integer(\"other_hidden_dim\", 10, \"hidden dim for other features\")\n",
        "\n",
        "flags.DEFINE_integer(\"epochs\", 3, \"number of training epochs\")\n",
        "flags.DEFINE_integer(\"eval_every\", 50, \"number of training steps after each the model is evaluated\")\n",
        "flags.DEFINE_float(\"lr\", 2e-5, \"learning rate. Preferred 2e-5, 3e-5, 5e-5\")\n",
        "\n",
        "flags.DEFINE_float(\"dropout\", 0.3, \"dropout rate\")\n",
        "flags.DEFINE_list(\"other_features\", [],\n",
        "                  \"other feature aggregations to use\")\n",
        "\n",
        "flags.DEFINE_string(\"data_path\", \"data\", \"data directory path\")\n",
        "flags.DEFINE_string(\"save_path\", \"models/{}_bs{}_lr{}_drop{}_hidden{}_seed{}.pth\",\n",
        "                    \"where to save the model\")\n",
        "\n",
        "flags.DEFINE_integer(\"use_uncased\", 0, \"help to experiment with RoBERTa uncased\")\n",
        "flags.DEFINE_integer(\"use_lpft\", 0, \"whether to apply the method of Linear Probing and Finetuning. If True, in the lp_step steps, only train classifier head, after that finetune the whole model.\")\n",
        "flags.DEFINE_integer(\"lp_step\", 100, \"number of Linear Probing\")\n",
        "\n",
        "flags.DEFINE_integer(\"seed\", 101, \"to reproduce the experiment\")\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "#HP\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def train(model, data_train, data_val, epochs, device, criterion, \n",
        "          optimizer, scheduler, save_path, eval_every, use_lpft, lp_step):\n",
        "    step = 0\n",
        "    curr_best_val_f1_macro = 0\n",
        "    best_val_at_step = 0\n",
        "\n",
        "    if use_lpft:\n",
        "        model.fix_transformer_stem(True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_bar = tqdm(data_train,\n",
        "                         total=int(len(data_train)),\n",
        "                         desc=f\"train: {epoch + 1} / {epochs}\")\n",
        "\n",
        "        correct_num = 0\n",
        "        total_num = 0\n",
        "        running_loss = 0\n",
        "        for batch in train_bar:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            other_features = batch[\"features\"].to(device) if \"features\" in batch else None\n",
        "            label = batch[\"label\"].to(device)\n",
        "            step += 1\n",
        "            logits = model(input_ids, attention_mask, other_features)\n",
        "            predicted = torch.max(logits, dim=1)[1]\n",
        "\n",
        "            loss = criterion(logits, label)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            correct_num += (predicted == label).sum().item()\n",
        "            total_num += label.shape[0]\n",
        "\n",
        "            train_bar.set_postfix(acc=(correct_num / total_num),\n",
        "                                  loss=(running_loss / total_num))\n",
        "\n",
        "            del batch, input_ids, attention_mask, other_features, label, logits, loss, predicted\n",
        "\n",
        "            if step == lp_step and use_lpft:\n",
        "                model.fix_transformer_stem(False)\n",
        "\n",
        "            if step%eval_every == 0 or (step == lp_step and use_lpft):\n",
        "                model.eval()\n",
        "                y_pred = []\n",
        "                y_true = []\n",
        "                val_running_loss = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for batch in data_val:\n",
        "                        input_ids = batch[\"input_ids\"].to(device)\n",
        "                        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                        other_features = batch[\"features\"].to(\n",
        "                            device) if \"features\" in batch else None\n",
        "                        label = batch[\"label\"].to(device)\n",
        "\n",
        "                        logits = model(input_ids, attention_mask, other_features)\n",
        "                        predicted = torch.max(logits, dim=1)[1]\n",
        "\n",
        "                        loss = criterion(logits, label)\n",
        "                        val_running_loss += loss.item()\n",
        "\n",
        "                        y_pred.extend(predicted.tolist())\n",
        "                        y_true.extend(label.tolist())\n",
        "\n",
        "                        del batch, input_ids, attention_mask, label, logits, predicted\n",
        "                \n",
        "                report = classification_report(y_true, y_pred, output_dict=True)\n",
        "                print(\n",
        "                    f\"[valid] epoch: {epoch}, global step: {step}, loss: {val_running_loss / len(data_val)},\"\n",
        "                    f\" report:\\n{classification_report(y_true, y_pred, digits=4)}\"\n",
        "                    f\"confusion_matrix:\\n{confusion_matrix(y_true, y_pred)}\"\n",
        "                    )\n",
        "\n",
        "                if report['macro avg']['f1-score'] > curr_best_val_f1_macro:\n",
        "                    curr_best_val_f1_macro = report[\"macro avg\"]['f1-score']\n",
        "                    best_val_at_step = step\n",
        "                    model_dir, name = save_path.rsplit(\"/\", 1)\n",
        "                    # name = f\"acc{curr_best_val_f1_macro}_{name}\"\n",
        "                    os.makedirs(model_dir, exist_ok=True)\n",
        "                    torch.save(model.state_dict(), os.path.join(model_dir, name))\n",
        "\n",
        "        print(\n",
        "            f\"[train] epoch: {epoch}, global step: {step}, loss: {running_loss / total_num},\"\n",
        "            f\" accuracy: {correct_num / total_num}\")\n",
        "\n",
        "    print(f\"[finish] best valid macro avg is {curr_best_val_f1_macro}, achieved at global step {best_val_at_step}\")\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    del args  # not used\n",
        "        \n",
        "    seed = FLAGS.seed\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    train_dataloader, class_weights = create_dataloader(FLAGS.data_path,\n",
        "                                                        \"train\",\n",
        "                                                        FLAGS.model_name,\n",
        "                                                        batch_size=FLAGS.batch_size,\n",
        "                                                        max_length=FLAGS.max_len,\n",
        "                                                        columns=FLAGS.other_features,\n",
        "                                                        use_uncased=FLAGS.use_uncased)\n",
        "    val_dataloader, _ = create_dataloader(FLAGS.data_path,\n",
        "                                          \"valid\",\n",
        "                                          FLAGS.model_name,\n",
        "                                          batch_size=FLAGS.batch_size,\n",
        "                                          max_length=FLAGS.max_len,\n",
        "                                          columns=FLAGS.other_features,\n",
        "                                          use_uncased=FLAGS.use_uncased)\n",
        "\n",
        "    model = TransformerSentimentAnalyzer(FLAGS.model_name,\n",
        "                                         num_class=5,\n",
        "                                         num_other_features=len(FLAGS.other_features),\n",
        "                                         hidden_size=FLAGS.other_hidden_dim,\n",
        "                                         dropout_rate=FLAGS.dropout,\n",
        "                                         use_pooled=FLAGS.use_pooled).to(DEVICE)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(DEVICE))\n",
        "    bert_optim = AdamW(model.parameters(), lr=FLAGS.lr, correct_bias=False)\n",
        "\n",
        "    total_steps = len(train_dataloader) * FLAGS.epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(bert_optim,\n",
        "                                                num_warmup_steps=0,\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    model_save_path = FLAGS.save_path.format(FLAGS.model_name, FLAGS.batch_size, FLAGS.lr,\n",
        "                                             FLAGS.dropout, FLAGS.other_hidden_dim, FLAGS.seed)\n",
        "\n",
        "    print(f'Fixed Transformer stem. Total head trainable parameters {model.count_parameters()}')\n",
        "    train(model, train_dataloader, val_dataloader, FLAGS.epochs, DEVICE, loss_fn,\n",
        "          bert_optim, scheduler, model_save_path, \n",
        "          FLAGS.eval_every, FLAGS.use_lpft, FLAGS.lp_step)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(main)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH1rZJSFculi",
        "outputId": "494f9df8-62d4-44a1-b233-f19251fa5355"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluate.py"
      ],
      "metadata": {
        "id": "pLvoVgL32dc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate.py\n",
        "import os\n",
        "\n",
        "from absl import flags\n",
        "from absl import app\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from model import TransformerSentimentAnalyzer\n",
        "from dataset import create_dataloader\n",
        "\n",
        "flags.DEFINE_string(\"data_path\", \"data_2021_spring\", \"data directory path\")\n",
        "flags.DEFINE_integer(\"max_len\", 256, \"max sentence length. max value is 512 for bert\")\n",
        "flags.DEFINE_list(\"other_features\", [],\n",
        "                  \"other feature aggregations to use\")\n",
        "flags.DEFINE_string(\"model_path\", None, \"where to save the model\", required=True)\n",
        "flags.DEFINE_bool(\"use_pooled\", True, \"whether to use pooled output of Bert\")\n",
        "flags.DEFINE_string(\"save_path\", \"preds/pred.csv\", \"name of the file to save predictions\")\n",
        "flags.DEFINE_string(\"which_data\", \"test\", \"which data to evaluate on. valid or test\")\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def evaluate(model, test_data, device, mode=\"test\", save_name=\"pred.csv\"):\n",
        "    test_bar = tqdm(test_data, total=int(len(test_data)))\n",
        "\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    if mode == \"valid\":\n",
        "        y_true = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_bar:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            other_features = batch[\"features\"].to(device) if \"features\" in batch else None\n",
        "            logits = model(input_ids, attention_mask, other_features)\n",
        "            predicted = torch.max(logits, dim=1)[1]\n",
        "            preds.extend(predicted.tolist())\n",
        "            if mode == \"valid\":\n",
        "                y_true.extend(batch[\"label\"].tolist())\n",
        "\n",
        "    if mode == \"valid\":\n",
        "        print(classification_report(y_true, preds, digits=4))\n",
        "    else:\n",
        "        review_ids = test_data.dataset.data_file[\"review_id\"]\n",
        "        save_preds(review_ids, np.array(preds), save_name)\n",
        "\n",
        "\n",
        "def save_preds(review_ids, preds, save_name=\"pred.csv\"):\n",
        "    answer_df = pd.DataFrame(data={\n",
        "        'review_id': review_ids,\n",
        "        'stars': preds + 1,\n",
        "    })\n",
        "    answer_df.to_csv(save_name, index=False)\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    del args  # unused\n",
        "\n",
        "    ckpt_name = os.path.basename(FLAGS.model_path)\n",
        "    ckpt_name = ckpt_name.rsplit(\".\", 1)[0]\n",
        "    try:\n",
        "        model_name, batch_size, lr, dropout, hidden, seed, _ = ckpt_name.split(\"_\")\n",
        "    except:\n",
        "        model_name, batch_size, lr, dropout, hidden, seed = ckpt_name.split(\"_\")\n",
        "    batch_size = int(batch_size[2:])\n",
        "    dropout = float(dropout[4:])\n",
        "    hidden = int(hidden[6:])\n",
        "\n",
        "    test_dataloader, _ = create_dataloader(FLAGS.data_path,\n",
        "                                           FLAGS.which_data,\n",
        "                                           model_name,\n",
        "                                           batch_size=batch_size,\n",
        "                                           max_length=FLAGS.max_len,\n",
        "                                           columns=FLAGS.other_features)\n",
        "\n",
        "    model = TransformerSentimentAnalyzer(model_name,\n",
        "                                         num_class=5,\n",
        "                                         num_other_features=len(FLAGS.other_features),\n",
        "                                         hidden_size=hidden,\n",
        "                                         dropout_rate=dropout,\n",
        "                                         use_pooled=FLAGS.use_pooled).to(DEVICE)\n",
        "    model.load_state_dict(torch.load(FLAGS.model_path))\n",
        "    model.eval()\n",
        "\n",
        "    evaluate(model,\n",
        "             test_dataloader,\n",
        "             DEVICE,\n",
        "             mode=FLAGS.which_data,\n",
        "             save_name=FLAGS.save_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(main)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kUXtl_V2dCI",
        "outputId": "e68af7df-6fe1-4ac1-fdf1-165da74d1bb3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "zbEV0a35bSNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBZNfuO3bTLg",
        "outputId": "0e65db4a-1535-4e4c-83fa-dfe0448ba303"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.12.1+cu113)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 2)) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 29.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (1.1.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (0.26.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 66.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 53.6 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (14.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 4)) (1.47.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu->-r requirements.txt (line 4)) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 8)) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 8)) (2.8.2)\n",
            "Installing collected packages: tokenizers, tensorflow-estimator, tensorboard, keras, huggingface-hub, gast, transformers, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires keras<2.9,>=2.8.0rc0, but you have keras 2.10.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.4.0 huggingface-hub-0.9.1 keras-2.10.0 tensorboard-2.10.0 tensorflow-estimator-2.10.0 tensorflow-gpu-2.10.0 tokenizers-0.12.1 transformers-4.21.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrT5PNK0ctVg",
        "outputId": "49526159-0c34-4f86-9ded-cae5327c9a57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-09 06:00:12.923382: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-09 06:00:13.136061: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-09-09 06:00:14.027915: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-09 06:00:14.028092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-09 06:00:14.028115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "\n",
            "       USAGE: main.py [flags]\n",
            "flags:\n",
            "\n",
            "main.py:\n",
            "  --batch_size: batch size: 16 or 32 preferred\n",
            "    (default: '16')\n",
            "    (an integer)\n",
            "  --data_path: data directory path\n",
            "    (default: 'data')\n",
            "  --dropout: dropout rate\n",
            "    (default: '0.3')\n",
            "    (a number)\n",
            "  --epochs: number of training epochs\n",
            "    (default: '3')\n",
            "    (an integer)\n",
            "  --eval_every: number of training steps after each the model is evaluated\n",
            "    (default: '50')\n",
            "    (an integer)\n",
            "  --lp_step: number of Linear Probing\n",
            "    (default: '100')\n",
            "    (an integer)\n",
            "  --lr: learning rate. Preferred 2e-5, 3e-5, 5e-5\n",
            "    (default: '2e-05')\n",
            "    (a number)\n",
            "  --max_len: max sentence length. max value is 512 for bert\n",
            "    (default: '256')\n",
            "    (an integer)\n",
            "  --model_name: which transformer to use\n",
            "    (default: 'bert-base-cased')\n",
            "  --other_features: other feature aggregations to use\n",
            "    (default: '')\n",
            "    (a comma separated list)\n",
            "  --other_hidden_dim: hidden dim for other features\n",
            "    (default: '10')\n",
            "    (an integer)\n",
            "  --save_path: where to save the model\n",
            "    (default: 'models/{}_bs{}_lr{}_drop{}_hidden{}_seed{}.pth')\n",
            "  --seed: to reproduce the experiment\n",
            "    (default: '101')\n",
            "    (an integer)\n",
            "  --use_lpft: whether to apply the method of Linear Probing and Finetuning. If\n",
            "    True, in the lp_step steps, only train classifier head, after that finetune\n",
            "    the whole model.\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --[no]use_pooled: whether to use pooled output of Bert\n",
            "    (default: 'true')\n",
            "  --use_uncased: help to experiment with RoBERTa uncased\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "\n",
            "Try --helpfull to get a list of all flags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "y3RmwfUM29XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-nG6uYZb1X_2",
        "outputId": "04c86d6e-b3e9-4c8d-bd1f-f18f96c18bfb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Sentiment_Analysis/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python main.py --data_path https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Sentiment_Analysis/data \\\n",
        "  --model_name roberta-base \\\n",
        "  --batch_size 32 \\\n",
        "  --max_len 256 \\\n",
        "  --epochs 3 \\\n",
        "  --lr 1e-5 \\\n",
        "  --dropout 0.4 \\\n",
        "  --save_path models/{}_bs{}_lr{}_drop{}_hidden{}_seed{}_lpft.pth \\\n",
        "  --use_pooled \\\n",
        "  --other_hidden_dim 32 \\\n",
        "  --eval_every 50 \\\n",
        "  --use_lpft 1 \\\n",
        "  --lp_step 10 \\\n",
        "  --seed 101 \\\n",
        "  > log_roberta_lpft.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw-9ICXU1U1y",
        "outputId": "f471601a-d301-48ac-df56-731a62a017ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-09 06:03:54.861863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-09 06:03:55.066780: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-09-09 06:03:55.802013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-09 06:03:55.802147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-09 06:03:55.802169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2022-09-09 06:03:57.571290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-09 06:03:57.585323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-09 06:03:57.586024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Downloading vocab.json: 100% 878k/878k [00:00<00:00, 7.86MB/s]\n",
            "Downloading merges.txt: 100% 446k/446k [00:00<00:00, 4.64MB/s]\n",
            "Downloading config.json: 100% 481/481 [00:00<00:00, 642kB/s]\n",
            "Downloading pytorch_model.bin: 100% 478M/478M [00:08<00:00, 60.0MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "train: 1 / 3:   2% 9/563 [00:07<04:37,  1.99it/s, acc=0.153, loss=0.0525]/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "train: 1 / 3: 100% 563/563 [18:31<00:00,  1.97s/it, acc=0.648, loss=0.0278]\n",
            "train: 2 / 3: 100% 563/563 [18:00<00:00,  1.92s/it, acc=0.756, loss=0.0195]\n",
            "train: 3 / 3: 100% 563/563 [17:57<00:00,  1.91s/it, acc=0.822, loss=0.0137]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "J1u0V-id2_on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Edkhy-O2x1X",
        "outputId": "25a9e7fa-27cf-4717-a55b-40175fdd2175"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta-base_bs32_lr1e-05_drop0.4_hidden32_seed101_lpft.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py --data_path https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Sentiment_Analysis/data \\\n",
        "  --model_path models/roberta-base_bs32_lr1e-05_drop0.4_hidden32_seed101_lpft.pth \\\n",
        "  --which_data valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlCJmiXM1j5R",
        "outputId": "5342bffb-54bc-4908-f374-bdae7f11493a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-09 06:59:38.152135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-09 06:59:38.354252: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-09-09 06:59:39.164833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-09 06:59:39.164986: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-09 06:59:39.165014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2022-09-09 06:59:40.553518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-09 06:59:40.560130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-09 06:59:40.560826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100% 63/63 [00:31<00:00,  2.00it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8721    0.7979    0.8333       282\n",
            "           1     0.4649    0.6324    0.5358       136\n",
            "           2     0.5693    0.5425    0.5556       212\n",
            "           3     0.5523    0.5665    0.5593       466\n",
            "           4     0.8290    0.8042    0.8164       904\n",
            "\n",
            "    accuracy                         0.7085      2000\n",
            "   macro avg     0.6575    0.6687    0.6601      2000\n",
            "weighted avg     0.7183    0.7085    0.7122      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict"
      ],
      "metadata": {
        "id": "DYUoBTi93B4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py --data_path https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Sentiment_Analysis/data \\\n",
        "  --model_path models/roberta-base_bs32_lr1e-05_drop0.4_hidden32_seed101_lpft.pth \\\n",
        "  --which_data test \\\n",
        "  --save_path pred.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KJVNcVB3EUp",
        "outputId": "f7dcbb9d-2e26-4211-bcdc-6775a4722089"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-09 07:02:05.574903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-09 07:02:05.768320: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-09-09 07:02:06.750276: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-09 07:02:06.750421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-09 07:02:06.750444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2022-09-09 07:02:09.317678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-09 07:02:09.327600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-09 07:02:09.328581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100% 125/125 [01:04<00:00,  1.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv(\"pred.csv\")[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xk65df40DQrG",
        "outputId": "3700dc46-a543-43b9-d8b3-450c897ae175"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                review_id  stars\n",
              "0  I77zZlSdCFAClxdjHwPcxw      5\n",
              "1  ioFNKarf29KGjRZdH0qC8Q      5\n",
              "2  9429anmcYIcaEcMptJCNKQ      1\n",
              "3  PsUCdt7PKjzgBC0c7xXhJA      5\n",
              "4  GQBlykKyShQcNeu2ivLdSA      4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42195f79-a01d-4cd2-b6cd-921226333667\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I77zZlSdCFAClxdjHwPcxw</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ioFNKarf29KGjRZdH0qC8Q</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9429anmcYIcaEcMptJCNKQ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PsUCdt7PKjzgBC0c7xXhJA</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GQBlykKyShQcNeu2ivLdSA</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42195f79-a01d-4cd2-b6cd-921226333667')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42195f79-a01d-4cd2-b6cd-921226333667 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42195f79-a01d-4cd2-b6cd-921226333667');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}