{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanHoann/Yelp_Dataset_Challenges/blob/main/Recommendation_Prediction/Final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7bca9f",
      "metadata": {
        "id": "9c7bca9f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Concatenate, Dense, Dot, Dropout, Embedding, Input, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import random\n",
        "\n",
        "# Setting random seeds to replicate results easily\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ce4558f",
      "metadata": {
        "id": "4ce4558f"
      },
      "source": [
        "# Root Mean Squared Error (RMSE)\n",
        "\n",
        "We need a reliable way to evaluate the performance of recommendation algorithms. RMSE is one of the popular metrics to estimate how good the recommendation algorithm is. Since RMSE is measuring the prediction errors, the smaller error that the model can achieve, the better performance it is, and vice versa.\n",
        "\n",
        "$$RMSE=\\sqrt{\\sum_{i=1}^n\\frac{(\\hat{y}_i - y_i)^2}{N}}$$\n",
        "\n",
        "$\\hat{y}_i$: The predicted answer of sample $i$\n",
        "\n",
        "$y$: The ground truth answer of sample $i$\n",
        "\n",
        "Data analysis: Plot the number of each that give review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4875920",
      "metadata": {
        "id": "c4875920"
      },
      "outputs": [],
      "source": [
        "def rmse(pred, actual):\n",
        "    '''\n",
        "    params:\n",
        "        pred <np.array>: an array containing all predicted ratings\n",
        "        actual <np.array>: an array containing all ground truth ratings\n",
        "\n",
        "    return:\n",
        "        a scalar whose value is the rmse\n",
        "    '''\n",
        "    # Ignore ratings with value zero.\n",
        "    pred = pred[actual.nonzero()].flatten()\n",
        "    actual = actual[actual.nonzero()].flatten()\n",
        "    return np.sqrt(mean_squared_error(pred, actual))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3979452d",
      "metadata": {
        "id": "3979452d"
      },
      "source": [
        "# Neural Collaborative Filtering (NCF) Model Implementation\n",
        "\n",
        "Here we implement two instantiations of NCF model. \n",
        "\n",
        "The first instantiation computes the recommendation score (e.g., ratings) between a pair of user and item using dot product of their embeddings, which is equivalent to matrix factorization model for recommendation.\n",
        "\n",
        "The second instantiation concatenates the user's and item's embeddings, then feed the the concatenated vector into a MLP to calculate the recommendation score. Adoption of MLP equips the model with high flexibility and non-linearity to effectively learn the interaction between user and item latent features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44b22c8",
      "metadata": {
        "id": "b44b22c8"
      },
      "outputs": [],
      "source": [
        "def build_ncf_model(n_users, n_items, embed_size, output_layer='dot',params=0):\n",
        "    '''\n",
        "    params:\n",
        "        n_users <int>: The number of user embedding vectors\n",
        "        n_items <int>: The number of item embedding vectors\n",
        "        embed_size <int>: The dimension of each embedding vector\n",
        "        output_layer <str>: Indicates the instantiation of NCF to use, available options are either 'dot' or 'mlp'\n",
        "\n",
        "    return:\n",
        "        a keras Model object for the constructed ncf model \n",
        "    '''\n",
        "    # Get the users and items input\n",
        "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
        "\n",
        "\n",
        "    # Get the embeddings of users and items\n",
        "    user_emb = Embedding(output_dim=embed_size, input_dim=n_users, input_length=1)(user_input)\n",
        "    user_emb = Reshape((embed_size,))(user_emb)\n",
        "    item_emb = Embedding(output_dim=embed_size, input_dim=n_items, input_length=1)(item_input)\n",
        "    item_emb = Reshape((embed_size,))(item_emb)\n",
        "\n",
        "\n",
        "    if output_layer == 'dot':\n",
        "        # Compute the dot product of users' and items' embeddings as the model output\n",
        "        model_output = Dot(axes=1)([user_emb, item_emb])\n",
        "\n",
        "    elif output_layer == 'mlp':\n",
        "        # Concatenate the users' and items' embeddings as the input of MLP\n",
        "        mlp_input = Concatenate()([user_emb, item_emb])\n",
        "\n",
        "        # First fully-connected layer\n",
        "        dense_1 = Dense(128, activation='relu')(mlp_input)\n",
        "        dense_1_dp = Dropout(0.15)(dense_1)\n",
        "\n",
        "        # Second fully-connected layer\n",
        "        dense_2 = Dense(64, activation='relu')(dense_1_dp)\n",
        "        dense_2_dp = Dropout(0.15)(dense_2)\n",
        "\n",
        "        # Final fully-connected layer to compute model output\n",
        "        model_output = Dense(1)(dense_2_dp)\n",
        "    elif output_layer == 'cus':\n",
        "        # Concatenate the users' and items' embeddings as the input of MLP\n",
        "        mlp_input = Concatenate()([user_emb, item_emb])\n",
        "\n",
        "        # First fully-connected layer\n",
        "        dense_1 = Dense(params[0], activation='relu')(mlp_input)\n",
        "        dense_1_dp = Dropout(params[1])(dense_1)\n",
        "\n",
        "        # Second fully-connected layer\n",
        "        dense_2 = Dense(params[2], activation='relu')(dense_1_dp)\n",
        "        dense_2_dp = Dropout(params[3])(dense_2)\n",
        "\n",
        "        # Final fully-connected layer to compute model output\n",
        "        model_output = Dense(params[4])(dense_2_dp)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    model = Model(inputs=[user_input, item_input], outputs=model_output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ee02b9e",
      "metadata": {
        "id": "0ee02b9e"
      },
      "source": [
        "# Ratings Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "952f5b81",
      "metadata": {
        "id": "952f5b81"
      },
      "source": [
        "### Loading training and validation rating table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a372635b",
      "metadata": {
        "id": "a372635b"
      },
      "outputs": [],
      "source": [
        "data = \"https://raw.githubusercontent.com/VanHoann/Yelp_Dataset_Challenges/main/Recommendation_Prediction/data\"\n",
        "tr_df = pd.read_csv(f\"{data}/train.csv\")\n",
        "val_df = pd.read_csv(f\"{data}/valid.csv\")\n",
        "test_df = pd.read_csv(f\"{data}/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee7c22ad",
      "metadata": {
        "id": "ee7c22ad"
      },
      "source": [
        "### Building two dictionaries to map original user ids and item ids into corresponding indices in respective embedding matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90b8ea9f",
      "metadata": {
        "id": "90b8ea9f"
      },
      "outputs": [],
      "source": [
        "# Get the unique set of all user ids and set of all business ids in train set\n",
        "user_set = set(tr_df.user_id.unique()).union(set(test_df.user_id.unique()))\n",
        "business_set = set(tr_df.business_id.unique()).union(set(test_df.business_id.unique()))\n",
        "\n",
        "# Build user vocabulary\n",
        "user_vocab = dict(zip(user_set, range(1, len(user_set) + 1)))\n",
        "\n",
        "# Reserve the first row of the embedding matrix for users unseen in the training set\n",
        "user_vocab['unk'] = 0 \n",
        "n_users = len(user_vocab)\n",
        "\n",
        "# Build business vocabulary\n",
        "business_vocab = dict(zip(business_set, range(1, len(business_set) + 1)))\n",
        "# Reserve the first row of the embedding matrix for businesses unseen in the training set\n",
        "business_vocab['unk'] = 0\n",
        "n_items = len(business_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(user_vocab.items())[:2])\n",
        "print(list(business_vocab.items())[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dkn3-wI2F2d",
        "outputId": "5b055938-27d4-48d0-eac1-1d81450d30c0"
      },
      "id": "1dkn3-wI2F2d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('963c74473df680c5293cf505d2044e09', 1), ('56855fadbba2aebf832cc2dc3674c9d0', 2)]\n",
            "[('6ab42de44090919368e967d5cad01e47', 1), ('5d756dbba7c6902ea27b838e087621e6', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7ccd4c5",
      "metadata": {
        "id": "c7ccd4c5"
      },
      "source": [
        "### Replacing the original user and item ids in train and valdiation set with indices in embedding matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c8760a",
      "metadata": {
        "id": "a4c8760a"
      },
      "outputs": [],
      "source": [
        "# Transforming user_id into a number by the user_vocab dictionary, and\n",
        "# transforming business_id into a number by the business_vocab dictonary\n",
        "tr_users = tr_df.user_id.apply(lambda x: user_vocab[x]).values\n",
        "tr_items = tr_df.business_id.apply(lambda x: business_vocab[x]).values\n",
        "val_users = val_df.user_id.apply(lambda x: user_vocab[x] if x in user_vocab else 0).values\n",
        "val_items = val_df.business_id.apply(lambda x: business_vocab[x] if x in business_vocab else 0).values\n",
        "test_users = test_df.user_id.apply(lambda x: user_vocab[x]).values\n",
        "test_items = test_df.business_id.apply(lambda x: business_vocab[x]).values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ba8f80",
      "metadata": {
        "id": "54ba8f80"
      },
      "source": [
        "### Retrieving ratings in the training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1904b132",
      "metadata": {
        "id": "1904b132"
      },
      "outputs": [],
      "source": [
        "tr_ratings = tr_df.stars.values\n",
        "val_ratings = val_df.stars.values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d20b2ebd",
      "metadata": {
        "id": "d20b2ebd"
      },
      "source": [
        "### Building the NCF model defined above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c8ace4",
      "metadata": {
        "id": "c0c8ace4"
      },
      "outputs": [],
      "source": [
        "model = build_ncf_model(n_users, n_items, embed_size=50, output_layer='mlp')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd14336",
      "metadata": {
        "id": "9fd14336"
      },
      "source": [
        "### Training the model using Adam optimizer and mean squared error loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.mkdir(\"models\")"
      ],
      "metadata": {
        "id": "ux1_K-YXIw1X"
      },
      "id": "ux1_K-YXIw1X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc550016",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc550016",
        "outputId": "3c3c9356-f1d0-434a-fee7-cac7f7d4dcec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1878/1878 [==============================] - 20s 10ms/step - loss: 0.8388\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(\n",
        "        [tr_users, tr_items], \n",
        "        tr_ratings, \n",
        "        epochs=1, \n",
        "        verbose=1,\n",
        "        callbacks=[ModelCheckpoint('models/model.h5')])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0acc8dde",
      "metadata": {
        "id": "0acc8dde"
      },
      "source": [
        "### Tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e056a3bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e056a3bc",
        "outputId": "a1b15067-2290-4acc-fdb0-4bb623f140e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set RMSE:  0.955914160752847\n",
            "Validation set RMSE:  1.0640883301074038\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('models/model.h5')\n",
        "y_pred = model.predict([tr_users, tr_items])\n",
        "print(\"Train set RMSE: \", rmse(y_pred, tr_ratings))\n",
        "y_pred = model.predict([val_users, val_items])\n",
        "print(\"Validation set RMSE: \", rmse(y_pred, val_ratings))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best = rmse(y_pred, val_ratings)"
      ],
      "metadata": {
        "id": "abDuduaA9XRI"
      },
      "id": "abDuduaA9XRI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i1 in [5,6]:\n",
        "    for i2 in range(12,15):\n",
        "      for i3 in [7,8]:\n",
        "        for i4 in range(10,12):\n",
        "          model = build_ncf_model(n_users, n_items, embed_size=50, output_layer='cus',params=[2**i1,0.1+0.01*i2,2**i3,0.1+0.01*i4,1])\n",
        "          model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "          history = model.fit(\n",
        "                  [tr_users, tr_items], \n",
        "                  tr_ratings, \n",
        "                  epochs=1, \n",
        "                  verbose=0,\n",
        "                  callbacks=[ModelCheckpoint('models/model.h5')])\n",
        "          model = tf.keras.models.load_model('models/model.h5')\n",
        "          #print(str(i1)+\" \"+str(i2)+ \" \"+str(i3)+ \" \"+str(i4))\n",
        "          y_pred = model.predict([tr_users, tr_items])\n",
        "          #print(\"Train set RMSE: \", rmse(y_pred, tr_ratings))\n",
        "          y_pred = model.predict([val_users, val_items])\n",
        "          #print(\"Validation set RMSE: \", rmse(y_pred, val_ratings))\n",
        "          if rmse(y_pred,val_ratings) < best:\n",
        "            best = rmse(y_pred,val_ratings)\n",
        "            print(\"Update current best with value\",rmse(y_pred,val_ratings))\n",
        "            print(\"Best params is \"+str(i1)+\" \"+str(i2)+\" \"+str(i3)+\" \"+str(i4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEeQauXzkEgn",
        "outputId": "faa0bae4-1209-46eb-d241-ff277bab3945"
      },
      "id": "QEeQauXzkEgn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update current best with value 1.0628255374216928\n",
            "Best params is 5 12 8 10\n",
            "Update current best with value 1.0623724321992232\n",
            "Best params is 5 12 8 11\n",
            "Update current best with value 1.0619134493239775\n",
            "Best params is 5 13 8 10\n",
            "Update current best with value 1.0615142402393105\n",
            "Best params is 5 14 8 10\n",
            "Update current best with value 1.0605953145581708\n",
            "Best params is 6 13 8 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "dpOAj9sljc-v"
      },
      "id": "dpOAj9sljc-v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate.py"
      ],
      "metadata": {
        "id": "bpfk5_Oq4ZzB"
      },
      "id": "bpfk5_Oq4ZzB"
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_ncf_model(n_users, n_items, embed_size=50, output_layer='cus',params=[32,0.24,256,0.2,1])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(\n",
        "        [tr_users, tr_items], \n",
        "        tr_ratings, \n",
        "        epochs=1, \n",
        "        verbose=0,\n",
        "        callbacks=[ModelCheckpoint('models/model.h5')])\n",
        "model = tf.keras.models.load_model('models/model.h5')\n",
        "#print(str(i1)+\" \"+str(i2)+ \" \"+str(i3)+ \" \"+str(i4))\n",
        "tr_pred = model.predict([tr_users, tr_items])\n",
        "print(\"Train set RMSE: \", rmse(tr_pred, tr_ratings))\n",
        "val_pred = model.predict([val_users, val_items])\n",
        "print(\"Validation set RMSE: \", rmse(val_pred, val_ratings))\n",
        "test_pred = model.predict([test_users,test_items])"
      ],
      "metadata": {
        "id": "J9n0VBn9-JVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f1166d-f360-4eba-ad2d-9c09bca379f1"
      },
      "id": "J9n0VBn9-JVv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set RMSE:  0.9761562416079695\n",
            "Validation set RMSE:  1.0596320973598592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val = val_df\n",
        "val[\"stars\"] = val_pred\n",
        "val.to_csv(\"val_pred.csv\", index=False)"
      ],
      "metadata": {
        "id": "Rzo6cVlD4wI4"
      },
      "id": "Rzo6cVlD4wI4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Function to calculate RMSE\n",
        "def rmse(pred, actual):\n",
        "\t# Ignore nonzero terms.\n",
        "\tpred = pred[actual.nonzero()].flatten()\n",
        "\tactual = actual[actual.nonzero()].flatten()\n",
        "\treturn sqrt(mean_squared_error(pred, actual))\n",
        "\n",
        "val_df = pd.read_csv(f\"{data}/valid.csv\")\n",
        "\n",
        "pred_df = pd.read_csv('val_pred.csv')\n",
        "\n",
        "df = pd.merge(val_df, pred_df, how=\"left\", left_on=['user_id',\n",
        "\t\t'business_id'], right_on = ['user_id','business_id'])\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "print(\"VALIDATION RMSE: \", rmse(df['stars_y'].values, df['stars_x'].values))"
      ],
      "metadata": {
        "id": "CvtUJGfGnmk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961ec0f2-74a2-4bcc-84b6-23bb0da7e1a9"
      },
      "id": "CvtUJGfGnmk2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION RMSE:  1.0596320974266384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_df['business_id'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_-NXSktCeHa",
        "outputId": "bdebca0c-d111-41d1-a726-4beea0a86f12"
      },
      "id": "i_-NXSktCeHa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "a872871042c5c46838a1ba924dab1f6c    106\n",
              "fd37fd10d66b673df363b646a26c9ab3     94\n",
              "a3e891f8e82805513255e0e0fb1dafa8     86\n",
              "918191ea9d67f9f664a111dbce971237     77\n",
              "f441407637e366ac9dbadc249f6241bb     77\n",
              "                                   ... \n",
              "95c1bd5fd7e26428382a82c2a547d852      1\n",
              "c657ef76ba2c26d47409221ae13f8b49      1\n",
              "ddf68eee71d5772a0840911c4b3eb083      1\n",
              "e8e838c80af3f889a789b20745531851      1\n",
              "493dfe7c8119d73bd1ecadd361094682      1\n",
              "Name: business_id, Length: 5938, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}